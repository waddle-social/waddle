# Issue #56: Spatial Audio

## User Story
As a **waddle participant**, I want to **experience spatial audio that positions voices in 3D space** so that **conversations feel more natural and I can better identify who is speaking**.

## Description
Implement 3D spatial audio positioning that places participant voices in virtual space based on their video position or custom arrangements. This creates a more immersive and natural conversation experience, making it easier to distinguish between speakers and reducing cognitive load in group conversations.

## Acceptance Criteria
- [ ] 3D audio positioning based on video layout
- [ ] Head-related transfer function (HRTF) processing
- [ ] Custom spatial arrangements
- [ ] Audio focus modes
- [ ] Distance-based volume attenuation
- [ ] Room acoustics simulation
- [ ] Spatial audio visualization
- [ ] Accessibility options

## Technical Implementation

### 1. Spatial Audio Engine
```typescript
// Spatial Audio Core Engine
export interface SpatialAudioConfig {
  mode: 'auto' | 'manual' | 'theater' | 'circle';
  hrtfEnabled: boolean;
  roomSize: 'small' | 'medium' | 'large' | 'custom';
  reverbAmount: number;
  distanceModel: 'linear' | 'inverse' | 'exponential';
  maxDistance: number;
  refDistance: number;
  rolloffFactor: number;
}

export class SpatialAudioEngine {
  private audioContext: AudioContext;
  private panner nodes = new Map<string, PannerNode>();
  private binauralProcessor: BinauralProcessor;
  private roomSimulator: RoomAcoustics;
  private spatializer: AudioSpatializer;
  
  constructor(
    private config: SpatialAudioConfig
  ) {
    this.audioContext = new AudioContext({
      sampleRate: 48000,
      latencyHint: 'interactive'
    });
    
    this.binauralProcessor = new BinauralProcessor(this.audioContext);
    this.roomSimulator = new RoomAcoustics(this.audioContext);
    this.spatializer = new AudioSpatializer(this.audioContext);
    
    this.initialize();
  }
  
  private async initialize() {
    // Load HRTF database
    if (this.config.hrtfEnabled) {
      await this.binauralProcessor.loadHRTFDatabase();
    }
    
    // Configure room acoustics
    this.roomSimulator.setRoomParameters({
      dimensions: this.getRoomDimensions(),
      materials: this.getRoomMaterials(),
      reverbTime: this.calculateReverbTime()
    });
    
    // Set distance model
    this.configureDistanceModel();
  }
  
  async createSpatialSource(
    participantId: string,
    stream: MediaStream
  ): Promise<SpatialAudioSource> {
    const source = this.audioContext.createMediaStreamSource(stream);
    
    // Create processing chain
    const gainNode = this.audioContext.createGain();
    const pannerNode = this.audioContext.createPanner();
    
    // Configure panner
    pannerNode.panningModel = this.config.hrtfEnabled ? 'HRTF' : 'equalpower';
    pannerNode.distanceModel = this.config.distanceModel;
    pannerNode.refDistance = this.config.refDistance;
    pannerNode.maxDistance = this.config.maxDistance;
    pannerNode.rolloffFactor = this.config.rolloffFactor;
    
    // Additional spatial processing
    const spatialChain = await this.createSpatialProcessingChain();
    
    // Connect nodes
    source.connect(gainNode);
    gainNode.connect(spatialChain.input);
    spatialChain.output.connect(pannerNode);
    
    // Apply room acoustics if enabled
    if (this.config.roomSize !== 'custom') {
      const roomOutput = await this.roomSimulator.process(pannerNode);
      roomOutput.connect(this.audioContext.destination);
    } else {
      pannerNode.connect(this.audioContext.destination);
    }
    
    // Store panner for position updates
    this.pannerNodes.set(participantId, pannerNode);
    
    return {
      id: participantId,
      source,
      gainNode,
      pannerNode,
      position: { x: 0, y: 0, z: 0 },
      orientation: { x: 0, y: 0, z: -1 },
      updatePosition: this.createPositionUpdater(participantId)
    };
  }
  
  private async createSpatialProcessingChain(): Promise<AudioProcessingChain> {
    // Create convolution reverb for early reflections
    const convolver = this.audioContext.createConvolver();
    const impulseResponse = await this.generateRoomImpulseResponse();
    convolver.buffer = impulseResponse;
    
    // Create filters for distance simulation
    const lowShelfFilter = this.audioContext.createBiquadFilter();
    lowShelfFilter.type = 'lowshelf';
    lowShelfFilter.frequency.value = 320;
    
    const highShelfFilter = this.audioContext.createBiquadFilter();
    highShelfFilter.type = 'highshelf';
    highShelfFilter.frequency.value = 3200;
    
    // Dynamics processing for presence
    const compressor = this.audioContext.createDynamicsCompressor();
    compressor.threshold.value = -24;
    compressor.knee.value = 30;
    compressor.ratio.value = 12;
    compressor.attack.value = 0.003;
    compressor.release.value = 0.25;
    
    // Connect chain
    const input = this.audioContext.createGain();
    const output = this.audioContext.createGain();
    const dry = this.audioContext.createGain();
    const wet = this.audioContext.createGain();
    
    // Dry path
    input.connect(dry);
    dry.connect(lowShelfFilter);
    lowShelfFilter.connect(highShelfFilter);
    highShelfFilter.connect(compressor);
    compressor.connect(output);
    
    // Wet path (reverb)
    input.connect(convolver);
    convolver.connect(wet);
    wet.connect(output);
    
    // Set mix levels
    dry.gain.value = 1 - this.config.reverbAmount;
    wet.gain.value = this.config.reverbAmount;
    
    return { input, output };
  }
  
  updateListenerPosition(position: Position3D, orientation: Orientation3D) {
    const listener = this.audioContext.listener;
    
    // Update position with smooth transitions
    if (listener.positionX) {
      // Using new API
      listener.positionX.linearRampToValueAtTime(
        position.x,
        this.audioContext.currentTime + 0.1
      );
      listener.positionY.linearRampToValueAtTime(
        position.y,
        this.audioContext.currentTime + 0.1
      );
      listener.positionZ.linearRampToValueAtTime(
        position.z,
        this.audioContext.currentTime + 0.1
      );
    } else {
      // Fallback to deprecated API
      listener.setPosition(position.x, position.y, position.z);
    }
    
    // Update orientation
    if (listener.forwardX) {
      listener.forwardX.linearRampToValueAtTime(
        orientation.x,
        this.audioContext.currentTime + 0.1
      );
      listener.forwardY.linearRampToValueAtTime(
        orientation.y,
        this.audioContext.currentTime + 0.1
      );
      listener.forwardZ.linearRampToValueAtTime(
        orientation.z,
        this.audioContext.currentTime + 0.1
      );
      
      listener.upX.linearRampToValueAtTime(0, this.audioContext.currentTime + 0.1);
      listener.upY.linearRampToValueAtTime(1, this.audioContext.currentTime + 0.1);
      listener.upZ.linearRampToValueAtTime(0, this.audioContext.currentTime + 0.1);
    } else {
      listener.setOrientation(
        orientation.x, orientation.y, orientation.z,
        0, 1, 0
      );
    }
  }
  
  private createPositionUpdater(
    participantId: string
  ): (position: Position3D) => void {
    return (position: Position3D) => {
      const panner = this.pannerNodes.get(participantId);
      if (!panner) return;
      
      // Smooth position transitions
      const transitionTime = this.audioContext.currentTime + 0.05;
      
      if (panner.positionX) {
        panner.positionX.linearRampToValueAtTime(position.x, transitionTime);
        panner.positionY.linearRampToValueAtTime(position.y, transitionTime);
        panner.positionZ.linearRampToValueAtTime(position.z, transitionTime);
      } else {
        panner.setPosition(position.x, position.y, position.z);
      }
      
      // Update distance-based filtering
      this.updateDistanceEffects(participantId, position);
    };
  }
  
  private updateDistanceEffects(participantId: string, position: Position3D) {
    const distance = Math.sqrt(
      position.x ** 2 + position.y ** 2 + position.z ** 2
    );
    
    // Apply high-frequency rolloff for distance
    const cutoffFreq = Math.max(
      1000,
      20000 - (distance * 1000)
    );
    
    // Update filters associated with this source
    // This would be implemented based on your audio chain
  }
}

// Binaural Processing with HRTF
export class BinauralProcessor {
  private hrtfDatabase: HRTFDatabase;
  private convolvers = new Map<string, ConvolverNode>();
  
  constructor(private audioContext: AudioContext) {}
  
  async loadHRTFDatabase(): Promise<void> {
    // Load HRTF impulse responses
    const response = await fetch('/audio/hrtf/kemar.json');
    const data = await response.json();
    
    this.hrtfDatabase = new HRTFDatabase(data);
    
    // Preload common angles
    await this.preloadCommonHRTFs();
  }
  
  async createBinauralNode(
    azimuth: number,
    elevation: number
  ): Promise<ConvolverNode> {
    const convolver = this.audioContext.createConvolver();
    
    // Get nearest HRTF pair
    const hrtfPair = this.hrtfDatabase.getNearestHRTF(azimuth, elevation);
    
    // Create stereo impulse response
    const impulseBuffer = await this.createStereoImpulseResponse(hrtfPair);
    convolver.buffer = impulseBuffer;
    
    return convolver;
  }
  
  private async createStereoImpulseResponse(
    hrtfPair: HRTFPair
  ): Promise<AudioBuffer> {
    const length = hrtfPair.left.length;
    const buffer = this.audioContext.createBuffer(
      2,
      length,
      this.audioContext.sampleRate
    );
    
    // Copy HRTF data to channels
    buffer.copyToChannel(hrtfPair.left, 0);
    buffer.copyToChannel(hrtfPair.right, 1);
    
    return buffer;
  }
  
  interpolateHRTF(
    azimuth: number,
    elevation: number
  ): Float32Array[] {
    // Find surrounding HRTFs
    const surrounding = this.hrtfDatabase.getSurroundingHRTFs(
      azimuth,
      elevation
    );
    
    // Perform spherical interpolation
    const weights = this.calculateInterpolationWeights(
      azimuth,
      elevation,
      surrounding
    );
    
    // Interpolate impulse responses
    return this.interpolateImpulseResponses(surrounding, weights);
  }
}
```

### 2. Spatial Positioning System
```typescript
// Spatial Layout Manager
export class SpatialLayoutManager {
  private participants = new Map<string, ParticipantSpatialData>();
  private layoutMode: LayoutMode;
  private customPositions = new Map<string, Position3D>();
  
  constructor(
    private spatialEngine: SpatialAudioEngine,
    private config: SpatialLayoutConfig
  ) {
    this.layoutMode = config.defaultLayout;
  }
  
  async arrangeParticipants(
    participantIds: string[],
    mode?: LayoutMode
  ): Promise<void> {
    this.layoutMode = mode || this.layoutMode;
    
    const positions = this.calculatePositions(
      participantIds,
      this.layoutMode
    );
    
    // Apply positions with smooth transitions
    for (let i = 0; i < participantIds.length; i++) {
      const participantId = participantIds[i];
      const position = positions[i];
      
      await this.updateParticipantPosition(participantId, position);
    }
    
    // Update visualization
    this.notifyPositionUpdate();
  }
  
  private calculatePositions(
    participantIds: string[],
    mode: LayoutMode
  ): Position3D[] {
    const count = participantIds.length;
    
    switch (mode) {
      case 'circle':
        return this.calculateCircleLayout(count);
        
      case 'theater':
        return this.calculateTheaterLayout(count);
        
      case 'line':
        return this.calculateLineLayout(count);
        
      case 'grid':
        return this.calculateGridLayout(count);
        
      case 'focus':
        return this.calculateFocusLayout(count);
        
      case 'custom':
        return participantIds.map(id => 
          this.customPositions.get(id) || { x: 0, y: 0, z: 0 }
        );
        
      default:
        return this.calculateAutoLayout(count);
    }
  }
  
  private calculateCircleLayout(count: number): Position3D[] {
    const positions: Position3D[] = [];
    const radius = Math.max(2, count * 0.5); // Dynamic radius
    
    for (let i = 0; i < count; i++) {
      const angle = (i / count) * Math.PI * 2;
      positions.push({
        x: Math.cos(angle) * radius,
        y: 0, // Keep at ear level
        z: Math.sin(angle) * radius
      });
    }
    
    return positions;
  }
  
  private calculateTheaterLayout(count: number): Position3D[] {
    const positions: Position3D[] = [];
    const rows = Math.ceil(Math.sqrt(count));
    const seatsPerRow = Math.ceil(count / rows);
    
    let participantIndex = 0;
    
    for (let row = 0; row < rows && participantIndex < count; row++) {
      const z = -row * 2; // Depth
      const y = row * 0.3; // Elevation for stadium seating
      const rowSeats = Math.min(seatsPerRow, count - participantIndex);
      const rowWidth = (rowSeats - 1) * 1.5;
      
      for (let seat = 0; seat < rowSeats; seat++) {
        const x = -rowWidth / 2 + seat * 1.5;
        positions.push({ x, y, z });
        participantIndex++;
      }
    }
    
    return positions;
  }
  
  private calculateFocusLayout(count: number): Position3D[] {
    const positions: Position3D[] = [];
    
    if (count === 0) return positions;
    
    // First participant at center
    positions.push({ x: 0, y: 0, z: -2 });
    
    // Others in semicircle behind listener
    const othersCount = count - 1;
    const startAngle = -Math.PI / 3;
    const endAngle = Math.PI / 3;
    const radius = 3;
    
    for (let i = 0; i < othersCount; i++) {
      const angle = startAngle + (i / (othersCount - 1)) * (endAngle - startAngle);
      positions.push({
        x: Math.sin(angle) * radius,
        y: 0,
        z: Math.cos(angle) * radius
      });
    }
    
    return positions;
  }
  
  async setCustomPosition(
    participantId: string,
    position: Position3D
  ): Promise<void> {
    this.customPositions.set(participantId, position);
    await this.updateParticipantPosition(participantId, position);
  }
  
  private async updateParticipantPosition(
    participantId: string,
    position: Position3D
  ): Promise<void> {
    const participant = this.participants.get(participantId);
    if (!participant) return;
    
    // Update spatial audio engine
    participant.spatialSource.updatePosition(position);
    
    // Store new position
    participant.position = position;
    
    // Calculate and apply orientation
    const orientation = this.calculateOrientation(position);
    participant.spatialSource.updateOrientation(orientation);
  }
  
  private calculateOrientation(position: Position3D): Orientation3D {
    // Orient towards listener (origin)
    const distance = Math.sqrt(
      position.x ** 2 + position.y ** 2 + position.z ** 2
    );
    
    if (distance === 0) {
      return { x: 0, y: 0, z: -1 };
    }
    
    return {
      x: -position.x / distance,
      y: -position.y / distance,
      z: -position.z / distance
    };
  }
}

// Audio Focus System
export class AudioFocusManager {
  private focusedParticipants = new Set<string>();
  private focusMode: FocusMode = 'none';
  private focusStrength: number = 0.7;
  
  constructor(
    private spatialEngine: SpatialAudioEngine,
    private participants: Map<string, ParticipantSpatialData>
  ) {}
  
  setFocusMode(mode: FocusMode, participantIds?: string[]) {
    this.focusMode = mode;
    
    if (mode === 'specific' && participantIds) {
      this.focusedParticipants = new Set(participantIds);
    }
    
    this.applyFocus();
  }
  
  private applyFocus() {
    for (const [id, participant] of this.participants) {
      const isFocused = this.shouldBeFocused(id);
      const targetGain = isFocused ? 1.0 : (1.0 - this.focusStrength);
      
      // Smooth gain transition
      participant.spatialSource.gainNode.gain.linearRampToValueAtTime(
        targetGain,
        this.spatialEngine.currentTime + 0.3
      );
      
      // Adjust spatial spread
      if (this.focusMode !== 'none') {
        this.adjustSpatialSpread(participant, isFocused);
      }
    }
  }
  
  private shouldBeFocused(participantId: string): boolean {
    switch (this.focusMode) {
      case 'none':
        return true;
        
      case 'specific':
        return this.focusedParticipants.has(participantId);
        
      case 'speaking':
        return this.isSpeaking(participantId);
        
      case 'proximity':
        return this.isNearby(participantId);
        
      default:
        return true;
    }
  }
  
  private adjustSpatialSpread(
    participant: ParticipantSpatialData,
    isFocused: boolean
  ) {
    const panner = participant.spatialSource.pannerNode;
    
    if (isFocused) {
      // Tighten spatial image
      panner.coneInnerAngle = 30;
      panner.coneOuterAngle = 45;
      panner.coneOuterGain = 0.4;
    } else {
      // Widen spatial image
      panner.coneInnerAngle = 60;
      panner.coneOuterAngle = 90;
      panner.coneOuterGain = 0.7;
    }
  }
}
```

### 3. Room Acoustics Simulation
```typescript
// Room Acoustics Simulator
export class RoomAcoustics {
  private convolver: ConvolverNode;
  private earlyReflections: DelayNode[];
  private lateReverb: ConvolverNode;
  private roomParameters: RoomParameters;
  
  constructor(private audioContext: AudioContext) {
    this.setupAcousticNetwork();
  }
  
  private setupAcousticNetwork() {
    // Main convolver for room impulse response
    this.convolver = this.audioContext.createConvolver();
    
    // Early reflections network
    this.earlyReflections = this.createEarlyReflections();
    
    // Late reverb
    this.lateReverb = this.audioContext.createConvolver();
  }
  
  async setRoomParameters(params: RoomParameters) {
    this.roomParameters = params;
    
    // Generate room impulse response
    const impulseResponse = await this.generateRoomImpulse(params);
    this.convolver.buffer = impulseResponse;
    
    // Update early reflections
    this.updateEarlyReflections(params);
    
    // Update late reverb
    await this.updateLateReverb(params);
  }
  
  private async generateRoomImpulse(
    params: RoomParameters
  ): Promise<AudioBuffer> {
    const sampleRate = this.audioContext.sampleRate;
    const length = params.reverbTime * sampleRate;
    const buffer = this.audioContext.createBuffer(2, length, sampleRate);
    
    for (let channel = 0; channel < 2; channel++) {
      const channelData = buffer.getChannelData(channel);
      
      // Generate impulse response using image source method
      this.generateChannelImpulse(channelData, params, channel === 0);
    }
    
    return buffer;
  }
  
  private generateChannelImpulse(
    data: Float32Array,
    params: RoomParameters,
    isLeft: boolean
  ) {
    const { dimensions, materials } = params;
    
    // Calculate room modes
    const modes = this.calculateRoomModes(dimensions);
    
    // Generate early reflections (0-80ms)
    const earlyTime = Math.min(0.08 * this.audioContext.sampleRate, data.length);
    for (let i = 0; i < earlyTime; i++) {
      const time = i / this.audioContext.sampleRate;
      data[i] = this.calculateEarlyReflection(time, dimensions, materials, isLeft);
    }
    
    // Generate late reverb (80ms+)
    for (let i = earlyTime; i < data.length; i++) {
      const time = i / this.audioContext.sampleRate;
      const decay = Math.exp(-3 * time / params.reverbTime);
      data[i] = (Math.random() - 0.5) * decay * 0.5;
      
      // Add modal resonances
      for (const mode of modes) {
        if (mode.frequency < 500) {
          data[i] += Math.sin(2 * Math.PI * mode.frequency * time) * 
                     mode.amplitude * decay * 0.1;
        }
      }
    }
    
    // Apply frequency-dependent decay
    this.applyFrequencyDecay(data, materials);
  }
  
  private calculateRoomModes(dimensions: RoomDimensions): RoomMode[] {
    const modes: RoomMode[] = [];
    const c = 343; // Speed of sound in m/s
    
    // Calculate axial modes
    for (let nx = 0; nx <= 3; nx++) {
      for (let ny = 0; ny <= 3; ny++) {
        for (let nz = 0; nz <= 3; nz++) {
          if (nx + ny + nz === 0) continue;
          
          const frequency = (c / 2) * Math.sqrt(
            (nx / dimensions.width) ** 2 +
            (ny / dimensions.height) ** 2 +
            (nz / dimensions.depth) ** 2
          );
          
          if (frequency < 500) {
            modes.push({
              frequency,
              amplitude: 1 / (nx + ny + nz + 1),
              type: 'axial'
            });
          }
        }
      }
    }
    
    return modes;
  }
  
  private createEarlyReflections(): DelayNode[] {
    const reflections: DelayNode[] = [];
    
    // Create 6 primary reflections (one per wall)
    const delays = [0.010, 0.015, 0.020, 0.025, 0.030, 0.035];
    
    for (const delay of delays) {
      const delayNode = this.audioContext.createDelay();
      delayNode.delayTime.value = delay;
      reflections.push(delayNode);
    }
    
    return reflections;
  }
  
  async process(input: AudioNode): Promise<AudioNode> {
    const wetGain = this.audioContext.createGain();
    const dryGain = this.audioContext.createGain();
    const output = this.audioContext.createGain();
    
    // Dry path
    input.connect(dryGain);
    dryGain.connect(output);
    
    // Wet path - Early reflections
    for (let i = 0; i < this.earlyReflections.length; i++) {
      const reflection = this.earlyReflections[i];
      const gain = this.audioContext.createGain();
      gain.gain.value = this.calculateReflectionGain(i);
      
      input.connect(reflection);
      reflection.connect(gain);
      gain.connect(wetGain);
    }
    
    // Wet path - Late reverb
    input.connect(this.convolver);
    this.convolver.connect(wetGain);
    wetGain.connect(output);
    
    // Set wet/dry mix based on room size
    const wetAmount = this.calculateWetAmount();
    wetGain.gain.value = wetAmount;
    dryGain.gain.value = 1 - wetAmount;
    
    return output;
  }
  
  private calculateReflectionGain(reflectionIndex: number): number {
    const materials = this.roomParameters.materials;
    const averageAbsorption = Object.values(materials)
      .reduce((sum, mat) => sum + mat.absorption, 0) / 6;
    
    return (1 - averageAbsorption) * Math.pow(0.8, reflectionIndex);
  }
}

// Material Properties
export interface MaterialProperties {
  absorption: number; // 0-1
  scattering: number; // 0-1
  transmission: number; // 0-1
}

export const MATERIAL_PRESETS: Record<string, MaterialProperties> = {
  concrete: { absorption: 0.02, scattering: 0.1, transmission: 0 },
  wood: { absorption: 0.15, scattering: 0.3, transmission: 0.05 },
  carpet: { absorption: 0.6, scattering: 0.5, transmission: 0 },
  glass: { absorption: 0.05, scattering: 0.05, transmission: 0.2 },
  fabric: { absorption: 0.7, scattering: 0.6, transmission: 0.1 },
  acoustic_panel: { absorption: 0.9, scattering: 0.4, transmission: 0 }
};
```

### 4. Spatial Audio UI
```tsx
export function SpatialAudioControls() {
  const [spatialEnabled, setSpatialEnabled] = useState(true);
  const [layoutMode, setLayoutMode] = useState<LayoutMode>('auto');
  const [showVisualizer, setShowVisualizer] = useState(true);
  const [focusMode, setFocusMode] = useState<FocusMode>('none');
  const [roomSettings, setRoomSettings] = useState<RoomSettings>({
    size: 'medium',
    reverb: 0.3
  });
  
  const spatialEngine = useSpatialAudioEngine();
  const participants = useParticipants();
  
  const handleLayoutChange = async (mode: LayoutMode) => {
    setLayoutMode(mode);
    await spatialEngine.setLayoutMode(mode);
  };
  
  const handleFocusModeChange = (mode: FocusMode) => {
    setFocusMode(mode);
    spatialEngine.setFocusMode(mode);
  };
  
  return (
    <div className="spatial-audio-controls">
      <div className="spatial-header">
        <h3>Spatial Audio</h3>
        <Toggle
          checked={spatialEnabled}
          onChange={setSpatialEnabled}
          label="Enable 3D Audio"
        />
      </div>
      
      {spatialEnabled && (
        <>
          <div className="layout-section">
            <h4>Audio Layout</h4>
            <LayoutModeSelector
              value={layoutMode}
              onChange={handleLayoutChange}
              options={[
                { value: 'auto', label: 'Automatic', icon: <AutoIcon /> },
                { value: 'circle', label: 'Circle', icon: <CircleIcon /> },
                { value: 'theater', label: 'Theater', icon: <TheaterIcon /> },
                { value: 'focus', label: 'Focus', icon: <FocusIcon /> },
                { value: 'custom', label: 'Custom', icon: <CustomIcon /> }
              ]}
            />
          </div>
          
          <div className="focus-section">
            <h4>Audio Focus</h4>
            <FocusModeSelector
              value={focusMode}
              onChange={handleFocusModeChange}
            />
          </div>
          
          <div className="room-section">
            <h4>Room Acoustics</h4>
            <RoomSizeSelector
              value={roomSettings.size}
              onChange={(size) => setRoomSettings(prev => ({ ...prev, size }))}
            />
            <SliderControl
              label="Reverb Amount"
              value={roomSettings.reverb}
              min={0}
              max={1}
              step={0.1}
              onChange={(reverb) => setRoomSettings(prev => ({ ...prev, reverb }))}
            />
          </div>
          
          {showVisualizer && (
            <SpatialVisualizer
              participants={participants}
              layoutMode={layoutMode}
              onPositionChange={(id, pos) => 
                spatialEngine.updateParticipantPosition(id, pos)
              }
            />
          )}
          
          <button
            className="visualizer-toggle"
            onClick={() => setShowVisualizer(!showVisualizer)}
          >
            {showVisualizer ? 'Hide' : 'Show'} Spatial Map
          </button>
        </>
      )}
    </div>
  );
}

function SpatialVisualizer({ 
  participants, 
  layoutMode, 
  onPositionChange 
}: {
  participants: Participant[];
  layoutMode: LayoutMode;
  onPositionChange: (id: string, position: Position3D) => void;
}) {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [selectedParticipant, setSelectedParticipant] = useState<string>();
  const [isDragging, setIsDragging] = useState(false);
  
  useEffect(() => {
    if (!canvasRef.current) return;
    
    const canvas = canvasRef.current;
    const ctx = canvas.getContext('2d')!;
    
    // Clear canvas
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    
    // Draw room boundaries
    drawRoom(ctx, canvas.width, canvas.height);
    
    // Draw listener position
    drawListener(ctx, canvas.width / 2, canvas.height / 2);
    
    // Draw participants
    participants.forEach(participant => {
      const pos = participant.spatialPosition || { x: 0, y: 0, z: 0 };
      const screenPos = worldToScreen(pos, canvas.width, canvas.height);
      
      drawParticipant(
        ctx,
        screenPos.x,
        screenPos.y,
        participant,
        selectedParticipant === participant.id
      );
    });
    
    // Draw sound waves for speaking participants
    participants
      .filter(p => p.isSpeaking)
      .forEach(participant => {
        const pos = participant.spatialPosition || { x: 0, y: 0, z: 0 };
        const screenPos = worldToScreen(pos, canvas.width, canvas.height);
        drawSoundWaves(ctx, screenPos.x, screenPos.y);
      });
  }, [participants, selectedParticipant]);
  
  const handleMouseDown = (e: React.MouseEvent) => {
    if (layoutMode !== 'custom') return;
    
    const rect = canvasRef.current!.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    
    // Find participant at position
    const participant = findParticipantAtPosition(x, y, participants);
    if (participant) {
      setSelectedParticipant(participant.id);
      setIsDragging(true);
    }
  };
  
  const handleMouseMove = (e: React.MouseEvent) => {
    if (!isDragging || !selectedParticipant) return;
    
    const rect = canvasRef.current!.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    
    // Convert screen to world coordinates
    const worldPos = screenToWorld(
      { x, y },
      canvasRef.current!.width,
      canvasRef.current!.height
    );
    
    onPositionChange(selectedParticipant, worldPos);
  };
  
  return (
    <div className="spatial-visualizer">
      <canvas
        ref={canvasRef}
        width={300}
        height={300}
        onMouseDown={handleMouseDown}
        onMouseMove={handleMouseMove}
        onMouseUp={() => setIsDragging(false)}
        onMouseLeave={() => setIsDragging(false)}
      />
      
      <div className="visualizer-legend">
        <div className="legend-item">
          <div className="legend-icon listener" />
          <span>You (Listener)</span>
        </div>
        <div className="legend-item">
          <div className="legend-icon participant" />
          <span>Participant</span>
        </div>
        <div className="legend-item">
          <div className="legend-icon speaking" />
          <span>Speaking</span>
        </div>
      </div>
    </div>
  );
}

function drawListener(
  ctx: CanvasRenderingContext2D,
  x: number,
  y: number
) {
  // Draw listener icon (head with ears)
  ctx.fillStyle = '#4299e1';
  ctx.beginPath();
  ctx.arc(x, y, 12, 0, Math.PI * 2);
  ctx.fill();
  
  // Draw direction indicator
  ctx.strokeStyle = '#2b6cb0';
  ctx.lineWidth = 3;
  ctx.beginPath();
  ctx.moveTo(x, y);
  ctx.lineTo(x, y - 20);
  ctx.stroke();
  
  // Draw ears
  ctx.fillStyle = '#4299e1';
  ctx.beginPath();
  ctx.arc(x - 12, y, 4, 0, Math.PI * 2);
  ctx.arc(x + 12, y, 4, 0, Math.PI * 2);
  ctx.fill();
}

function drawParticipant(
  ctx: CanvasRenderingContext2D,
  x: number,
  y: number,
  participant: Participant,
  isSelected: boolean
) {
  const radius = 10;
  
  // Draw selection ring if selected
  if (isSelected) {
    ctx.strokeStyle = '#48bb78';
    ctx.lineWidth = 2;
    ctx.beginPath();
    ctx.arc(x, y, radius + 4, 0, Math.PI * 2);
    ctx.stroke();
  }
  
  // Draw participant circle
  ctx.fillStyle = participant.isSpeaking ? '#f56565' : '#718096';
  ctx.beginPath();
  ctx.arc(x, y, radius, 0, Math.PI * 2);
  ctx.fill();
  
  // Draw name
  ctx.fillStyle = '#2d3748';
  ctx.font = '12px sans-serif';
  ctx.textAlign = 'center';
  ctx.fillText(participant.name, x, y + radius + 15);
}

function drawSoundWaves(
  ctx: CanvasRenderingContext2D,
  x: number,
  y: number
) {
  ctx.strokeStyle = 'rgba(245, 101, 101, 0.3)';
  ctx.lineWidth = 2;
  
  for (let i = 1; i <= 3; i++) {
    ctx.globalAlpha = 1 - (i * 0.3);
    ctx.beginPath();
    ctx.arc(x, y, 10 + (i * 8), 0, Math.PI * 2);
    ctx.stroke();
  }
  
  ctx.globalAlpha = 1;
}
```

### 5. Accessibility Features
```typescript
// Accessibility Manager for Spatial Audio
export class SpatialAccessibilityManager {
  private audioBeacons = new Map<string, AudioBeacon>();
  private spatialCues: boolean = true;
  private verbalAnnouncements: boolean = false;
  
  constructor(
    private spatialEngine: SpatialAudioEngine,
    private tts: TextToSpeech
  ) {}
  
  enableAccessibilityMode(options: AccessibilityOptions) {
    this.spatialCues = options.spatialCues ?? true;
    this.verbalAnnouncements = options.verbalAnnouncements ?? false;
    
    if (options.audioBeacons) {
      this.setupAudioBeacons();
    }
    
    if (options.enhancedSeparation) {
      this.enhanceAudioSeparation();
    }
  }
  
  private setupAudioBeacons() {
    // Create unique audio signatures for each participant
    this.participants.forEach((participant, index) => {
      const beacon = new AudioBeacon({
        frequency: 200 + (index * 50), // Unique frequency
        pattern: this.generateBeaconPattern(index),
        volume: 0.1
      });
      
      this.audioBeacons.set(participant.id, beacon);
    });
  }
  
  private generateBeaconPattern(index: number): BeaconPattern {
    // Create unique rhythmic patterns
    const patterns: BeaconPattern[] = [
      { beeps: 1, duration: 100, interval: 1000 },
      { beeps: 2, duration: 50, interval: 1500 },
      { beeps: 3, duration: 30, interval: 2000 },
      { beeps: 1, duration: 200, interval: 1200 }
    ];
    
    return patterns[index % patterns.length];
  }
  
  private enhanceAudioSeparation() {
    // Apply spectral separation to improve voice distinction
    this.participants.forEach((participant, index) => {
      const eq = this.createPersonalizedEQ(index);
      participant.audioChain.insertEffect(eq);
    });
  }
  
  private createPersonalizedEQ(index: number): BiquadFilterNode {
    const filter = this.audioContext.createBiquadFilter();
    filter.type = 'peaking';
    
    // Assign unique frequency emphasis
    filter.frequency.value = 1000 + (index * 500);
    filter.Q.value = 2;
    filter.gain.value = 3;
    
    return filter;
  }
  
  announceParticipantPosition(
    participantId: string,
    position: Position3D
  ) {
    if (!this.verbalAnnouncements) return;
    
    const participant = this.participants.get(participantId);
    if (!participant) return;
    
    const direction = this.getDirectionDescription(position);
    const distance = this.getDistanceDescription(position);
    
    const announcement = `${participant.name} is ${distance} to your ${direction}`;
    this.tts.speak(announcement);
  }
  
  private getDirectionDescription(position: Position3D): string {
    const angle = Math.atan2(position.x, position.z) * 180 / Math.PI;
    
    if (angle >= -22.5 && angle < 22.5) return 'front';
    if (angle >= 22.5 && angle < 67.5) return 'front right';
    if (angle >= 67.5 && angle < 112.5) return 'right';
    if (angle >= 112.5 && angle < 157.5) return 'back right';
    if (angle >= 157.5 || angle < -157.5) return 'back';
    if (angle >= -157.5 && angle < -112.5) return 'back left';
    if (angle >= -112.5 && angle < -67.5) return 'left';
    return 'front left';
  }
  
  private getDistanceDescription(position: Position3D): string {
    const distance = Math.sqrt(
      position.x ** 2 + position.y ** 2 + position.z ** 2
    );
    
    if (distance < 1) return 'very close';
    if (distance < 3) return 'nearby';
    if (distance < 5) return 'at medium distance';
    return 'far away';
  }
}

// Accessibility Settings UI
export function SpatialAccessibilitySettings() {
  const [settings, setSettings] = useState<AccessibilityOptions>({
    spatialCues: true,
    verbalAnnouncements: false,
    audioBeacons: false,
    enhancedSeparation: false,
    simplifiedMode: false
  });
  
  const accessibilityManager = useAccessibilityManager();
  
  const updateSetting = (key: keyof AccessibilityOptions, value: boolean) => {
    const newSettings = { ...settings, [key]: value };
    setSettings(newSettings);
    accessibilityManager.updateSettings(newSettings);
  };
  
  return (
    <div className="spatial-accessibility-settings">
      <h3>Spatial Audio Accessibility</h3>
      
      <div className="accessibility-options">
        <ToggleOption
          label="Spatial Audio Cues"
          description="Play subtle sounds to indicate participant positions"
          checked={settings.spatialCues}
          onChange={(v) => updateSetting('spatialCues', v)}
        />
        
        <ToggleOption
          label="Verbal Position Announcements"
          description="Announce participant positions when they join or move"
          checked={settings.verbalAnnouncements}
          onChange={(v) => updateSetting('verbalAnnouncements', v)}
        />
        
        <ToggleOption
          label="Audio Beacons"
          description="Assign unique sound signatures to each participant"
          checked={settings.audioBeacons}
          onChange={(v) => updateSetting('audioBeacons', v)}
        />
        
        <ToggleOption
          label="Enhanced Voice Separation"
          description="Apply additional processing to distinguish voices"
          checked={settings.enhancedSeparation}
          onChange={(v) => updateSetting('enhancedSeparation', v)}
        />
        
        <ToggleOption
          label="Simplified Spatial Mode"
          description="Reduce spatial complexity for easier comprehension"
          checked={settings.simplifiedMode}
          onChange={(v) => updateSetting('simplifiedMode', v)}
        />
      </div>
      
      <div className="test-section">
        <h4>Test Spatial Audio</h4>
        <button onClick={() => accessibilityManager.playTestSequence()}>
          Play Test Sequence
        </button>
        <p className="test-description">
          Plays a sound from each participant position to help you understand the spatial layout
        </p>
      </div>
    </div>
  );
}
```

### 6. Performance & Analytics
```typescript
// Spatial Audio Performance Monitor
export class SpatialAudioPerformance {
  private metrics: PerformanceMetrics = {
    processingLatency: [],
    cpuUsage: [],
    spatialAccuracy: [],
    userSatisfaction: []
  };
  
  constructor(
    private analyticsService: AnalyticsService
  ) {
    this.startMonitoring();
  }
  
  private startMonitoring() {
    // Monitor audio processing latency
    setInterval(() => {
      const latency = this.measureProcessingLatency();
      this.metrics.processingLatency.push(latency);
      
      if (latency > 20) { // 20ms threshold
        this.handleHighLatency(latency);
      }
    }, 1000);
    
    // Monitor CPU usage
    if ('performance' in window && 'measureUserAgentSpecificMemory' in performance) {
      this.monitorResourceUsage();
    }
  }
  
  private measureProcessingLatency(): number {
    const start = performance.now();
    
    // Measure actual audio processing time
    // This would be implemented based on your audio pipeline
    
    return performance.now() - start;
  }
  
  private async handleHighLatency(latency: number) {
    // Automatically adjust quality settings
    if (latency > 50) {
      await this.degradeQuality('severe');
    } else if (latency > 30) {
      await this.degradeQuality('moderate');
    }
    
    // Log performance issue
    this.analyticsService.logEvent('spatial_audio_performance', {
      issue: 'high_latency',
      latency,
      timestamp: Date.now()
    });
  }
  
  async generatePerformanceReport(): Promise<PerformanceReport> {
    const avgLatency = this.calculateAverage(this.metrics.processingLatency);
    const p95Latency = this.calculatePercentile(this.metrics.processingLatency, 95);
    
    return {
      summary: {
        averageLatency: avgLatency,
        p95Latency,
        spatialAccuracy: this.calculateSpatialAccuracy(),
        resourceUsage: await this.getResourceUsage()
      },
      recommendations: this.generateRecommendations(),
      timeline: this.generateTimeline()
    };
  }
}

// Spatial Audio Analytics Dashboard
export function SpatialAudioAnalytics() {
  const [analytics, setAnalytics] = useState<SpatialAnalytics>();
  const [timeRange, setTimeRange] = useState<TimeRange>({ days: 7 });
  
  useEffect(() => {
    loadAnalytics();
  }, [timeRange]);
  
  const loadAnalytics = async () => {
    const data = await api.getSpatialAudioAnalytics(timeRange);
    setAnalytics(data);
  };
  
  if (!analytics) return <LoadingSpinner />;
  
  return (
    <div className="spatial-audio-analytics">
      <div className="analytics-header">
        <h2>Spatial Audio Analytics</h2>
        <TimeRangeSelector value={timeRange} onChange={setTimeRange} />
      </div>
      
      <div className="analytics-grid">
        <MetricCard
          title="Avg Processing Latency"
          value={`${analytics.performance.avgLatency.toFixed(1)}ms`}
          trend={analytics.performance.latencyTrend}
          target="< 20ms"
        />
        
        <MetricCard
          title="Spatial Accuracy"
          value={`${(analytics.quality.spatialAccuracy * 100).toFixed(0)}%`}
          trend={analytics.quality.accuracyTrend}
        />
        
        <MetricCard
          title="User Satisfaction"
          value={`${analytics.satisfaction.score.toFixed(1)}/5`}
          trend={analytics.satisfaction.trend}
        />
        
        <MetricCard
          title="Feature Usage"
          value={`${analytics.usage.spatialEnabledPercent}%`}
          subtitle="Users with spatial audio enabled"
        />
      </div>
      
      <div className="analytics-charts">
        <LatencyHistogram data={analytics.performance.latencyDistribution} />
        <LayoutUsageChart data={analytics.usage.layoutModes} />
        <QualityTimelineChart data={analytics.quality.timeline} />
        <UserFeedbackChart data={analytics.satisfaction.feedback} />
      </div>
      
      <div className="insights-section">
        <h3>Insights & Recommendations</h3>
        <InsightsList insights={analytics.insights} />
      </div>
    </div>
  );
}
```

## Dependencies
- Web Audio API for spatial processing
- HRTF database for binaural audio
- Convolution reverb impulse responses
- 3D visualization library (Three.js)
- Audio worklets for custom processing

## Estimated Effort
**5 days**
- 1 day: Core spatial audio engine
- 1 day: Room acoustics simulation
- 1 day: UI components and visualizer
- 1 day: Layout algorithms and positioning
- 1 day: Accessibility features and analytics

## Notes
- Consider head tracking integration for VR/AR
- Add support for ambisonic audio formats
- Implement psychoacoustic masking optimization
- Consider binaural recording playback
- Add spatial audio presets for common scenarios
- Support for external spatial audio hardware
- Implement audio object metadata