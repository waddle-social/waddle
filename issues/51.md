# Issue #51: AI Summaries

## User Story
As a **waddle participant**, I want to **receive AI-generated summaries of conversations** so that **I can quickly catch up on missed discussions and understand key points**.

## Description
Implement AI-powered conversation summaries that automatically generate insights from voice and text conversations. This includes real-time transcription, key point extraction, action item identification, and sentiment analysis to help users stay informed about important discussions they may have missed.

## Acceptance Criteria
- [ ] Real-time voice transcription
- [ ] Automatic summary generation
- [ ] Key point extraction
- [ ] Action item identification
- [ ] Sentiment analysis
- [ ] Multi-language support
- [ ] Privacy-preserving processing
- [ ] Summary customization options

## Technical Implementation

### 1. Transcription Service
```typescript
// Transcription Engine
export interface TranscriptionConfig {
  language: string;
  model: 'whisper-v3' | 'nova-2' | 'auto';
  punctuation: boolean;
  profanityFilter: boolean;
  speakerDiarization: boolean;
  customVocabulary?: string[];
}

export class TranscriptionService {
  private activeTranscriptions = new Map<string, TranscriptionSession>();
  private whisperAPI: WhisperAPI;
  
  constructor(
    private env: Env,
    private analytics: AnalyticsService
  ) {
    this.whisperAPI = new WhisperAPI(env.OPENAI_API_KEY);
  }
  
  async startTranscription(
    channelId: string,
    config: TranscriptionConfig
  ): Promise<TranscriptionSession> {
    const session = new TranscriptionSession({
      channelId,
      config,
      onTranscript: this.handleTranscript.bind(this),
      onError: this.handleError.bind(this)
    });
    
    this.activeTranscriptions.set(channelId, session);
    
    // Initialize audio processing pipeline
    await session.initialize({
      sampleRate: 48000,
      channels: 1,
      encoding: 'opus'
    });
    
    return session;
  }
  
  private async handleTranscript(
    channelId: string,
    transcript: TranscriptSegment
  ) {
    // Store transcript segment
    await this.storeTranscript(channelId, transcript);
    
    // Trigger summary update if needed
    if (transcript.isFinal) {
      await this.triggerSummaryUpdate(channelId);
    }
    
    // Real-time broadcast to participants
    await this.broadcastTranscript(channelId, transcript);
  }
  
  async processAudioChunk(
    channelId: string,
    userId: string,
    audioData: ArrayBuffer
  ): Promise<void> {
    const session = this.activeTranscriptions.get(channelId);
    if (!session) return;
    
    // Add to audio buffer with speaker identification
    await session.addAudioChunk({
      userId,
      timestamp: Date.now(),
      data: audioData
    });
  }
}

// Transcription Session
export class TranscriptionSession {
  private audioBuffer: AudioBuffer;
  private transcriptionQueue: Queue<AudioSegment>;
  private speakerEmbeddings = new Map<string, Float32Array>();
  
  constructor(
    private config: TranscriptionSessionConfig
  ) {
    this.audioBuffer = new RingAudioBuffer(30000); // 30 seconds
    this.transcriptionQueue = new Queue();
    this.startProcessing();
  }
  
  private async startProcessing() {
    while (true) {
      const segment = await this.transcriptionQueue.dequeue();
      if (!segment) continue;
      
      try {
        // Process with Whisper API
        const result = await this.transcribeSegment(segment);
        
        // Apply speaker diarization if enabled
        if (this.config.config.speakerDiarization) {
          await this.applySpeakerDiarization(result);
        }
        
        // Emit transcript
        this.config.onTranscript(this.config.channelId, result);
        
      } catch (error) {
        this.config.onError(error);
      }
    }
  }
  
  private async transcribeSegment(
    segment: AudioSegment
  ): Promise<TranscriptSegment> {
    // Convert audio to required format
    const audioBlob = await this.convertAudio(segment.data);
    
    // Call Whisper API
    const response = await this.whisperAPI.transcribe({
      audio: audioBlob,
      model: this.config.config.model === 'auto' ? 'whisper-1' : this.config.config.model,
      language: this.config.config.language,
      prompt: this.getContextPrompt(),
      temperature: 0.2,
      response_format: 'verbose_json'
    });
    
    return {
      id: generateId(),
      userId: segment.userId,
      text: response.text,
      timestamp: segment.timestamp,
      duration: response.duration,
      language: response.language,
      segments: response.segments,
      confidence: this.calculateConfidence(response),
      isFinal: true
    };
  }
  
  private async applySpeakerDiarization(
    transcript: TranscriptSegment
  ): Promise<void> {
    // Extract speaker embeddings
    const embedding = await this.extractSpeakerEmbedding(transcript.audio);
    
    // Compare with known speakers
    let bestMatch: { userId: string; similarity: number } | null = null;
    
    for (const [userId, knownEmbedding] of this.speakerEmbeddings) {
      const similarity = this.cosineSimilarity(embedding, knownEmbedding);
      if (similarity > 0.85 && (!bestMatch || similarity > bestMatch.similarity)) {
        bestMatch = { userId, similarity };
      }
    }
    
    if (bestMatch) {
      transcript.userId = bestMatch.userId;
    } else {
      // New speaker detected
      this.speakerEmbeddings.set(transcript.userId, embedding);
    }
  }
}
```

### 2. AI Summary Engine
```typescript
// Summary Generator
export class AISummaryEngine {
  private summaryCache = new Map<string, ConversationSummary>();
  private processingQueue = new Queue<SummaryRequest>();
  
  constructor(
    private env: Env,
    private llmService: LLMService,
    private transcriptStore: TranscriptStore
  ) {
    this.startProcessing();
  }
  
  async generateSummary(
    channelId: string,
    options: SummaryOptions = {}
  ): Promise<ConversationSummary> {
    // Check cache
    const cached = this.summaryCache.get(channelId);
    if (cached && !this.isStale(cached, options)) {
      return cached;
    }
    
    // Queue for processing
    const request: SummaryRequest = {
      channelId,
      options,
      priority: options.priority || 'normal'
    };
    
    return await this.processingQueue.enqueue(request);
  }
  
  private async processSummaryRequest(
    request: SummaryRequest
  ): Promise<ConversationSummary> {
    // Fetch transcripts
    const transcripts = await this.transcriptStore.getTranscripts(
      request.channelId,
      request.options.timeRange
    );
    
    if (transcripts.length === 0) {
      return this.createEmptySummary(request.channelId);
    }
    
    // Prepare context
    const context = this.prepareContext(transcripts);
    
    // Generate different summary components in parallel
    const [
      overview,
      keyPoints,
      actionItems,
      sentiment,
      topics
    ] = await Promise.all([
      this.generateOverview(context),
      this.extractKeyPoints(context),
      this.extractActionItems(context),
      this.analyzeSentiment(context),
      this.identifyTopics(context)
    ]);
    
    const summary: ConversationSummary = {
      id: generateId(),
      channelId: request.channelId,
      timestamp: Date.now(),
      timeRange: {
        start: transcripts[0].timestamp,
        end: transcripts[transcripts.length - 1].timestamp
      },
      overview,
      keyPoints,
      actionItems,
      sentiment,
      topics,
      participants: this.extractParticipants(transcripts),
      wordCount: context.split(' ').length,
      language: this.detectPrimaryLanguage(transcripts)
    };
    
    // Cache and persist
    this.summaryCache.set(request.channelId, summary);
    await this.persistSummary(summary);
    
    return summary;
  }
  
  private async generateOverview(context: string): Promise<string> {
    const prompt = `
      Analyze this conversation and provide a concise overview (2-3 sentences) that captures:
      - The main topic or purpose of the discussion
      - Key decisions or outcomes
      - Overall tone and progression
      
      Conversation:
      ${context}
      
      Overview:
    `;
    
    const response = await this.llmService.complete({
      prompt,
      model: 'claude-3-haiku',
      maxTokens: 150,
      temperature: 0.3
    });
    
    return response.text.trim();
  }
  
  private async extractKeyPoints(context: string): Promise<KeyPoint[]> {
    const prompt = `
      Extract the 3-5 most important points from this conversation.
      For each point, provide:
      1. A brief title (5-10 words)
      2. A detailed explanation (1-2 sentences)
      3. The speaker who made this point
      4. Importance level (high/medium/low)
      
      Format as JSON array with structure:
      [{"title": "", "description": "", "speaker": "", "importance": ""}]
      
      Conversation:
      ${context}
      
      Key Points:
    `;
    
    const response = await this.llmService.complete({
      prompt,
      model: 'claude-3-haiku',
      maxTokens: 500,
      temperature: 0.2
    });
    
    try {
      const points = JSON.parse(response.text);
      return points.map((p: any) => ({
        id: generateId(),
        title: p.title,
        description: p.description,
        speaker: p.speaker,
        importance: p.importance as 'high' | 'medium' | 'low',
        timestamp: this.findTimestamp(context, p.description)
      }));
    } catch (error) {
      console.error('Failed to parse key points:', error);
      return [];
    }
  }
  
  private async extractActionItems(context: string): Promise<ActionItem[]> {
    const prompt = `
      Identify any action items, tasks, or commitments made during this conversation.
      For each action item, provide:
      1. Description of the task
      2. Person responsible (if mentioned)
      3. Due date or timeline (if mentioned)
      4. Priority (high/medium/low)
      5. Status (assigned/unassigned)
      
      Format as JSON array with structure:
      [{"task": "", "assignee": "", "dueDate": "", "priority": "", "status": ""}]
      
      Conversation:
      ${context}
      
      Action Items:
    `;
    
    const response = await this.llmService.complete({
      prompt,
      model: 'claude-3-haiku',
      maxTokens: 500,
      temperature: 0.2
    });
    
    try {
      const items = JSON.parse(response.text);
      return items.map((item: any) => ({
        id: generateId(),
        task: item.task,
        assignee: item.assignee || null,
        dueDate: item.dueDate ? new Date(item.dueDate) : null,
        priority: item.priority as 'high' | 'medium' | 'low',
        status: item.status as 'assigned' | 'unassigned',
        createdAt: Date.now()
      }));
    } catch (error) {
      console.error('Failed to parse action items:', error);
      return [];
    }
  }
  
  private async analyzeSentiment(context: string): Promise<SentimentAnalysis> {
    const prompt = `
      Analyze the overall sentiment and emotional tone of this conversation.
      Consider:
      - Overall sentiment (positive/neutral/negative)
      - Emotional progression throughout
      - Any conflicts or tensions
      - Collaboration and agreement levels
      
      Provide scores from 0-100 for:
      - positivity
      - negativity
      - neutrality
      - collaboration
      - tension
      
      Format as JSON: {"overall": "", "positivity": 0, "negativity": 0, "neutrality": 0, "collaboration": 0, "tension": 0}
      
      Conversation:
      ${context}
      
      Sentiment Analysis:
    `;
    
    const response = await this.llmService.complete({
      prompt,
      model: 'claude-3-haiku',
      maxTokens: 200,
      temperature: 0.2
    });
    
    try {
      const analysis = JSON.parse(response.text);
      return {
        overall: analysis.overall as 'positive' | 'neutral' | 'negative',
        scores: {
          positivity: analysis.positivity,
          negativity: analysis.negativity,
          neutrality: analysis.neutrality,
          collaboration: analysis.collaboration,
          tension: analysis.tension
        },
        progression: await this.analyzeSentimentProgression(context)
      };
    } catch (error) {
      console.error('Failed to parse sentiment:', error);
      return this.getDefaultSentiment();
    }
  }
}
```

### 3. Summary UI Components
```tsx
export function ConversationSummary({ channelId }: { channelId: string }) {
  const [summary, setSummary] = useState<ConversationSummary>();
  const [loading, setLoading] = useState(true);
  const [timeRange, setTimeRange] = useState<'last-hour' | 'last-day' | 'all'>('last-hour');
  const [autoRefresh, setAutoRefresh] = useState(true);
  
  useEffect(() => {
    loadSummary();
    
    if (autoRefresh) {
      const interval = setInterval(loadSummary, 60000); // Refresh every minute
      return () => clearInterval(interval);
    }
  }, [channelId, timeRange, autoRefresh]);
  
  const loadSummary = async () => {
    setLoading(true);
    try {
      const data = await api.getConversationSummary(channelId, {
        timeRange: getTimeRangeOptions(timeRange)
      });
      setSummary(data);
    } finally {
      setLoading(false);
    }
  };
  
  if (loading && !summary) return <SummaryLoader />;
  if (!summary) return <EmptySummary />;
  
  return (
    <div className="conversation-summary">
      <div className="summary-header">
        <h3>Conversation Insights</h3>
        <div className="summary-controls">
          <TimeRangeSelector value={timeRange} onChange={setTimeRange} />
          <Toggle
            label="Auto-refresh"
            checked={autoRefresh}
            onChange={setAutoRefresh}
          />
          <Button
            variant="secondary"
            size="sm"
            onClick={loadSummary}
            icon={<RefreshIcon />}
          />
        </div>
      </div>
      
      <div className="summary-overview">
        <p>{summary.overview}</p>
        <div className="summary-meta">
          <span>{summary.participants.length} participants</span>
          <span>{formatDuration(summary.timeRange)}</span>
          <span>{summary.wordCount} words</span>
        </div>
      </div>
      
      <div className="summary-sections">
        <SummarySection title="Key Points" icon={<KeyIcon />}>
          <KeyPointsList points={summary.keyPoints} />
        </SummarySection>
        
        {summary.actionItems.length > 0 && (
          <SummarySection title="Action Items" icon={<TaskIcon />}>
            <ActionItemsList items={summary.actionItems} />
          </SummarySection>
        )}
        
        <SummarySection title="Sentiment" icon={<MoodIcon />}>
          <SentimentDisplay analysis={summary.sentiment} />
        </SummarySection>
        
        <SummarySection title="Topics" icon={<TagIcon />}>
          <TopicCloud topics={summary.topics} />
        </SummarySection>
      </div>
      
      <SummaryActions summary={summary} />
    </div>
  );
}

function KeyPointsList({ points }: { points: KeyPoint[] }) {
  return (
    <div className="key-points-list">
      {points.map(point => (
        <div key={point.id} className={`key-point importance-${point.importance}`}>
          <div className="point-header">
            <h4>{point.title}</h4>
            <ImportanceBadge level={point.importance} />
          </div>
          <p>{point.description}</p>
          <div className="point-meta">
            <span className="speaker">{point.speaker}</span>
            <span className="timestamp">{formatTime(point.timestamp)}</span>
          </div>
        </div>
      ))}
    </div>
  );
}

function ActionItemsList({ items }: { items: ActionItem[] }) {
  const [showCompleted, setShowCompleted] = useState(false);
  
  const visibleItems = items.filter(item => 
    showCompleted || item.status !== 'completed'
  );
  
  return (
    <div className="action-items-list">
      <div className="list-controls">
        <Toggle
          label="Show completed"
          checked={showCompleted}
          onChange={setShowCompleted}
        />
      </div>
      
      {visibleItems.map(item => (
        <ActionItemCard key={item.id} item={item} />
      ))}
      
      {visibleItems.length === 0 && (
        <EmptyState message="No action items to show" />
      )}
    </div>
  );
}

function SentimentDisplay({ analysis }: { analysis: SentimentAnalysis }) {
  return (
    <div className="sentiment-display">
      <div className="sentiment-overall">
        <SentimentIcon sentiment={analysis.overall} />
        <span className={`sentiment-label sentiment-${analysis.overall}`}>
          {analysis.overall}
        </span>
      </div>
      
      <div className="sentiment-scores">
        <ScoreBar label="Positivity" value={analysis.scores.positivity} color="green" />
        <ScoreBar label="Collaboration" value={analysis.scores.collaboration} color="blue" />
        <ScoreBar label="Neutrality" value={analysis.scores.neutrality} color="gray" />
        <ScoreBar label="Tension" value={analysis.scores.tension} color="orange" />
        <ScoreBar label="Negativity" value={analysis.scores.negativity} color="red" />
      </div>
      
      {analysis.progression && (
        <SentimentProgression data={analysis.progression} />
      )}
    </div>
  );
}
```

### 4. Privacy & Security
```typescript
// Privacy-Preserving Processing
export class PrivacySummaryProcessor {
  private encryptionKey: CryptoKey;
  
  constructor(
    private env: Env,
    private privacySettings: PrivacySettings
  ) {}
  
  async processWithPrivacy(
    transcripts: Transcript[],
    userConsents: Map<string, ConsentSettings>
  ): Promise<ProcessedTranscripts> {
    // Filter based on user consent
    const consentedTranscripts = transcripts.filter(t => {
      const consent = userConsents.get(t.userId);
      return consent?.allowAISummaries !== false;
    });
    
    // Anonymize if required
    if (this.privacySettings.anonymizeSpeakers) {
      return this.anonymizeTranscripts(consentedTranscripts);
    }
    
    // Redact sensitive information
    return this.redactSensitiveInfo(consentedTranscripts);
  }
  
  private async anonymizeTranscripts(
    transcripts: Transcript[]
  ): Promise<ProcessedTranscripts> {
    const speakerMap = new Map<string, string>();
    let speakerCount = 0;
    
    return transcripts.map(t => ({
      ...t,
      userId: speakerMap.get(t.userId) || 
        speakerMap.set(t.userId, `Speaker ${++speakerCount}`).get(t.userId)!,
      text: await this.redactPersonalInfo(t.text)
    }));
  }
  
  private async redactSensitiveInfo(text: string): Promise<string> {
    // Redact patterns
    const patterns = [
      // Email addresses
      /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/g,
      // Phone numbers
      /\b\d{3}[-.]?\d{3}[-.]?\d{4}\b/g,
      // Credit card numbers
      /\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b/g,
      // Social security numbers
      /\b\d{3}-\d{2}-\d{4}\b/g
    ];
    
    let redacted = text;
    for (const pattern of patterns) {
      redacted = redacted.replace(pattern, '[REDACTED]');
    }
    
    // Use AI for context-aware redaction
    if (this.privacySettings.aiRedaction) {
      redacted = await this.aiRedact(redacted);
    }
    
    return redacted;
  }
  
  private async aiRedact(text: string): Promise<string> {
    const prompt = `
      Redact any sensitive personal information from this text while preserving meaning.
      Replace with [REDACTED-TYPE] where TYPE describes what was removed.
      Types: NAME, ADDRESS, MEDICAL, FINANCIAL, etc.
      
      Text: ${text}
      
      Redacted:
    `;
    
    const response = await this.llmService.complete({
      prompt,
      model: 'claude-3-haiku',
      maxTokens: text.length * 2,
      temperature: 0.1
    });
    
    return response.text;
  }
}

// Consent Management
export class ConsentManager {
  async getUserConsent(userId: string): Promise<ConsentSettings> {
    const consent = await this.env.USER_CONSENT.get(userId);
    return consent ? JSON.parse(consent) : this.getDefaultConsent();
  }
  
  async updateConsent(
    userId: string,
    settings: Partial<ConsentSettings>
  ): Promise<void> {
    const current = await this.getUserConsent(userId);
    const updated = { ...current, ...settings, lastUpdated: Date.now() };
    
    await this.env.USER_CONSENT.put(userId, JSON.stringify(updated));
    
    // Trigger consent-based actions
    if (!updated.allowAISummaries) {
      await this.removeUserFromSummaries(userId);
    }
  }
}
```

### 5. Real-time Updates
```typescript
// Real-time Summary Updates
export class RealtimeSummaryService {
  private updateThrottler = new Map<string, ThrottleTimer>();
  
  constructor(
    private summaryEngine: AISummaryEngine,
    private websocketService: WebSocketService
  ) {}
  
  async handleNewTranscript(
    channelId: string,
    transcript: Transcript
  ): Promise<void> {
    // Update incremental summary
    await this.updateIncrementalSummary(channelId, transcript);
    
    // Throttled full summary update
    this.scheduleFullUpdate(channelId);
    
    // Broadcast updates
    await this.broadcastUpdate(channelId, {
      type: 'transcript_added',
      transcript
    });
  }
  
  private async updateIncrementalSummary(
    channelId: string,
    transcript: Transcript
  ): Promise<void> {
    // Quick analysis for immediate insights
    const quickInsights = await this.extractQuickInsights(transcript);
    
    if (quickInsights.isImportant) {
      await this.broadcastUpdate(channelId, {
        type: 'important_point',
        insight: quickInsights
      });
    }
    
    // Update running statistics
    await this.updateRunningStats(channelId, transcript);
  }
  
  private scheduleFullUpdate(channelId: string) {
    const throttler = this.updateThrottler.get(channelId) || 
      this.updateThrottler.set(channelId, new ThrottleTimer(30000)).get(channelId)!;
    
    throttler.schedule(async () => {
      const summary = await this.summaryEngine.generateSummary(channelId, {
        incremental: true
      });
      
      await this.broadcastUpdate(channelId, {
        type: 'summary_updated',
        summary
      });
    });
  }
  
  private async extractQuickInsights(
    transcript: Transcript
  ): Promise<QuickInsight> {
    // Check for action item indicators
    const actionIndicators = [
      'I will', 'I\'ll', 'we need to', 'action item',
      'todo', 'by tomorrow', 'deadline', 'assigned to'
    ];
    
    const hasActionItem = actionIndicators.some(indicator => 
      transcript.text.toLowerCase().includes(indicator)
    );
    
    // Check for decision indicators
    const decisionIndicators = [
      'decided', 'agreed', 'let\'s go with', 'final decision',
      'confirmed', 'approved'
    ];
    
    const hasDecision = decisionIndicators.some(indicator =>
      transcript.text.toLowerCase().includes(indicator)
    );
    
    return {
      isImportant: hasActionItem || hasDecision,
      type: hasActionItem ? 'action_item' : hasDecision ? 'decision' : 'general',
      text: transcript.text,
      speaker: transcript.userId,
      timestamp: transcript.timestamp
    };
  }
}

// Summary Export/Share
export function SummaryActions({ summary }: { summary: ConversationSummary }) {
  const [exporting, setExporting] = useState(false);
  const [shareUrl, setShareUrl] = useState<string>();
  
  const exportSummary = async (format: 'pdf' | 'markdown' | 'json') => {
    setExporting(true);
    try {
      const data = await api.exportSummary(summary.id, format);
      downloadFile(data, `summary-${summary.id}.${format}`);
    } finally {
      setExporting(false);
    }
  };
  
  const shareSummary = async () => {
    const url = await api.createSummaryShareLink(summary.id, {
      expiresIn: 7 * 24 * 60 * 60 * 1000 // 7 days
    });
    setShareUrl(url);
  };
  
  return (
    <div className="summary-actions">
      <DropdownMenu>
        <DropdownMenuTrigger asChild>
          <Button variant="outline" disabled={exporting}>
            Export <ChevronDownIcon />
          </Button>
        </DropdownMenuTrigger>
        <DropdownMenuContent>
          <DropdownMenuItem onClick={() => exportSummary('pdf')}>
            Export as PDF
          </DropdownMenuItem>
          <DropdownMenuItem onClick={() => exportSummary('markdown')}>
            Export as Markdown
          </DropdownMenuItem>
          <DropdownMenuItem onClick={() => exportSummary('json')}>
            Export as JSON
          </DropdownMenuItem>
        </DropdownMenuContent>
      </DropdownMenu>
      
      <Button variant="outline" onClick={shareSummary}>
        Share Summary
      </Button>
      
      {shareUrl && (
        <ShareDialog url={shareUrl} onClose={() => setShareUrl(undefined)} />
      )}
    </div>
  );
}
```

### 6. Analytics & Insights
```typescript
// Summary Analytics
export class SummaryAnalytics {
  async trackSummaryUsage(event: SummaryUsageEvent) {
    await this.analytics.track('summary_viewed', {
      summaryId: event.summaryId,
      userId: event.userId,
      viewDuration: event.duration,
      sections: event.sectionsViewed,
      exports: event.exportCount
    });
  }
  
  async generateInsightsReport(
    waddleId: string,
    timeRange: TimeRange
  ): Promise<InsightsReport> {
    const summaries = await this.getSummaries(waddleId, timeRange);
    
    return {
      totalConversations: summaries.length,
      averageLength: this.calculateAverageLength(summaries),
      topTopics: this.extractTopTopics(summaries),
      sentimentTrend: this.analyzeSentimentTrend(summaries),
      participationStats: this.calculateParticipationStats(summaries),
      actionItemsStats: this.analyzeActionItems(summaries),
      peakActivityTimes: this.findPeakTimes(summaries)
    };
  }
  
  private extractTopTopics(summaries: ConversationSummary[]): TopicStats[] {
    const topicCounts = new Map<string, number>();
    
    for (const summary of summaries) {
      for (const topic of summary.topics) {
        topicCounts.set(topic.name, (topicCounts.get(topic.name) || 0) + topic.relevance);
      }
    }
    
    return Array.from(topicCounts.entries())
      .map(([name, score]) => ({ name, score, trend: 'stable' }))
      .sort((a, b) => b.score - a.score)
      .slice(0, 10);
  }
}

// Insights Dashboard
export function InsightsDashboard({ waddleId }: { waddleId: string }) {
  const [insights, setInsights] = useState<InsightsReport>();
  const [timeRange, setTimeRange] = useState<TimeRange>({ days: 7 });
  
  useEffect(() => {
    loadInsights();
  }, [waddleId, timeRange]);
  
  const loadInsights = async () => {
    const data = await api.getWaddleInsights(waddleId, timeRange);
    setInsights(data);
  };
  
  if (!insights) return <LoadingSpinner />;
  
  return (
    <div className="insights-dashboard">
      <div className="insights-header">
        <h2>Conversation Insights</h2>
        <TimeRangePicker value={timeRange} onChange={setTimeRange} />
      </div>
      
      <div className="insights-grid">
        <InsightCard
          title="Total Conversations"
          value={insights.totalConversations}
          trend={insights.conversationTrend}
        />
        
        <InsightCard
          title="Average Length"
          value={formatDuration(insights.averageLength)}
          subtitle="per conversation"
        />
        
        <InsightCard
          title="Action Items"
          value={insights.actionItemsStats.total}
          subtitle={`${insights.actionItemsStats.completed} completed`}
        />
        
        <InsightCard
          title="Overall Sentiment"
          value={insights.sentimentTrend.current}
          trend={insights.sentimentTrend.change}
        />
      </div>
      
      <div className="insights-charts">
        <TopicsChart topics={insights.topTopics} />
        <ActivityHeatmap data={insights.peakActivityTimes} />
        <ParticipationChart stats={insights.participationStats} />
        <SentimentTrendChart data={insights.sentimentTrend.history} />
      </div>
    </div>
  );
}
```

## Dependencies
- OpenAI Whisper API for transcription
- Claude API for summary generation
- WebRTC for audio capture
- D1 for transcript storage
- Cloudflare Workers AI (optional)

## Estimated Effort
**6 days**
- 1 day: Transcription service setup
- 2 days: AI summary engine implementation
- 1 day: Privacy and consent management
- 1 day: Real-time updates system
- 1 day: UI components and analytics

## Notes
- Implement incremental summary updates for efficiency
- Consider offering different summary detail levels
- Add support for multiple languages
- Implement summary search functionality
- Consider edge deployment for lower latency
- Add ability to correct transcription errors
- Implement speaker identification improvements