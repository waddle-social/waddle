# Issue #26: Native Audio Implementation

## User Story
As an **Android user**, I want to **have high-quality voice chat with low latency** so that **I can communicate effectively with other waddle members**.

## Description
Implement native audio capture, processing, and playback for Android using the Android Audio APIs, WebRTC for voice communication, and integration with Cloudflare's RealTimeKit. This includes echo cancellation, noise suppression, and optimal audio routing.

## Acceptance Criteria
- [ ] Low-latency audio capture and playback
- [ ] WebRTC integration for voice chat
- [ ] Echo cancellation and noise suppression
- [ ] Automatic audio routing (speaker/earpiece/bluetooth)
- [ ] Audio focus management
- [ ] Background audio support
- [ ] Bluetooth device handling
- [ ] Audio level monitoring

## Technical Implementation

### 1. Audio Service Architecture
```kotlin
// Core Audio Service
@AndroidEntryPoint
class VoiceService : Service() {
    @Inject lateinit var audioManager: WaddleAudioManager
    @Inject lateinit var webRTCManager: WebRTCManager
    @Inject lateinit var notificationManager: VoiceNotificationManager
    
    private val binder = VoiceBinder()
    private var isInVoiceChannel = false
    
    inner class VoiceBinder : Binder() {
        fun getService(): VoiceService = this@VoiceService
    }
    
    override fun onBind(intent: Intent): IBinder = binder
    
    override fun onCreate() {
        super.onCreate()
        audioManager.initialize()
        startForegroundService()
    }
    
    override fun onStartCommand(intent: Intent?, flags: Int, startId: Int): Int {
        when (intent?.action) {
            ACTION_JOIN_VOICE -> handleJoinVoice(intent)
            ACTION_LEAVE_VOICE -> handleLeaveVoice()
            ACTION_MUTE_TOGGLE -> handleMuteToggle()
            ACTION_DEAFEN_TOGGLE -> handleDeafenToggle()
        }
        
        return START_STICKY
    }
    
    private fun handleJoinVoice(intent: Intent) {
        val channelId = intent.getStringExtra(EXTRA_CHANNEL_ID) ?: return
        val waddleId = intent.getStringExtra(EXTRA_WADDLE_ID) ?: return
        val token = intent.getStringExtra(EXTRA_TOKEN) ?: return
        
        lifecycleScope.launch {
            try {
                // Request audio focus
                audioManager.requestAudioFocus()
                
                // Initialize WebRTC
                webRTCManager.initialize(channelId, token)
                
                // Connect to voice channel
                webRTCManager.connect()
                
                isInVoiceChannel = true
                updateNotification(VoiceState.CONNECTED)
                
            } catch (e: Exception) {
                Log.e(TAG, "Failed to join voice channel", e)
                handleError(e)
            }
        }
    }
    
    private fun startForegroundService() {
        val notification = notificationManager.createVoiceNotification(
            state = VoiceState.CONNECTING,
            channelName = "Voice Channel"
        )
        
        startForeground(NOTIFICATION_ID, notification)
    }
    
    companion object {
        const val ACTION_JOIN_VOICE = "com.waddle.android.action.JOIN_VOICE"
        const val ACTION_LEAVE_VOICE = "com.waddle.android.action.LEAVE_VOICE"
        const val ACTION_MUTE_TOGGLE = "com.waddle.android.action.MUTE_TOGGLE"
        const val ACTION_DEAFEN_TOGGLE = "com.waddle.android.action.DEAFEN_TOGGLE"
    }
}

// Audio Manager
@Singleton
class WaddleAudioManager @Inject constructor(
    @ApplicationContext private val context: Context,
    private val audioDeviceManager: AudioDeviceManager
) {
    private val audioManager = context.getSystemService(Context.AUDIO_SERVICE) as AudioManager
    private var audioFocusRequest: AudioFocusRequest? = null
    private val audioAttributes = AudioAttributes.Builder()
        .setUsage(AudioAttributes.USAGE_VOICE_COMMUNICATION)
        .setContentType(AudioAttributes.CONTENT_TYPE_SPEECH)
        .build()
    
    fun initialize() {
        // Set audio mode for voice communication
        audioManager.mode = AudioManager.MODE_IN_COMMUNICATION
        
        // Register audio device callbacks
        audioDeviceManager.registerCallbacks()
        
        // Configure for low latency
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {
            audioManager.setProperty(
                AudioManager.PROPERTY_OUTPUT_FRAMES_PER_BUFFER,
                "256" // Low latency buffer size
            )
        }
    }
    
    fun requestAudioFocus(): Boolean {
        return if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {
            audioFocusRequest = AudioFocusRequest.Builder(AudioManager.AUDIOFOCUS_GAIN)
                .setAudioAttributes(audioAttributes)
                .setOnAudioFocusChangeListener(audioFocusListener)
                .setWillPauseWhenDucked(false)
                .build()
            
            audioManager.requestAudioFocus(audioFocusRequest!!) == AudioManager.AUDIOFOCUS_REQUEST_GRANTED
        } else {
            @Suppress("DEPRECATION")
            audioManager.requestAudioFocus(
                audioFocusListener,
                AudioManager.STREAM_VOICE_CALL,
                AudioManager.AUDIOFOCUS_GAIN
            ) == AudioManager.AUDIOFOCUS_REQUEST_GRANTED
        }
    }
    
    private val audioFocusListener = AudioManager.OnAudioFocusChangeListener { focusChange ->
        when (focusChange) {
            AudioManager.AUDIOFOCUS_GAIN -> {
                // Resume audio
                resumeAudio()
            }
            AudioManager.AUDIOFOCUS_LOSS -> {
                // Stop audio
                pauseAudio()
            }
            AudioManager.AUDIOFOCUS_LOSS_TRANSIENT -> {
                // Pause temporarily
                pauseAudio()
            }
            AudioManager.AUDIOFOCUS_LOSS_TRANSIENT_CAN_DUCK -> {
                // Lower volume
                duckAudio()
            }
        }
    }
    
    fun setSpeakerphoneOn(on: Boolean) {
        audioManager.isSpeakerphoneOn = on
    }
    
    fun setMicrophoneMute(mute: Boolean) {
        audioManager.isMicrophoneMute = mute
    }
}
```

### 2. WebRTC Implementation
```kotlin
// WebRTC Manager
@Singleton
class WebRTCManager @Inject constructor(
    @ApplicationContext private val context: Context,
    private val signallingClient: SignallingClient,
    private val audioProcessing: AudioProcessingManager
) {
    private var peerConnectionFactory: PeerConnectionFactory? = null
    private var peerConnection: PeerConnection? = null
    private var localAudioTrack: AudioTrack? = null
    private val remoteAudioTracks = mutableMapOf<String, AudioTrack>()
    
    private val eglBase = EglBase.create()
    
    fun initialize(channelId: String, token: String) {
        // Initialize PeerConnectionFactory
        initializePeerConnectionFactory()
        
        // Create peer connection
        createPeerConnection()
        
        // Setup local audio
        setupLocalAudio()
        
        // Connect to signalling
        signallingClient.connect(channelId, token)
    }
    
    private fun initializePeerConnectionFactory() {
        val options = PeerConnectionFactory.InitializationOptions.builder(context)
            .setEnableInternalTracer(BuildConfig.DEBUG)
            .createInitializationOptions()
        
        PeerConnectionFactory.initialize(options)
        
        val audioDeviceModule = createAudioDeviceModule()
        
        peerConnectionFactory = PeerConnectionFactory.builder()
            .setAudioDeviceModule(audioDeviceModule)
            .setAudioProcessingFactory(createAudioProcessingFactory())
            .createPeerConnectionFactory()
    }
    
    private fun createAudioDeviceModule(): AudioDeviceModule {
        return JavaAudioDeviceModule.builder(context)
            .setSamplesReadyCallback { samples ->
                // Process audio samples for level monitoring
                audioProcessing.processSamples(samples)
            }
            .setUseHardwareAcousticEchoCanceler(true)
            .setUseHardwareNoiseSuppressor(true)
            .setAudioRecordErrorCallback(audioRecordErrorCallback)
            .setAudioTrackErrorCallback(audioTrackErrorCallback)
            .createAudioDeviceModule()
    }
    
    private fun createAudioProcessingFactory(): AudioProcessingFactory {
        return AudioProcessingFactory {
            val audioProcessing = AudioProcessing.create()
            
            // Configure echo cancellation
            audioProcessing.setEchoCancellation(true)
            audioProcessing.setEchoCancellationLevel(
                AudioProcessing.EchoCancellation.Level.HIGH
            )
            
            // Configure noise suppression
            audioProcessing.setNoiseSuppression(true)
            audioProcessing.setNoiseSuppressionLevel(
                AudioProcessing.NoiseSuppression.Level.HIGH
            )
            
            // Configure automatic gain control
            audioProcessing.setAutoGainControl(true)
            audioProcessing.setAutoGainControlLevel(
                AudioProcessing.AutoGainControl.Level.HIGH
            )
            
            // Configure voice detection
            audioProcessing.setVoiceDetection(true)
            
            audioProcessing
        }
    }
    
    private fun setupLocalAudio() {
        val audioSource = peerConnectionFactory?.createAudioSource(createAudioConstraints())
        localAudioTrack = peerConnectionFactory?.createAudioTrack(AUDIO_TRACK_ID, audioSource)
        
        // Add to peer connection
        val stream = peerConnectionFactory?.createLocalMediaStream(LOCAL_STREAM_ID)
        stream?.addTrack(localAudioTrack)
        peerConnection?.addStream(stream)
    }
    
    private fun createAudioConstraints(): MediaConstraints {
        return MediaConstraints().apply {
            // Mandatory constraints
            mandatory.add(MediaConstraints.KeyValuePair("googEchoCancellation", "true"))
            mandatory.add(MediaConstraints.KeyValuePair("googAutoGainControl", "true"))
            mandatory.add(MediaConstraints.KeyValuePair("googNoiseSuppression", "true"))
            mandatory.add(MediaConstraints.KeyValuePair("googHighpassFilter", "true"))
            
            // Optional constraints
            optional.add(MediaConstraints.KeyValuePair("googAudioMirroring", "false"))
            optional.add(MediaConstraints.KeyValuePair("googTypingNoiseDetection", "true"))
        }
    }
    
    private fun createPeerConnection() {
        val iceServers = listOf(
            PeerConnection.IceServer.builder("stun:stun.waddle.chat:3478").createIceServer(),
            PeerConnection.IceServer.builder("turn:turn.waddle.chat:3478")
                .setUsername("waddle")
                .setPassword(getTurnCredentials())
                .createIceServer()
        )
        
        val rtcConfig = PeerConnection.RTCConfiguration(iceServers).apply {
            bundlePolicy = PeerConnection.BundlePolicy.MAXBUNDLE
            rtcpMuxPolicy = PeerConnection.RtcpMuxPolicy.REQUIRE
            tcpCandidatePolicy = PeerConnection.TcpCandidatePolicy.DISABLED
            candidateNetworkPolicy = PeerConnection.CandidateNetworkPolicy.ALL
            continualGatheringPolicy = PeerConnection.ContinualGatheringPolicy.GATHER_CONTINUALLY
            audioJitterBufferMaxPackets = 50
            audioJitterBufferFastAccelerate = true
            iceConnectionReceivingTimeout = 5000
            enableDtlsSrtp = true
        }
        
        peerConnection = peerConnectionFactory?.createPeerConnection(
            rtcConfig,
            peerConnectionObserver
        )
    }
    
    private val peerConnectionObserver = object : PeerConnection.Observer {
        override fun onIceCandidate(candidate: IceCandidate) {
            // Send ICE candidate to remote peer
            signallingClient.sendIceCandidate(candidate)
        }
        
        override fun onIceConnectionChange(state: PeerConnection.IceConnectionState) {
            when (state) {
                PeerConnection.IceConnectionState.CONNECTED -> {
                    onConnected()
                }
                PeerConnection.IceConnectionState.DISCONNECTED -> {
                    onDisconnected()
                }
                PeerConnection.IceConnectionState.FAILED -> {
                    onConnectionFailed()
                }
                else -> {}
            }
        }
        
        override fun onAddStream(stream: MediaStream) {
            // Handle remote audio stream
            stream.audioTracks.forEach { track ->
                remoteAudioTracks[track.id()] = track
                onRemoteAudioTrackAdded(track)
            }
        }
        
        override fun onRemoveStream(stream: MediaStream) {
            // Handle stream removal
            stream.audioTracks.forEach { track ->
                remoteAudioTracks.remove(track.id())
                onRemoteAudioTrackRemoved(track)
            }
        }
        
        // Other observer methods...
    }
}
```

### 3. Audio Processing
```kotlin
// Audio Processing Manager
@Singleton
class AudioProcessingManager @Inject constructor() {
    private val audioLevelListeners = mutableSetOf<AudioLevelListener>()
    private val voiceDetectionListeners = mutableSetOf<VoiceDetectionListener>()
    
    private val audioBuffer = ShortArray(BUFFER_SIZE)
    private var bufferPosition = 0
    
    fun processSamples(samples: AudioSamples) {
        // Copy samples to buffer
        val data = samples.data
        val length = samples.length
        
        synchronized(audioBuffer) {
            for (i in 0 until length) {
                audioBuffer[bufferPosition] = data[i]
                bufferPosition = (bufferPosition + 1) % BUFFER_SIZE
                
                // Process when buffer is full
                if (bufferPosition == 0) {
                    processAudioBuffer()
                }
            }
        }
    }
    
    private fun processAudioBuffer() {
        // Calculate RMS level
        val rms = calculateRMS(audioBuffer)
        val dbLevel = 20 * log10(rms.toDouble())
        
        // Notify level listeners
        audioLevelListeners.forEach { listener ->
            listener.onAudioLevel(dbLevel.toFloat())
        }
        
        // Voice activity detection
        val isVoiceDetected = detectVoiceActivity(audioBuffer, rms)
        voiceDetectionListeners.forEach { listener ->
            listener.onVoiceDetected(isVoiceDetected)
        }
    }
    
    private fun calculateRMS(buffer: ShortArray): Float {
        var sum = 0.0
        for (sample in buffer) {
            sum += sample * sample
        }
        return sqrt(sum / buffer.size).toFloat()
    }
    
    private fun detectVoiceActivity(buffer: ShortArray, rms: Float): Boolean {
        // Simple VAD based on energy and zero-crossing rate
        if (rms < VOICE_THRESHOLD) return false
        
        var zeroCrossings = 0
        for (i in 1 until buffer.size) {
            if ((buffer[i] >= 0) != (buffer[i - 1] >= 0)) {
                zeroCrossings++
            }
        }
        
        val zeroCrossingRate = zeroCrossings.toFloat() / buffer.size
        return zeroCrossingRate > MIN_ZCR && zeroCrossingRate < MAX_ZCR
    }
    
    companion object {
        private const val BUFFER_SIZE = 2048
        private const val VOICE_THRESHOLD = 0.01f
        private const val MIN_ZCR = 0.1f
        private const val MAX_ZCR = 0.5f
    }
}

// Audio Device Manager
@Singleton
class AudioDeviceManager @Inject constructor(
    @ApplicationContext private val context: Context
) {
    private val audioManager = context.getSystemService(Context.AUDIO_SERVICE) as AudioManager
    private val bluetoothAdapter = BluetoothAdapter.getDefaultAdapter()
    private val callbacks = mutableSetOf<AudioDeviceCallback>()
    
    private val bluetoothReceiver = object : BroadcastReceiver() {
        override fun onReceive(context: Context, intent: Intent) {
            when (intent.action) {
                BluetoothHeadset.ACTION_CONNECTION_STATE_CHANGED -> {
                    handleBluetoothConnectionChange(intent)
                }
                AudioManager.ACTION_HEADSET_PLUG -> {
                    handleWiredHeadsetChange(intent)
                }
            }
        }
    }
    
    fun registerCallbacks() {
        // Register for audio device changes
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {
            audioManager.registerAudioDeviceCallback(audioDeviceCallback, null)
        }
        
        // Register for bluetooth changes
        val bluetoothFilter = IntentFilter().apply {
            addAction(BluetoothHeadset.ACTION_CONNECTION_STATE_CHANGED)
            addAction(AudioManager.ACTION_HEADSET_PLUG)
        }
        context.registerReceiver(bluetoothReceiver, bluetoothFilter)
    }
    
    @RequiresApi(Build.VERSION_CODES.M)
    private val audioDeviceCallback = object : AudioDeviceCallback() {
        override fun onAudioDevicesAdded(addedDevices: Array<out AudioDeviceInfo>) {
            addedDevices.forEach { device ->
                when (device.type) {
                    AudioDeviceInfo.TYPE_BLUETOOTH_A2DP,
                    AudioDeviceInfo.TYPE_BLUETOOTH_SCO -> {
                        notifyBluetoothConnected(device)
                    }
                    AudioDeviceInfo.TYPE_WIRED_HEADSET,
                    AudioDeviceInfo.TYPE_WIRED_HEADPHONES -> {
                        notifyWiredHeadsetConnected(device)
                    }
                }
            }
        }
        
        override fun onAudioDevicesRemoved(removedDevices: Array<out AudioDeviceInfo>) {
            removedDevices.forEach { device ->
                notifyDeviceRemoved(device)
            }
        }
    }
    
    fun getAvailableAudioDevices(): List<AudioDevice> {
        val devices = mutableListOf<AudioDevice>()
        
        // Add built-in devices
        devices.add(AudioDevice(
            id = "speaker",
            name = "Speaker",
            type = AudioDeviceType.SPEAKER,
            isConnected = true
        ))
        
        devices.add(AudioDevice(
            id = "earpiece",
            name = "Earpiece",
            type = AudioDeviceType.EARPIECE,
            isConnected = true
        ))
        
        // Add connected devices
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M) {
            audioManager.getDevices(AudioManager.GET_DEVICES_OUTPUTS).forEach { device ->
                devices.add(AudioDevice(
                    id = device.id.toString(),
                    name = device.productName.toString(),
                    type = mapDeviceType(device.type),
                    isConnected = true
                ))
            }
        }
        
        return devices
    }
    
    fun selectAudioDevice(device: AudioDevice) {
        when (device.type) {
            AudioDeviceType.SPEAKER -> {
                audioManager.isSpeakerphoneOn = true
                audioManager.isBluetoothScoOn = false
            }
            AudioDeviceType.EARPIECE -> {
                audioManager.isSpeakerphoneOn = false
                audioManager.isBluetoothScoOn = false
            }
            AudioDeviceType.BLUETOOTH -> {
                audioManager.isSpeakerphoneOn = false
                startBluetoothSco()
            }
            AudioDeviceType.WIRED_HEADSET -> {
                audioManager.isSpeakerphoneOn = false
                audioManager.isBluetoothScoOn = false
            }
        }
    }
    
    private fun startBluetoothSco() {
        if (audioManager.isBluetoothScoAvailableOffCall) {
            audioManager.startBluetoothSco()
            audioManager.isBluetoothScoOn = true
        }
    }
}
```

### 4. Voice Activity UI
```kotlin
// Voice Channel Screen
@Composable
fun VoiceChannelScreen(
    waddleId: String,
    channelId: String,
    viewModel: VoiceChannelViewModel = hiltViewModel()
) {
    val state by viewModel.uiState.collectAsState()
    
    LaunchedEffect(channelId) {
        viewModel.joinVoiceChannel(waddleId, channelId)
    }
    
    DisposableEffect(channelId) {
        onDispose {
            viewModel.leaveVoiceChannel()
        }
    }
    
    Scaffold(
        topBar = {
            VoiceChannelTopBar(
                channelName = state.channelName,
                connectionState = state.connectionState,
                onNavigateBack = { viewModel.leaveVoiceChannel() }
            )
        },
        bottomBar = {
            VoiceControls(
                isMuted = state.isMuted,
                isDeafened = state.isDeafened,
                onMuteToggle = { viewModel.toggleMute() },
                onDeafenToggle = { viewModel.toggleDeafen() },
                onLeave = { viewModel.leaveVoiceChannel() }
            )
        }
    ) { paddingValues ->
        Column(
            modifier = Modifier
                .fillMaxSize()
                .padding(paddingValues)
        ) {
            // Connection state
            AnimatedVisibility(visible = state.connectionState != ConnectionState.CONNECTED) {
                ConnectionStateBar(state = state.connectionState)
            }
            
            // Participants grid
            LazyVerticalGrid(
                columns = GridCells.Adaptive(minSize = 120.dp),
                contentPadding = PaddingValues(16.dp),
                horizontalArrangement = Arrangement.spacedBy(8.dp),
                verticalArrangement = Arrangement.spacedBy(8.dp)
            ) {
                items(state.participants) { participant ->
                    VoiceParticipantCard(
                        participant = participant,
                        isSpeaking = state.speakingParticipants.contains(participant.id)
                    )
                }
            }
        }
    }
}

@Composable
fun VoiceParticipantCard(
    participant: VoiceParticipant,
    isSpeaking: Boolean
) {
    Card(
        modifier = Modifier
            .fillMaxWidth()
            .aspectRatio(1f),
        colors = CardDefaults.cardColors(
            containerColor = if (isSpeaking) {
                MaterialTheme.colorScheme.primaryContainer
            } else {
                MaterialTheme.colorScheme.surface
            }
        ),
        border = if (isSpeaking) {
            BorderStroke(2.dp, MaterialTheme.colorScheme.primary)
        } else null
    ) {
        Column(
            modifier = Modifier
                .fillMaxSize()
                .padding(8.dp),
            horizontalAlignment = Alignment.CenterHorizontally,
            verticalArrangement = Arrangement.Center
        ) {
            Box {
                AsyncImage(
                    model = participant.avatarUrl,
                    contentDescription = participant.username,
                    modifier = Modifier
                        .size(64.dp)
                        .clip(CircleShape),
                    contentScale = ContentScale.Crop
                )
                
                // Speaking indicator
                if (isSpeaking) {
                    Box(
                        modifier = Modifier
                            .align(Alignment.BottomEnd)
                            .size(24.dp)
                            .background(
                                MaterialTheme.colorScheme.primary,
                                CircleShape
                            ),
                        contentAlignment = Alignment.Center
                    ) {
                        Icon(
                            imageVector = Icons.Default.Mic,
                            contentDescription = "Speaking",
                            modifier = Modifier.size(16.dp),
                            tint = MaterialTheme.colorScheme.onPrimary
                        )
                    }
                }
            }
            
            Spacer(modifier = Modifier.height(8.dp))
            
            Text(
                text = participant.username,
                style = MaterialTheme.typography.bodySmall,
                maxLines = 1,
                overflow = TextOverflow.Ellipsis
            )
            
            // Status icons
            Row(
                horizontalArrangement = Arrangement.spacedBy(4.dp)
            ) {
                if (participant.isMuted) {
                    Icon(
                        imageVector = Icons.Default.MicOff,
                        contentDescription = "Muted",
                        modifier = Modifier.size(16.dp),
                        tint = MaterialTheme.colorScheme.error
                    )
                }
                if (participant.isDeafened) {
                    Icon(
                        imageVector = Icons.Default.VolumeOff,
                        contentDescription = "Deafened",
                        modifier = Modifier.size(16.dp),
                        tint = MaterialTheme.colorScheme.error
                    )
                }
            }
        }
    }
}

@Composable
fun VoiceControls(
    isMuted: Boolean,
    isDeafened: Boolean,
    onMuteToggle: () -> Unit,
    onDeafenToggle: () -> Unit,
    onLeave: () -> Unit
) {
    Surface(
        color = MaterialTheme.colorScheme.surfaceVariant,
        tonalElevation = 3.dp
    ) {
        Row(
            modifier = Modifier
                .fillMaxWidth()
                .padding(16.dp),
            horizontalArrangement = Arrangement.SpaceEvenly
        ) {
            // Mute button
            FilledTonalIconButton(
                onClick = onMuteToggle,
                colors = IconButtonDefaults.filledTonalIconButtonColors(
                    containerColor = if (isMuted) {
                        MaterialTheme.colorScheme.error
                    } else {
                        MaterialTheme.colorScheme.primaryContainer
                    }
                )
            ) {
                Icon(
                    imageVector = if (isMuted) Icons.Default.MicOff else Icons.Default.Mic,
                    contentDescription = if (isMuted) "Unmute" else "Mute"
                )
            }
            
            // Deafen button
            FilledTonalIconButton(
                onClick = onDeafenToggle,
                colors = IconButtonDefaults.filledTonalIconButtonColors(
                    containerColor = if (isDeafened) {
                        MaterialTheme.colorScheme.error
                    } else {
                        MaterialTheme.colorScheme.primaryContainer
                    }
                )
            ) {
                Icon(
                    imageVector = if (isDeafened) Icons.Default.VolumeOff else Icons.Default.VolumeUp,
                    contentDescription = if (isDeafened) "Undeafen" else "Deafen"
                )
            }
            
            // Leave button
            FilledTonalIconButton(
                onClick = onLeave,
                colors = IconButtonDefaults.filledTonalIconButtonColors(
                    containerColor = MaterialTheme.colorScheme.error
                )
            ) {
                Icon(
                    imageVector = Icons.Default.CallEnd,
                    contentDescription = "Leave voice channel"
                )
            }
        }
    }
}
```

### 5. Background Service Management
```kotlin
// Voice Service Connection
class VoiceServiceConnection @Inject constructor(
    @ApplicationContext private val context: Context
) {
    private var service: VoiceService? = null
    private var bound = false
    
    private val connection = object : ServiceConnection {
        override fun onServiceConnected(name: ComponentName, binder: IBinder) {
            val voiceBinder = binder as VoiceService.VoiceBinder
            service = voiceBinder.getService()
            bound = true
            serviceCallbacks.forEach { it.onServiceConnected(service!!) }
        }
        
        override fun onServiceDisconnected(name: ComponentName) {
            service = null
            bound = false
            serviceCallbacks.forEach { it.onServiceDisconnected() }
        }
    }
    
    fun bindService() {
        Intent(context, VoiceService::class.java).also { intent ->
            context.bindService(intent, connection, Context.BIND_AUTO_CREATE)
        }
    }
    
    fun unbindService() {
        if (bound) {
            context.unbindService(connection)
            bound = false
        }
    }
    
    fun startVoiceService(channelId: String, waddleId: String, token: String) {
        val intent = Intent(context, VoiceService::class.java).apply {
            action = VoiceService.ACTION_JOIN_VOICE
            putExtra(VoiceService.EXTRA_CHANNEL_ID, channelId)
            putExtra(VoiceService.EXTRA_WADDLE_ID, waddleId)
            putExtra(VoiceService.EXTRA_TOKEN, token)
        }
        
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {
            context.startForegroundService(intent)
        } else {
            context.startService(intent)
        }
    }
}

// Voice Notification Manager
@Singleton
class VoiceNotificationManager @Inject constructor(
    @ApplicationContext private val context: Context
) {
    fun createVoiceNotification(
        state: VoiceState,
        channelName: String
    ): Notification {
        createNotificationChannel()
        
        val builder = NotificationCompat.Builder(context, CHANNEL_ID)
            .setSmallIcon(R.drawable.ic_voice_chat)
            .setContentTitle("Waddle Voice")
            .setContentText("Connected to $channelName")
            .setPriority(NotificationCompat.PRIORITY_HIGH)
            .setCategory(NotificationCompat.CATEGORY_CALL)
            .setOngoing(true)
            .setShowWhen(false)
            .setVisibility(NotificationCompat.VISIBILITY_PUBLIC)
            
        // Add actions
        builder.addAction(createMuteAction())
        builder.addAction(createDeafenAction())
        builder.addAction(createLeaveAction())
        
        // Set color based on state
        when (state) {
            VoiceState.CONNECTING -> builder.setColor(Color.YELLOW)
            VoiceState.CONNECTED -> builder.setColor(Color.GREEN)
            VoiceState.ERROR -> builder.setColor(Color.RED)
        }
        
        return builder.build()
    }
    
    private fun createNotificationChannel() {
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.O) {
            val channel = NotificationChannel(
                CHANNEL_ID,
                "Voice Chat",
                NotificationManager.IMPORTANCE_HIGH
            ).apply {
                description = "Active voice chat notifications"
                setSound(null, null)
                enableVibration(false)
            }
            
            val notificationManager = context.getSystemService(NotificationManager::class.java)
            notificationManager.createNotificationChannel(channel)
        }
    }
    
    companion object {
        private const val CHANNEL_ID = "waddle_voice_channel"
    }
}
```

## Dependencies
- WebRTC Android SDK
- Android Audio APIs
- Kotlin Coroutines
- Hilt for DI
- Jetpack Compose for UI

## Estimated Effort
**5 days**
- 1 day: Audio service architecture
- 1 day: WebRTC integration
- 1 day: Audio processing and device management
- 1 day: UI implementation
- 1 day: Background service and notifications

## Notes
- Test on various Android devices
- Handle audio routing edge cases
- Implement proper error recovery
- Monitor battery usage
- Add audio quality settings