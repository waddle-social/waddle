# Issue #43: Stream Recording

## User Story
As a **content creator or waddle owner**, I want to **record voice streams and broadcasts for later playback** so that **absent members can catch up and valuable content can be preserved and shared**.

## Description
Implement a comprehensive recording system for voice streams and broadcasts, including automatic and manual recording options, cloud storage, post-processing capabilities, and playback features. The system should handle long-duration recordings efficiently and provide tools for editing and sharing recorded content.

## Acceptance Criteria
- [ ] Automatic and manual recording options
- [ ] Cloud storage with retention policies
- [ ] Multi-track audio recording
- [ ] Recording quality settings
- [ ] Post-processing and editing tools
- [ ] Playback with seeking and speed control
- [ ] Recording management dashboard
- [ ] Export and sharing capabilities

## Technical Implementation

### 1. Recording Infrastructure
```typescript
// Core recording system
export interface RecordingConfig {
  format: 'webm' | 'mp4' | 'mp3' | 'flac';
  quality: 'low' | 'medium' | 'high' | 'lossless';
  multitrack: boolean;
  includeVideo: boolean;
  includeTranscription: boolean;
  maxDuration?: number; // seconds
  autoSplit?: boolean; // Split into chunks
  splitDuration?: number; // seconds per chunk
}

export class StreamRecorder {
  private activeRecordings = new Map<string, RecordingSession>();
  private mediaRecorders = new Map<string, MediaRecorder>();
  private audioProcessors = new Map<string, AudioProcessor>();
  
  constructor(
    private storage: CloudStorage,
    private transcoding: TranscodingService,
    private analytics: AnalyticsService
  ) {}
  
  async startRecording(
    streamId: string,
    config: RecordingConfig
  ): Promise<RecordingSession> {
    // Check if already recording
    if (this.activeRecordings.has(streamId)) {
      throw new Error('Stream is already being recorded');
    }
    
    // Validate storage quota
    const quota = await this.storage.checkQuota();
    if (quota.remaining < this.estimateRecordingSize(config)) {
      throw new Error('Insufficient storage quota');
    }
    
    // Create recording session
    const session: RecordingSession = {
      id: crypto.randomUUID(),
      streamId,
      config,
      startTime: Date.now(),
      state: 'recording',
      tracks: new Map(),
      segments: [],
      metadata: {
        title: `Recording ${new Date().toISOString()}`,
        description: '',
        participants: []
      }
    };
    
    // Initialize recording based on config
    if (config.multitrack) {
      await this.initializeMultitrackRecording(session);
    } else {
      await this.initializeSingleTrackRecording(session);
    }
    
    // Store session
    this.activeRecordings.set(streamId, session);
    
    // Start monitoring
    this.startRecordingMonitoring(session);
    
    // Track recording start
    await this.analytics.track('recording_started', {
      recordingId: session.id,
      streamId,
      format: config.format,
      quality: config.quality,
      multitrack: config.multitrack
    });
    
    return session;
  }
  
  private async initializeMultitrackRecording(
    session: RecordingSession
  ) {
    // Create audio processor for mixing
    const processor = new AudioProcessor({
      sampleRate: 48000,
      channels: 2,
      bitDepth: 24
    });
    
    this.audioProcessors.set(session.id, processor);
    
    // Set up individual track recorders
    processor.on('track', async (track: ProcessedTrack) => {
      const trackRecorder = await this.createTrackRecorder(
        track,
        session.config
      );
      
      session.tracks.set(track.id, {
        id: track.id,
        participantId: track.participantId,
        recorder: trackRecorder,
        startTime: Date.now(),
        size: 0
      });
    });
    
    // Set up master mix recorder
    const masterStream = processor.getMasterOutput();
    const masterRecorder = await this.createMediaRecorder(
      masterStream,
      session.config
    );
    
    this.setupRecorderHandlers(masterRecorder, session, 'master');
    masterRecorder.start(1000); // 1 second chunks
    
    session.masterRecorder = masterRecorder;
  }
  
  private async initializeSingleTrackRecording(
    session: RecordingSession
  ) {
    // Get stream audio
    const stream = await this.getStreamAudio(session.streamId);
    
    // Create media recorder
    const recorder = await this.createMediaRecorder(stream, session.config);
    
    this.setupRecorderHandlers(recorder, session, 'single');
    
    // Start recording
    recorder.start(1000); // 1 second chunks
    
    this.mediaRecorders.set(session.id, recorder);
  }
  
  private async createMediaRecorder(
    stream: MediaStream,
    config: RecordingConfig
  ): Promise<MediaRecorder> {
    const mimeType = this.getMimeType(config.format, config.quality);
    const bitrate = this.getBitrate(config.quality);
    
    // Check codec support
    if (!MediaRecorder.isTypeSupported(mimeType)) {
      throw new Error(`Format ${config.format} is not supported`);
    }
    
    const recorder = new MediaRecorder(stream, {
      mimeType,
      audioBitsPerSecond: bitrate,
      videoBitsPerSecond: config.includeVideo ? bitrate * 10 : undefined
    });
    
    return recorder;
  }
  
  private setupRecorderHandlers(
    recorder: MediaRecorder,
    session: RecordingSession,
    trackId: string
  ) {
    const chunks: Blob[] = [];
    let segmentIndex = 0;
    let segmentSize = 0;
    
    recorder.ondataavailable = async (event) => {
      if (event.data.size > 0) {
        chunks.push(event.data);
        segmentSize += event.data.size;
        
        // Check if we should save a segment
        const shouldSave = session.config.autoSplit && 
          (chunks.length >= session.config.splitDuration! || 
           segmentSize >= 100 * 1024 * 1024); // 100MB
        
        if (shouldSave) {
          await this.saveSegment(
            session,
            trackId,
            chunks.slice(),
            segmentIndex++
          );
          chunks.length = 0;
          segmentSize = 0;
        }
      }
    };
    
    recorder.onstop = async () => {
      // Save final segment
      if (chunks.length > 0) {
        await this.saveSegment(
          session,
          trackId,
          chunks,
          segmentIndex
        );
      }
    };
    
    recorder.onerror = (error) => {
      console.error('Recording error:', error);
      this.handleRecordingError(session, error);
    };
  }
  
  private async saveSegment(
    session: RecordingSession,
    trackId: string,
    chunks: Blob[],
    index: number
  ) {
    const blob = new Blob(chunks, {
      type: this.getMimeType(session.config.format, session.config.quality)
    });
    
    // Generate segment key
    const key = `recordings/${session.id}/${trackId}/segment-${index}.${session.config.format}`;
    
    // Upload to storage
    const upload = await this.storage.upload(key, blob, {
      metadata: {
        recordingId: session.id,
        trackId,
        segmentIndex: index,
        duration: chunks.length * 1000, // Approximate
        size: blob.size
      }
    });
    
    // Update session
    session.segments.push({
      id: crypto.randomUUID(),
      trackId,
      index,
      url: upload.url,
      size: blob.size,
      duration: chunks.length * 1000,
      timestamp: Date.now()
    });
    
    // Update total size
    if (session.tracks.has(trackId)) {
      session.tracks.get(trackId)!.size += blob.size;
    }
  }
  
  async stopRecording(
    streamId: string,
    reason: string = 'manual'
  ): Promise<Recording> {
    const session = this.activeRecordings.get(streamId);
    if (!session) {
      throw new Error('No active recording found');
    }
    
    console.log(`Stopping recording for stream ${streamId}: ${reason}`);
    
    // Stop all recorders
    if (session.masterRecorder) {
      session.masterRecorder.stop();
    }
    
    for (const track of session.tracks.values()) {
      if (track.recorder && track.recorder.state !== 'inactive') {
        track.recorder.stop();
      }
    }
    
    const mediaRecorder = this.mediaRecorders.get(session.id);
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
      mediaRecorder.stop();
    }
    
    // Update session state
    session.state = 'processing';
    session.endTime = Date.now();
    session.stopReason = reason;
    
    // Process recording
    const recording = await this.processRecording(session);
    
    // Cleanup
    this.activeRecordings.delete(streamId);
    this.mediaRecorders.delete(session.id);
    this.audioProcessors.delete(session.id);
    
    // Track recording completion
    await this.analytics.track('recording_stopped', {
      recordingId: session.id,
      streamId,
      duration: session.endTime - session.startTime,
      reason,
      segmentCount: session.segments.length,
      totalSize: this.calculateTotalSize(session)
    });
    
    return recording;
  }
  
  private async processRecording(
    session: RecordingSession
  ): Promise<Recording> {
    try {
      // Concatenate segments if needed
      let files: RecordingFile[] = [];
      
      if (session.config.autoSplit) {
        files = await this.concatenateSegments(session);
      } else {
        files = this.getRecordingFiles(session);
      }
      
      // Generate metadata
      const metadata = await this.generateMetadata(session);
      
      // Create thumbnails/waveforms
      const visualizations = await this.generateVisualizations(files[0]);
      
      // Transcode if needed
      if (this.needsTranscoding(session.config)) {
        files = await this.transcodeRecording(files, session.config);
      }
      
      // Create recording entry
      const recording: Recording = {
        id: session.id,
        streamId: session.streamId,
        title: metadata.title,
        description: metadata.description,
        duration: session.endTime! - session.startTime,
        size: this.calculateTotalSize(session),
        format: session.config.format,
        quality: session.config.quality,
        files,
        metadata,
        visualizations,
        createdAt: session.startTime,
        state: 'completed',
        permissions: {
          public: false,
          downloadable: true,
          editable: true
        }
      };
      
      // Store recording metadata
      await this.storage.saveRecordingMetadata(recording);
      
      // Start transcription if enabled
      if (session.config.includeTranscription) {
        this.startTranscription(recording);
      }
      
      return recording;
      
    } catch (error) {
      console.error('Recording processing failed:', error);
      session.state = 'failed';
      session.error = error.message;
      throw error;
    }
  }
  
  private async concatenateSegments(
    session: RecordingSession
  ): Promise<RecordingFile[]> {
    const filesByTrack = new Map<string, RecordingSegment[]>();
    
    // Group segments by track
    for (const segment of session.segments) {
      const segments = filesByTrack.get(segment.trackId) || [];
      segments.push(segment);
      filesByTrack.set(segment.trackId, segments);
    }
    
    const files: RecordingFile[] = [];
    
    // Concatenate each track
    for (const [trackId, segments] of filesByTrack) {
      const sortedSegments = segments.sort((a, b) => a.index - b.index);
      
      const concatenated = await this.transcoding.concatenate({
        inputs: sortedSegments.map(s => s.url),
        format: session.config.format,
        outputKey: `recordings/${session.id}/${trackId}/complete.${session.config.format}`
      });
      
      files.push({
        id: crypto.randomUUID(),
        trackId,
        url: concatenated.url,
        size: concatenated.size,
        duration: concatenated.duration,
        format: session.config.format
      });
    }
    
    return files;
  }
}
```

### 2. Recording Playback System
```tsx
// Recording player with advanced features
export function RecordingPlayer({ 
  recordingId 
}: { 
  recordingId: string 
}) {
  const [recording, setRecording] = useState<Recording>();
  const [playing, setPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  const [playbackRate, setPlaybackRate] = useState(1);
  const [selectedTrack, setSelectedTrack] = useState<string>('master');
  const [volume, setVolume] = useState(100);
  const [showTranscript, setShowTranscript] = useState(false);
  
  const audioRef = useRef<HTMLAudioElement>(null);
  const waveformRef = useRef<WaveformVisualizer>();
  
  useEffect(() => {
    loadRecording();
  }, [recordingId]);
  
  const loadRecording = async () => {
    try {
      const data = await api.getRecording(recordingId);
      setRecording(data);
      setDuration(data.duration / 1000); // Convert to seconds
      
      // Initialize waveform
      if (data.visualizations?.waveform) {
        waveformRef.current = new WaveformVisualizer(
          data.visualizations.waveform
        );
      }
    } catch (error) {
      toast.error('Failed to load recording');
    }
  };
  
  const togglePlayPause = () => {
    if (!audioRef.current) return;
    
    if (playing) {
      audioRef.current.pause();
    } else {
      audioRef.current.play();
    }
    setPlaying(!playing);
  };
  
  const handleTimeUpdate = () => {
    if (!audioRef.current) return;
    setCurrentTime(audioRef.current.currentTime);
    
    // Update waveform progress
    waveformRef.current?.setProgress(
      audioRef.current.currentTime / duration
    );
  };
  
  const handleSeek = (time: number) => {
    if (!audioRef.current) return;
    audioRef.current.currentTime = time;
    setCurrentTime(time);
  };
  
  const handlePlaybackRateChange = (rate: number) => {
    if (!audioRef.current) return;
    audioRef.current.playbackRate = rate;
    setPlaybackRate(rate);
  };
  
  const downloadRecording = async () => {
    if (!recording) return;
    
    try {
      const url = await api.getRecordingDownloadUrl(recordingId);
      const a = document.createElement('a');
      a.href = url;
      a.download = `${recording.title}.${recording.format}`;
      a.click();
      
      toast.success('Download started');
    } catch (error) {
      toast.error('Failed to download recording');
    }
  };
  
  if (!recording) return <LoadingSpinner />;
  
  return (
    <div className="recording-player">
      <div className="player-header">
        <h3>{recording.title}</h3>
        <div className="player-meta">
          <span className="duration">
            {formatDuration(recording.duration)}
          </span>
          <span className="date">
            {formatDate(recording.createdAt)}
          </span>
          <span className="size">
            {formatFileSize(recording.size)}
          </span>
        </div>
      </div>
      
      <div className="player-visualization">
        <WaveformDisplay
          ref={waveformRef}
          onSeek={handleSeek}
          currentTime={currentTime}
          duration={duration}
        />
      </div>
      
      <audio
        ref={audioRef}
        src={recording.files.find(f => f.trackId === selectedTrack)?.url}
        onTimeUpdate={handleTimeUpdate}
        onEnded={() => setPlaying(false)}
      />
      
      <div className="player-controls">
        <div className="playback-controls">
          <Button
            variant="ghost"
            onClick={() => handleSeek(Math.max(0, currentTime - 10))}
          >
            <RewindIcon />
          </Button>
          
          <Button
            variant="primary"
            size="large"
            onClick={togglePlayPause}
          >
            {playing ? <PauseIcon /> : <PlayIcon />}
          </Button>
          
          <Button
            variant="ghost"
            onClick={() => handleSeek(Math.min(duration, currentTime + 10))}
          >
            <FastForwardIcon />
          </Button>
        </div>
        
        <div className="time-display">
          <span>{formatTime(currentTime)}</span>
          <Slider
            value={currentTime}
            max={duration}
            onChange={handleSeek}
            className="time-slider"
          />
          <span>{formatTime(duration)}</span>
        </div>
        
        <div className="player-options">
          <VolumeControl
            value={volume}
            onChange={setVolume}
          />
          
          <PlaybackRateSelector
            value={playbackRate}
            onChange={handlePlaybackRateChange}
          />
          
          {recording.files.length > 1 && (
            <TrackSelector
              tracks={recording.files}
              selected={selectedTrack}
              onChange={setSelectedTrack}
            />
          )}
          
          <Button
            variant="ghost"
            onClick={() => setShowTranscript(!showTranscript)}
            active={showTranscript}
          >
            <TranscriptIcon />
          </Button>
          
          <Button
            variant="ghost"
            onClick={downloadRecording}
          >
            <DownloadIcon />
          </Button>
        </div>
      </div>
      
      {showTranscript && recording.metadata.transcription && (
        <RecordingTranscript
          transcription={recording.metadata.transcription}
          currentTime={currentTime}
          onSeek={handleSeek}
        />
      )}
      
      <RecordingDetails recording={recording} />
    </div>
  );
}

export function RecordingTranscript({
  transcription,
  currentTime,
  onSeek
}: {
  transcription: Transcription;
  currentTime: number;
  onSeek: (time: number) => void;
}) {
  const [searchQuery, setSearchQuery] = useState('');
  const activeRef = useRef<HTMLDivElement>(null);
  
  useEffect(() => {
    // Scroll to active segment
    activeRef.current?.scrollIntoView({
      behavior: 'smooth',
      block: 'center'
    });
  }, [currentTime]);
  
  const filteredSegments = transcription.segments.filter(segment =>
    searchQuery ? 
      segment.text.toLowerCase().includes(searchQuery.toLowerCase()) :
      true
  );
  
  const isSegmentActive = (segment: TranscriptionSegment) => {
    return currentTime >= segment.start && currentTime < segment.end;
  };
  
  return (
    <div className="recording-transcript">
      <div className="transcript-header">
        <h4>Transcript</h4>
        <SearchInput
          value={searchQuery}
          onChange={setSearchQuery}
          placeholder="Search transcript..."
        />
      </div>
      
      <div className="transcript-content">
        {filteredSegments.map((segment, index) => {
          const isActive = isSegmentActive(segment);
          
          return (
            <div
              key={index}
              ref={isActive ? activeRef : null}
              className={`transcript-segment ${isActive ? 'active' : ''}`}
              onClick={() => onSeek(segment.start)}
            >
              <div className="segment-time">
                {formatTime(segment.start)}
              </div>
              <div className="segment-speaker">
                {segment.speaker}
              </div>
              <div className="segment-text">
                {highlightText(segment.text, searchQuery)}
              </div>
            </div>
          );
        })}
      </div>
    </div>
  );
}
```

### 3. Recording Editor
```typescript
// Basic editing capabilities
export class RecordingEditor {
  private audioContext: AudioContext;
  private sourceBuffer: AudioBuffer;
  private selection: { start: number; end: number } | null = null;
  
  constructor() {
    this.audioContext = new AudioContext();
  }
  
  async loadRecording(url: string): Promise<void> {
    const response = await fetch(url);
    const arrayBuffer = await response.arrayBuffer();
    this.sourceBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
  }
  
  async trimRecording(
    start: number,
    end: number
  ): Promise<Blob> {
    const sampleRate = this.sourceBuffer.sampleRate;
    const startSample = Math.floor(start * sampleRate);
    const endSample = Math.floor(end * sampleRate);
    const length = endSample - startSample;
    
    // Create new buffer with trimmed audio
    const trimmedBuffer = this.audioContext.createBuffer(
      this.sourceBuffer.numberOfChannels,
      length,
      sampleRate
    );
    
    // Copy audio data
    for (let channel = 0; channel < this.sourceBuffer.numberOfChannels; channel++) {
      const sourceData = this.sourceBuffer.getChannelData(channel);
      const trimmedData = trimmedBuffer.getChannelData(channel);
      
      for (let i = 0; i < length; i++) {
        trimmedData[i] = sourceData[startSample + i];
      }
    }
    
    // Encode to blob
    return this.encodeAudioBuffer(trimmedBuffer);
  }
  
  async removeSection(
    start: number,
    end: number
  ): Promise<Blob> {
    const sampleRate = this.sourceBuffer.sampleRate;
    const startSample = Math.floor(start * sampleRate);
    const endSample = Math.floor(end * sampleRate);
    const totalLength = this.sourceBuffer.length;
    const newLength = totalLength - (endSample - startSample);
    
    // Create new buffer without the removed section
    const editedBuffer = this.audioContext.createBuffer(
      this.sourceBuffer.numberOfChannels,
      newLength,
      sampleRate
    );
    
    for (let channel = 0; channel < this.sourceBuffer.numberOfChannels; channel++) {
      const sourceData = this.sourceBuffer.getChannelData(channel);
      const editedData = editedBuffer.getChannelData(channel);
      
      // Copy before removal
      for (let i = 0; i < startSample; i++) {
        editedData[i] = sourceData[i];
      }
      
      // Copy after removal
      for (let i = endSample; i < totalLength; i++) {
        editedData[i - (endSample - startSample)] = sourceData[i];
      }
    }
    
    return this.encodeAudioBuffer(editedBuffer);
  }
  
  async mergeRecordings(
    recordings: string[]
  ): Promise<Blob> {
    // Load all recordings
    const buffers: AudioBuffer[] = [];
    
    for (const url of recordings) {
      const response = await fetch(url);
      const arrayBuffer = await response.arrayBuffer();
      const buffer = await this.audioContext.decodeAudioData(arrayBuffer);
      buffers.push(buffer);
    }
    
    // Calculate total length
    const totalLength = buffers.reduce((sum, b) => sum + b.length, 0);
    const sampleRate = buffers[0].sampleRate;
    const channels = buffers[0].numberOfChannels;
    
    // Create merged buffer
    const mergedBuffer = this.audioContext.createBuffer(
      channels,
      totalLength,
      sampleRate
    );
    
    let offset = 0;
    
    for (const buffer of buffers) {
      for (let channel = 0; channel < channels; channel++) {
        const sourceData = buffer.getChannelData(channel);
        const mergedData = mergedBuffer.getChannelData(channel);
        
        for (let i = 0; i < buffer.length; i++) {
          mergedData[offset + i] = sourceData[i];
        }
      }
      
      offset += buffer.length;
    }
    
    return this.encodeAudioBuffer(mergedBuffer);
  }
  
  private async encodeAudioBuffer(
    buffer: AudioBuffer
  ): Promise<Blob> {
    // Create offline context for rendering
    const offlineContext = new OfflineAudioContext(
      buffer.numberOfChannels,
      buffer.length,
      buffer.sampleRate
    );
    
    // Create source
    const source = offlineContext.createBufferSource();
    source.buffer = buffer;
    source.connect(offlineContext.destination);
    source.start();
    
    // Render
    const renderedBuffer = await offlineContext.startRendering();
    
    // Convert to WAV
    return this.audioBufferToWav(renderedBuffer);
  }
  
  private audioBufferToWav(buffer: AudioBuffer): Blob {
    const length = buffer.length * buffer.numberOfChannels * 2;
    const arrayBuffer = new ArrayBuffer(44 + length);
    const view = new DataView(arrayBuffer);
    
    // WAV header
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + length, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, buffer.numberOfChannels, true);
    view.setUint32(24, buffer.sampleRate, true);
    view.setUint32(28, buffer.sampleRate * 4, true);
    view.setUint16(32, 4, true);
    view.setUint16(34, 16, true);
    writeString(36, 'data');
    view.setUint32(40, length, true);
    
    // Convert float samples to 16-bit PCM
    let offset = 44;
    for (let i = 0; i < buffer.length; i++) {
      for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
        const sample = Math.max(-1, Math.min(1, buffer.getChannelData(channel)[i]));
        view.setInt16(offset, sample * 0x7FFF, true);
        offset += 2;
      }
    }
    
    return new Blob([arrayBuffer], { type: 'audio/wav' });
  }
}
```

### 4. Recording Management Dashboard
```tsx
export function RecordingsDashboard({ 
  waddleId 
}: { 
  waddleId: string 
}) {
  const [recordings, setRecordings] = useState<Recording[]>([]);
  const [loading, setLoading] = useState(true);
  const [filter, setFilter] = useState<RecordingFilter>({});
  const [sortBy, setSortBy] = useState<'date' | 'size' | 'duration'>('date');
  const [view, setView] = useState<'grid' | 'list'>('grid');
  const [selectedRecordings, setSelectedRecordings] = useState<Set<string>>(new Set());
  
  useEffect(() => {
    loadRecordings();
  }, [waddleId, filter, sortBy]);
  
  const loadRecordings = async () => {
    setLoading(true);
    try {
      const data = await api.getRecordings({
        waddleId,
        ...filter,
        sortBy,
        limit: 50
      });
      setRecordings(data.recordings);
    } finally {
      setLoading(false);
    }
  };
  
  const handleBulkAction = async (action: string) => {
    if (selectedRecordings.size === 0) return;
    
    switch (action) {
      case 'delete':
        const confirmed = await confirm(
          'Delete Recordings',
          `Delete ${selectedRecordings.size} recordings?`
        );
        if (confirmed) {
          await deleteRecordings(Array.from(selectedRecordings));
        }
        break;
        
      case 'export':
        await exportRecordings(Array.from(selectedRecordings));
        break;
        
      case 'share':
        await shareRecordings(Array.from(selectedRecordings));
        break;
    }
    
    setSelectedRecordings(new Set());
  };
  
  const deleteRecordings = async (ids: string[]) => {
    try {
      await api.deleteRecordings(ids);
      toast.success(`Deleted ${ids.length} recordings`);
      loadRecordings();
    } catch (error) {
      toast.error('Failed to delete recordings');
    }
  };
  
  return (
    <div className="recordings-dashboard">
      <div className="dashboard-header">
        <h2>Recordings</h2>
        
        <div className="header-stats">
          <Stat
            label="Total Recordings"
            value={recordings.length}
          />
          <Stat
            label="Total Duration"
            value={formatDuration(
              recordings.reduce((sum, r) => sum + r.duration, 0)
            )}
          />
          <Stat
            label="Storage Used"
            value={formatFileSize(
              recordings.reduce((sum, r) => sum + r.size, 0)
            )}
          />
        </div>
      </div>
      
      <div className="dashboard-controls">
        <RecordingFilters
          filter={filter}
          onChange={setFilter}
        />
        
        <div className="view-controls">
          <SortSelector
            value={sortBy}
            onChange={setSortBy}
            options={[
              { value: 'date', label: 'Date' },
              { value: 'size', label: 'Size' },
              { value: 'duration', label: 'Duration' }
            ]}
          />
          
          <ViewToggle
            value={view}
            onChange={setView}
          />
        </div>
        
        {selectedRecordings.size > 0 && (
          <BulkActions
            count={selectedRecordings.size}
            onAction={handleBulkAction}
          />
        )}
      </div>
      
      {loading ? (
        <LoadingSpinner />
      ) : view === 'grid' ? (
        <RecordingsGrid
          recordings={recordings}
          selectedIds={selectedRecordings}
          onSelect={(id) => {
            const newSelected = new Set(selectedRecordings);
            if (newSelected.has(id)) {
              newSelected.delete(id);
            } else {
              newSelected.add(id);
            }
            setSelectedRecordings(newSelected);
          }}
        />
      ) : (
        <RecordingsList
          recordings={recordings}
          selectedIds={selectedRecordings}
          onSelect={(id) => {
            const newSelected = new Set(selectedRecordings);
            if (newSelected.has(id)) {
              newSelected.delete(id);
            } else {
              newSelected.add(id);
            }
            setSelectedRecordings(newSelected);
          }}
        />
      )}
    </div>
  );
}

export function RecordingCard({
  recording,
  selected,
  onSelect,
  onClick
}: {
  recording: Recording;
  selected: boolean;
  onSelect: () => void;
  onClick: () => void;
}) {
  const [showActions, setShowActions] = useState(false);
  
  return (
    <div 
      className={`recording-card ${selected ? 'selected' : ''}`}
      onMouseEnter={() => setShowActions(true)}
      onMouseLeave={() => setShowActions(false)}
    >
      <div className="card-checkbox">
        <Checkbox
          checked={selected}
          onChange={onSelect}
        />
      </div>
      
      <div className="card-content" onClick={onClick}>
        {recording.visualizations?.thumbnail ? (
          <img 
            src={recording.visualizations.thumbnail}
            alt={recording.title}
            className="card-thumbnail"
          />
        ) : (
          <div className="card-waveform">
            <WaveformPreview data={recording.visualizations?.waveform} />
          </div>
        )}
        
        <div className="card-info">
          <h4>{recording.title}</h4>
          <div className="card-meta">
            <span className="duration">
              {formatDuration(recording.duration)}
            </span>
            <span className="date">
              {formatDate(recording.createdAt)}
            </span>
          </div>
          
          {recording.metadata.participants && (
            <div className="card-participants">
              {recording.metadata.participants.slice(0, 3).map(p => (
                <Avatar
                  key={p.id}
                  src={p.avatar}
                  name={p.name}
                  size="small"
                />
              ))}
              {recording.metadata.participants.length > 3 && (
                <span className="more-participants">
                  +{recording.metadata.participants.length - 3}
                </span>
              )}
            </div>
          )}
        </div>
      </div>
      
      {showActions && (
        <div className="card-actions">
          <RecordingActions
            recording={recording}
            onEdit={() => navigateToEditor(recording.id)}
            onShare={() => shareRecording(recording.id)}
            onDelete={() => deleteRecording(recording.id)}
          />
        </div>
      )}
    </div>
  );
}
```

### 5. Storage Management
```typescript
// Cloud storage with retention policies
export class RecordingStorage {
  private storageProviders = new Map<string, StorageProvider>();
  private retentionPolicies = new Map<string, RetentionPolicy>();
  
  constructor(
    private config: StorageConfig,
    private analytics: AnalyticsService
  ) {
    this.initializeProviders();
  }
  
  private initializeProviders() {
    // Primary storage
    this.storageProviders.set('primary', new S3StorageProvider({
      bucket: this.config.primaryBucket,
      region: this.config.primaryRegion,
      credentials: this.config.credentials
    }));
    
    // Archive storage
    this.storageProviders.set('archive', new GlacierStorageProvider({
      vault: this.config.archiveVault,
      region: this.config.archiveRegion,
      credentials: this.config.credentials
    }));
    
    // CDN storage
    this.storageProviders.set('cdn', new CloudfrontProvider({
      distribution: this.config.cdnDistribution
    }));
  }
  
  async upload(
    key: string,
    data: Blob | Buffer,
    options: UploadOptions = {}
  ): Promise<UploadResult> {
    const provider = this.selectProvider(options);
    
    // Upload with progress tracking
    const upload = provider.upload(key, data, {
      ...options,
      onProgress: (progress) => {
        this.emit('uploadProgress', { key, progress });
      }
    });
    
    try {
      const result = await upload;
      
      // Track upload
      await this.analytics.track('recording_uploaded', {
        key,
        size: data.size || data.length,
        provider: provider.name,
        duration: Date.now() - upload.startTime
      });
      
      return result;
    } catch (error) {
      await this.analytics.track('recording_upload_failed', {
        key,
        error: error.message
      });
      throw error;
    }
  }
  
  async applyRetentionPolicies() {
    console.log('Applying retention policies...');
    
    for (const [waddleId, policy] of this.retentionPolicies) {
      await this.applyPolicyToWaddle(waddleId, policy);
    }
  }
  
  private async applyPolicyToWaddle(
    waddleId: string,
    policy: RetentionPolicy
  ) {
    // Get all recordings for waddle
    const recordings = await this.listRecordings(waddleId);
    
    for (const recording of recordings) {
      const age = Date.now() - recording.createdAt;
      const ageDays = age / (1000 * 60 * 60 * 24);
      
      // Check if should be archived
      if (policy.archiveAfterDays && ageDays > policy.archiveAfterDays) {
        if (recording.storageClass !== 'archive') {
          await this.archiveRecording(recording);
        }
      }
      
      // Check if should be deleted
      if (policy.deleteAfterDays && ageDays > policy.deleteAfterDays) {
        await this.deleteRecording(recording);
      }
      
      // Check size-based policies
      if (policy.maxSizePerWaddle) {
        const totalSize = await this.calculateWaddleStorage(waddleId);
        if (totalSize > policy.maxSizePerWaddle) {
          // Delete oldest recordings until under limit
          await this.enforceStorageLimit(waddleId, policy.maxSizePerWaddle);
        }
      }
    }
  }
  
  private async archiveRecording(recording: Recording) {
    console.log(`Archiving recording ${recording.id}`);
    
    // Download from primary storage
    const data = await this.storageProviders.get('primary')!
      .download(recording.files[0].url);
    
    // Upload to archive storage
    const archiveUrl = await this.storageProviders.get('archive')!
      .upload(`archive/${recording.id}`, data);
    
    // Update recording metadata
    recording.storageClass = 'archive';
    recording.files[0].url = archiveUrl.url;
    
    // Delete from primary storage
    await this.storageProviders.get('primary')!
      .delete(recording.files[0].url);
    
    await this.analytics.track('recording_archived', {
      recordingId: recording.id,
      size: recording.size
    });
  }
  
  async getStorageStats(waddleId: string): Promise<StorageStats> {
    const recordings = await this.listRecordings(waddleId);
    
    const stats: StorageStats = {
      totalSize: 0,
      recordingCount: recordings.length,
      byStorageClass: {
        primary: { size: 0, count: 0 },
        archive: { size: 0, count: 0 }
      },
      oldestRecording: null,
      newestRecording: null,
      averageSize: 0
    };
    
    for (const recording of recordings) {
      stats.totalSize += recording.size;
      
      const storageClass = recording.storageClass || 'primary';
      stats.byStorageClass[storageClass].size += recording.size;
      stats.byStorageClass[storageClass].count++;
      
      if (!stats.oldestRecording || recording.createdAt < stats.oldestRecording.createdAt) {
        stats.oldestRecording = recording;
      }
      
      if (!stats.newestRecording || recording.createdAt > stats.newestRecording.createdAt) {
        stats.newestRecording = recording;
      }
    }
    
    stats.averageSize = stats.totalSize / Math.max(1, recordings.length);
    
    return stats;
  }
  
  async setRetentionPolicy(
    waddleId: string,
    policy: RetentionPolicy
  ) {
    this.retentionPolicies.set(waddleId, policy);
    
    // Save to persistent storage
    await this.saveRetentionPolicies();
    
    // Apply immediately
    await this.applyPolicyToWaddle(waddleId, policy);
  }
}
```

### 6. Transcription Service
```typescript
// Automatic transcription for recordings
export class TranscriptionService {
  private transcriptionQueue = new Queue<TranscriptionJob>();
  private activeJobs = new Map<string, TranscriptionJob>();
  
  constructor(
    private speechToText: SpeechToTextProvider,
    private storage: StorageService
  ) {
    this.startWorker();
  }
  
  async transcribeRecording(
    recording: Recording,
    options: TranscriptionOptions = {}
  ): Promise<string> {
    const job: TranscriptionJob = {
      id: crypto.randomUUID(),
      recordingId: recording.id,
      status: 'queued',
      options: {
        language: options.language || 'auto',
        speakerDiarization: options.speakerDiarization ?? true,
        punctuation: options.punctuation ?? true,
        profanityFilter: options.profanityFilter ?? false,
        customVocabulary: options.customVocabulary || []
      },
      createdAt: Date.now()
    };
    
    // Add to queue
    await this.transcriptionQueue.add(job);
    this.activeJobs.set(job.id, job);
    
    // Track job start
    await this.analytics.track('transcription_started', {
      jobId: job.id,
      recordingId: recording.id,
      language: job.options.language
    });
    
    return job.id;
  }
  
  private async startWorker() {
    while (true) {
      const job = await this.transcriptionQueue.take();
      
      try {
        await this.processTranscriptionJob(job);
      } catch (error) {
        console.error('Transcription job failed:', error);
        job.status = 'failed';
        job.error = error.message;
      }
      
      // Remove from active jobs
      this.activeJobs.delete(job.id);
      
      // Small delay between jobs
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  }
  
  private async processTranscriptionJob(job: TranscriptionJob) {
    job.status = 'processing';
    job.startedAt = Date.now();
    
    // Get recording audio
    const recording = await this.storage.getRecording(job.recordingId);
    const audioUrl = recording.files[0].url;
    
    // Detect language if auto
    if (job.options.language === 'auto') {
      job.options.language = await this.detectLanguage(audioUrl);
    }
    
    // Start transcription
    const transcription = await this.speechToText.transcribe({
      audioUrl,
      language: job.options.language,
      features: {
        speakerDiarization: job.options.speakerDiarization,
        punctuation: job.options.punctuation,
        profanityFilter: job.options.profanityFilter
      },
      vocabulary: job.options.customVocabulary,
      onProgress: (progress) => {
        job.progress = progress;
        this.emit('progress', { jobId: job.id, progress });
      }
    });
    
    // Process results
    const processed = await this.processTranscriptionResults(
      transcription,
      job.options
    );
    
    // Save transcription
    await this.storage.saveTranscription(job.recordingId, processed);
    
    job.status = 'completed';
    job.completedAt = Date.now();
    job.result = processed;
    
    // Track completion
    await this.analytics.track('transcription_completed', {
      jobId: job.id,
      recordingId: job.recordingId,
      duration: job.completedAt - job.startedAt!,
      wordCount: processed.segments.reduce((sum, s) => 
        sum + s.text.split(' ').length, 0
      )
    });
  }
  
  private async processTranscriptionResults(
    raw: RawTranscription,
    options: TranscriptionOptions
  ): Promise<Transcription> {
    const segments: TranscriptionSegment[] = [];
    
    for (const utterance of raw.utterances) {
      const segment: TranscriptionSegment = {
        start: utterance.start,
        end: utterance.end,
        text: utterance.text,
        confidence: utterance.confidence,
        speaker: options.speakerDiarization ? 
          `Speaker ${utterance.speaker}` : 'Speaker',
        words: utterance.words?.map(w => ({
          text: w.text,
          start: w.start,
          end: w.end,
          confidence: w.confidence
        }))
      };
      
      segments.push(segment);
    }
    
    return {
      segments,
      language: raw.language,
      duration: raw.duration,
      confidence: raw.confidence,
      vocabulary: options.customVocabulary
    };
  }
  
  async getJobStatus(jobId: string): Promise<TranscriptionJob | null> {
    return this.activeJobs.get(jobId) || null;
  }
  
  async searchTranscriptions(
    query: string,
    options: SearchOptions = {}
  ): Promise<SearchResult[]> {
    const results = await this.storage.searchTranscriptions({
      query,
      ...options
    });
    
    return results.map(result => ({
      recordingId: result.recordingId,
      matches: result.matches.map(match => ({
        segment: match.segment,
        text: match.text,
        timestamp: match.timestamp,
        context: this.getContext(match, 30) // 30 words of context
      }))
    }));
  }
}
```

## Dependencies
- Media recording APIs
- Cloud storage service (S3/GCS)
- Transcoding service (FFmpeg)
- Speech-to-text API
- Audio processing libraries
- Waveform visualization

## Estimated Effort
**7 days**
- 1 day: Recording infrastructure
- 1 day: Multi-track recording
- 1 day: Playback system
- 1 day: Basic editing features
- 1 day: Storage and retention
- 1 day: Transcription service
- 1 day: Management dashboard

## Notes
- Implement efficient chunking for long recordings
- Add compression options
- Support various audio formats
- Enable collaborative editing
- Consider bandwidth for downloads
- Add chapter markers
- Plan for large file handling