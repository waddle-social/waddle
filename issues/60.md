# Issue #60: Auto-scaling

## User Story
As a **platform operator**, I want to **automatically scale resources based on demand** so that **Waddle maintains optimal performance while minimizing costs during low-traffic periods**.

## Description
Implement intelligent auto-scaling across all platform components including compute workers, WebRTC infrastructure, database connections, and caching layers. The system should predict traffic patterns, scale proactively, and handle both gradual growth and sudden traffic spikes efficiently.

## Acceptance Criteria
- [ ] Automatic scaling based on real-time metrics
- [ ] Predictive scaling using ML models
- [ ] Support for sudden traffic spikes
- [ ] Cost-aware scaling decisions
- [ ] Zero-downtime scaling operations
- [ ] Multi-region scaling coordination
- [ ] Custom scaling policies per service
- [ ] Scaling event notifications and logs

## Technical Implementation

### 1. Auto-scaling Core Engine
```typescript
// Core auto-scaling engine
export class AutoScalingEngine {
  private scalers: Map<string, ServiceScaler> = new Map();
  private predictor: TrafficPredictor;
  private costOptimizer: CostAwareScaler;
  private coordinator: ScalingCoordinator;
  
  constructor(
    private env: Env,
    private monitoring: MonitoringService,
    private infrastructure: InfrastructureService
  ) {
    this.predictor = new TrafficPredictor();
    this.costOptimizer = new CostAwareScaler();
    this.coordinator = new ScalingCoordinator();
    this.initializeScalers();
  }
  
  private initializeScalers() {
    // Compute workers scaler
    this.scalers.set('compute', new ComputeScaler({
      minInstances: 2,
      maxInstances: 100,
      targetCPU: 70,
      targetMemory: 80,
      scaleUpThreshold: 80,
      scaleDownThreshold: 30,
      cooldownPeriod: 300 // 5 minutes
    }));
    
    // WebRTC infrastructure scaler
    this.scalers.set('webrtc', new WebRTCScaler({
      minRelays: 1,
      maxRelays: 50,
      connectionsPerRelay: 1000,
      bandwidthPerRelay: 1000 * 1024 * 1024, // 1 Gbps
      geoDistribution: true
    }));
    
    // Database connection pool scaler
    this.scalers.set('database', new DatabaseScaler({
      minConnections: 10,
      maxConnections: 1000,
      connectionsPerWorker: 10,
      idleTimeout: 300000 // 5 minutes
    }));
    
    // Cache layer scaler
    this.scalers.set('cache', new CacheScaler({
      minNodes: 1,
      maxNodes: 20,
      memoryPerNode: 4 * 1024 * 1024 * 1024, // 4GB
      evictionPolicy: 'lru'
    }));
  }
  
  async startAutoScaling(): Promise<void> {
    // Start monitoring loop
    this.startMonitoringLoop();
    
    // Start predictive scaling
    this.startPredictiveScaling();
    
    // Start cost optimization
    this.startCostOptimization();
    
    console.log('Auto-scaling engine started');
  }
  
  private async startMonitoringLoop(): Promise<void> {
    setInterval(async () => {
      try {
        const metrics = await this.collectMetrics();
        const decisions = await this.makeScalingDecisions(metrics);
        await this.executeScalingActions(decisions);
      } catch (error) {
        console.error('Auto-scaling error:', error);
        await this.handleScalingError(error);
      }
    }, 30000); // Check every 30 seconds
  }
  
  private async collectMetrics(): Promise<SystemMetrics> {
    const [compute, network, database, cache] = await Promise.all([
      this.monitoring.getComputeMetrics(),
      this.monitoring.getNetworkMetrics(),
      this.monitoring.getDatabaseMetrics(),
      this.monitoring.getCacheMetrics()
    ]);
    
    return {
      timestamp: Date.now(),
      compute: {
        cpu: compute.avgCPU,
        memory: compute.avgMemory,
        instances: compute.instanceCount,
        requestRate: compute.requestsPerSecond,
        responseTime: compute.avgResponseTime
      },
      network: {
        bandwidth: network.totalBandwidth,
        connections: network.activeConnections,
        packetLoss: network.packetLoss,
        latency: network.avgLatency
      },
      database: {
        connections: database.activeConnections,
        queryTime: database.avgQueryTime,
        queueDepth: database.queryQueue,
        replication: database.replicationLag
      },
      cache: {
        hitRate: cache.hitRate,
        evictionRate: cache.evictionRate,
        memory: cache.usedMemory,
        nodes: cache.nodeCount
      }
    };
  }
  
  private async makeScalingDecisions(
    metrics: SystemMetrics
  ): Promise<ScalingDecision[]> {
    const decisions: ScalingDecision[] = [];
    
    // Check each service for scaling needs
    for (const [service, scaler] of this.scalers) {
      const serviceMetrics = this.getServiceMetrics(metrics, service);
      const decision = await scaler.evaluate(serviceMetrics);
      
      if (decision.action !== 'none') {
        // Validate decision with coordinator
        const validated = await this.coordinator.validate(decision, metrics);
        if (validated) {
          decisions.push(decision);
        }
      }
    }
    
    // Optimize decisions for cost
    return this.costOptimizer.optimize(decisions, metrics);
  }
  
  private async executeScalingActions(
    decisions: ScalingDecision[]
  ): Promise<void> {
    // Group decisions by priority
    const prioritized = this.prioritizeDecisions(decisions);
    
    // Execute in order
    for (const decision of prioritized) {
      try {
        await this.executeDecision(decision);
        
        // Track scaling event
        await this.trackScalingEvent(decision);
        
        // Wait for stabilization
        await this.waitForStabilization(decision.service);
      } catch (error) {
        console.error(`Failed to execute scaling decision for ${decision.service}:`, error);
        await this.rollbackScaling(decision);
      }
    }
  }
  
  private async executeDecision(decision: ScalingDecision): Promise<void> {
    const scaler = this.scalers.get(decision.service);
    if (!scaler) throw new Error(`Unknown service: ${decision.service}`);
    
    console.log(`Executing scaling action: ${decision.action} for ${decision.service}`);
    
    switch (decision.action) {
      case 'scale_up':
        await scaler.scaleUp(decision.targetCapacity);
        break;
        
      case 'scale_down':
        await scaler.scaleDown(decision.targetCapacity);
        break;
        
      case 'rebalance':
        await scaler.rebalance(decision.distribution);
        break;
    }
  }
}

// Service-specific scalers
export class ComputeScaler implements ServiceScaler {
  private lastScaleTime: number = 0;
  private currentCapacity: number = 0;
  
  constructor(private config: ComputeScalerConfig) {
    this.currentCapacity = config.minInstances;
  }
  
  async evaluate(metrics: ComputeMetrics): Promise<ScalingDecision> {
    // Check cooldown period
    if (Date.now() - this.lastScaleTime < this.config.cooldownPeriod * 1000) {
      return { service: 'compute', action: 'none' };
    }
    
    // Calculate target capacity
    const cpuBasedTarget = this.calculateCPUTarget(metrics.cpu);
    const memoryBasedTarget = this.calculateMemoryTarget(metrics.memory);
    const loadBasedTarget = this.calculateLoadTarget(metrics.requestRate);
    
    // Use the highest target
    const targetCapacity = Math.max(
      cpuBasedTarget,
      memoryBasedTarget,
      loadBasedTarget
    );
    
    // Apply bounds
    const boundedTarget = Math.max(
      this.config.minInstances,
      Math.min(this.config.maxInstances, targetCapacity)
    );
    
    // Determine action
    if (boundedTarget > this.currentCapacity * 1.1) {
      return {
        service: 'compute',
        action: 'scale_up',
        targetCapacity: boundedTarget,
        reason: `High resource usage: CPU ${metrics.cpu}%, Memory ${metrics.memory}%`
      };
    } else if (boundedTarget < this.currentCapacity * 0.9) {
      return {
        service: 'compute',
        action: 'scale_down',
        targetCapacity: boundedTarget,
        reason: `Low resource usage: CPU ${metrics.cpu}%, Memory ${metrics.memory}%`
      };
    }
    
    return { service: 'compute', action: 'none' };
  }
  
  async scaleUp(targetCapacity: number): Promise<void> {
    const instancesToAdd = targetCapacity - this.currentCapacity;
    console.log(`Scaling up compute: adding ${instancesToAdd} instances`);
    
    // Launch new instances in parallel
    const launchPromises = [];
    for (let i = 0; i < instancesToAdd; i++) {
      launchPromises.push(this.launchInstance());
    }
    
    const instances = await Promise.all(launchPromises);
    
    // Wait for instances to be ready
    await this.waitForInstances(instances);
    
    // Update load balancer
    await this.updateLoadBalancer(instances);
    
    this.currentCapacity = targetCapacity;
    this.lastScaleTime = Date.now();
  }
  
  async scaleDown(targetCapacity: number): Promise<void> {
    const instancesToRemove = this.currentCapacity - targetCapacity;
    console.log(`Scaling down compute: removing ${instancesToRemove} instances`);
    
    // Select instances to terminate (least loaded first)
    const instances = await this.selectInstancesToTerminate(instancesToRemove);
    
    // Graceful shutdown
    for (const instance of instances) {
      await this.drainInstance(instance);
      await this.terminateInstance(instance);
    }
    
    // Update load balancer
    await this.removeFromLoadBalancer(instances);
    
    this.currentCapacity = targetCapacity;
    this.lastScaleTime = Date.now();
  }
  
  private calculateCPUTarget(cpuUsage: number): number {
    // Target CPU utilization
    const targetUtilization = this.config.targetCPU;
    const currentUtilization = cpuUsage;
    
    return Math.ceil(
      this.currentCapacity * (currentUtilization / targetUtilization)
    );
  }
  
  private async drainInstance(instance: ComputeInstance): Promise<void> {
    // Stop accepting new connections
    await instance.setDraining(true);
    
    // Wait for existing connections to complete
    const timeout = 300000; // 5 minutes
    const start = Date.now();
    
    while (Date.now() - start < timeout) {
      const connections = await instance.getActiveConnections();
      if (connections === 0) break;
      
      await new Promise(resolve => setTimeout(resolve, 5000));
    }
  }
}

export class WebRTCScaler implements ServiceScaler {
  private relayPools: Map<string, RelayPool> = new Map();
  
  constructor(private config: WebRTCScalerConfig) {}
  
  async evaluate(metrics: WebRTCMetrics): Promise<ScalingDecision> {
    const totalConnections = metrics.activeConnections;
    const currentRelays = metrics.relayCount;
    
    // Calculate required relays
    const requiredRelays = Math.ceil(
      totalConnections / this.config.connectionsPerRelay
    );
    
    // Consider bandwidth requirements
    const bandwidthRelays = Math.ceil(
      metrics.totalBandwidth / this.config.bandwidthPerRelay
    );
    
    const targetRelays = Math.max(
      requiredRelays,
      bandwidthRelays,
      this.config.minRelays
    );
    
    // Check geo-distribution if enabled
    if (this.config.geoDistribution) {
      return this.evaluateGeoDistribution(metrics, targetRelays);
    }
    
    if (targetRelays > currentRelays) {
      return {
        service: 'webrtc',
        action: 'scale_up',
        targetCapacity: targetRelays,
        reason: `High connection count: ${totalConnections}`
      };
    } else if (targetRelays < currentRelays * 0.7) {
      return {
        service: 'webrtc',
        action: 'scale_down',
        targetCapacity: targetRelays,
        reason: `Low connection count: ${totalConnections}`
      };
    }
    
    return { service: 'webrtc', action: 'none' };
  }
  
  private async evaluateGeoDistribution(
    metrics: WebRTCMetrics,
    targetRelays: number
  ): Promise<ScalingDecision> {
    const distribution = await this.calculateOptimalDistribution(
      metrics.connectionsByRegion,
      targetRelays
    );
    
    // Check if rebalancing is needed
    const currentDistribution = await this.getCurrentDistribution();
    
    if (this.needsRebalancing(currentDistribution, distribution)) {
      return {
        service: 'webrtc',
        action: 'rebalance',
        distribution,
        reason: 'Optimize geographic distribution'
      };
    }
    
    return { service: 'webrtc', action: 'none' };
  }
  
  async scaleUp(targetCapacity: number): Promise<void> {
    const regions = await this.selectRegionsForScaling(targetCapacity);
    
    for (const [region, count] of regions) {
      const pool = this.getOrCreatePool(region);
      await pool.addRelays(count);
    }
    
    // Update DNS/load balancing
    await this.updateRouting();
  }
  
  private async selectRegionsForScaling(
    targetCapacity: number
  ): Promise<Map<string, number>> {
    const metrics = await this.monitoring.getRegionalMetrics();
    const distribution = new Map<string, number>();
    
    // Prioritize regions with high demand
    const sortedRegions = Array.from(metrics.entries())
      .sort((a, b) => b[1].demand - a[1].demand);
    
    let remaining = targetCapacity - this.getCurrentCapacity();
    
    for (const [region, regionMetrics] of sortedRegions) {
      if (remaining <= 0) break;
      
      const needed = Math.ceil(
        regionMetrics.connections / this.config.connectionsPerRelay
      ) - regionMetrics.currentRelays;
      
      if (needed > 0) {
        const toAdd = Math.min(needed, remaining);
        distribution.set(region, toAdd);
        remaining -= toAdd;
      }
    }
    
    return distribution;
  }
}
```

### 2. Predictive Scaling
```typescript
// ML-based traffic prediction
export class TrafficPredictor {
  private model: TensorFlowModel;
  private featureExtractor: FeatureExtractor;
  private history: CircularBuffer<TrafficData>;
  
  constructor() {
    this.model = this.loadModel();
    this.featureExtractor = new FeatureExtractor();
    this.history = new CircularBuffer(10080); // 1 week of minute data
  }
  
  async predictTraffic(
    horizon: number = 3600000 // 1 hour ahead
  ): Promise<TrafficPrediction> {
    // Extract features from historical data
    const features = await this.extractFeatures();
    
    // Make prediction
    const prediction = await this.model.predict(features);
    
    // Calculate confidence intervals
    const confidence = this.calculateConfidence(prediction);
    
    return {
      timestamp: Date.now() + horizon,
      predicted: {
        users: prediction.users,
        requests: prediction.requests,
        bandwidth: prediction.bandwidth,
        connections: prediction.connections
      },
      confidence,
      factors: this.identifyInfluencingFactors(features)
    };
  }
  
  private async extractFeatures(): Promise<PredictionFeatures> {
    const recent = this.history.getRecent(60); // Last hour
    const historical = this.history.getAll();
    
    return {
      // Time-based features
      hourOfDay: new Date().getHours(),
      dayOfWeek: new Date().getDay(),
      isWeekend: [0, 6].includes(new Date().getDay()),
      monthOfYear: new Date().getMonth(),
      
      // Traffic patterns
      recentAverage: this.calculateAverage(recent),
      recentTrend: this.calculateTrend(recent),
      volatility: this.calculateVolatility(recent),
      
      // Historical patterns
      sameDayLastWeek: this.getSameDayLastWeek(historical),
      sameHourYesterday: this.getSameHourYesterday(historical),
      weeklyPattern: this.extractWeeklyPattern(historical),
      
      // External factors
      specialEvents: await this.getSpecialEvents(),
      seasonality: this.detectSeasonality(historical)
    };
  }
  
  async recommendScaling(
    prediction: TrafficPrediction,
    currentCapacity: SystemCapacity
  ): Promise<ScalingRecommendation> {
    const recommendations: ScalingRecommendation = {
      immediate: [],
      scheduled: []
    };
    
    // Immediate scaling needs
    if (prediction.confidence > 0.8) {
      const immediateNeeds = this.calculateImmediateNeeds(
        prediction.predicted,
        currentCapacity
      );
      
      if (immediateNeeds.compute > 0) {
        recommendations.immediate.push({
          service: 'compute',
          action: 'scale_up',
          amount: immediateNeeds.compute,
          reason: 'Predicted traffic spike'
        });
      }
    }
    
    // Scheduled scaling for predicted patterns
    const schedule = this.generateScalingSchedule(prediction);
    recommendations.scheduled = schedule;
    
    return recommendations;
  }
  
  private generateScalingSchedule(
    prediction: TrafficPrediction
  ): ScheduledScaling[] {
    const schedule: ScheduledScaling[] = [];
    
    // Analyze predicted traffic pattern
    const peaks = this.findTrafficPeaks(prediction);
    const valleys = this.findTrafficValleys(prediction);
    
    // Schedule scale-up before peaks
    for (const peak of peaks) {
      schedule.push({
        time: peak.time - 600000, // 10 minutes before
        action: 'scale_up',
        services: this.determineServicesForPeak(peak),
        reason: `Predicted peak at ${new Date(peak.time).toISOString()}`
      });
    }
    
    // Schedule scale-down after valleys
    for (const valley of valleys) {
      schedule.push({
        time: valley.time + 600000, // 10 minutes after
        action: 'scale_down',
        services: this.determineServicesForValley(valley),
        reason: `Predicted low traffic at ${new Date(valley.time).toISOString()}`
      });
    }
    
    return schedule;
  }
}

// Predictive scaling coordinator
export class PredictiveScalingCoordinator {
  private predictor: TrafficPredictor;
  private scheduler: ScalingScheduler;
  private validator: PredictionValidator;
  
  constructor(
    private autoScaler: AutoScalingEngine,
    private monitoring: MonitoringService
  ) {
    this.predictor = new TrafficPredictor();
    this.scheduler = new ScalingScheduler();
    this.validator = new PredictionValidator();
  }
  
  async startPredictiveScaling(): Promise<void> {
    // Run predictions every 5 minutes
    setInterval(async () => {
      try {
        await this.runPredictionCycle();
      } catch (error) {
        console.error('Predictive scaling error:', error);
      }
    }, 300000);
    
    // Validate past predictions
    setInterval(async () => {
      await this.validatePredictions();
    }, 3600000); // Every hour
  }
  
  private async runPredictionCycle(): Promise<void> {
    // Get current system state
    const currentState = await this.monitoring.getSystemState();
    
    // Make predictions
    const predictions = await this.predictor.predictTraffic();
    
    // Generate scaling recommendations
    const recommendations = await this.predictor.recommendScaling(
      predictions,
      currentState.capacity
    );
    
    // Execute immediate recommendations
    for (const rec of recommendations.immediate) {
      await this.autoScaler.executeScaling(rec);
    }
    
    // Schedule future scaling
    for (const scheduled of recommendations.scheduled) {
      await this.scheduler.schedule(scheduled);
    }
    
    // Log predictions for validation
    await this.logPrediction(predictions);
  }
  
  private async validatePredictions(): Promise<void> {
    const recentPredictions = await this.getPastPredictions(3600000); // Last hour
    
    for (const prediction of recentPredictions) {
      const actual = await this.monitoring.getMetricsAt(prediction.timestamp);
      const accuracy = this.validator.calculateAccuracy(prediction, actual);
      
      // Update model if accuracy is low
      if (accuracy < 0.7) {
        await this.predictor.updateModel(prediction, actual);
      }
      
      // Log validation results
      await this.logValidation(prediction, actual, accuracy);
    }
  }
}
```

### 3. Cost-Aware Scaling
```typescript
// Cost optimization for auto-scaling
export class CostAwareScaler {
  private costCalculator: CostCalculator;
  private budgetManager: BudgetManager;
  
  constructor(
    private pricing: PricingService,
    private billing: BillingService
  ) {
    this.costCalculator = new CostCalculator(pricing);
    this.budgetManager = new BudgetManager(billing);
  }
  
  async optimize(
    decisions: ScalingDecision[],
    metrics: SystemMetrics
  ): Promise<ScalingDecision[]> {
    // Calculate cost impact of each decision
    const costedDecisions = await this.calculateCostImpact(decisions);
    
    // Check budget constraints
    const budget = await this.budgetManager.getAvailableBudget();
    
    // Optimize decisions based on cost/benefit
    return this.optimizeForCost(costedDecisions, budget, metrics);
  }
  
  private async calculateCostImpact(
    decisions: ScalingDecision[]
  ): Promise<CostedDecision[]> {
    const costed: CostedDecision[] = [];
    
    for (const decision of decisions) {
      const costImpact = await this.costCalculator.calculate(decision);
      
      costed.push({
        ...decision,
        costImpact: {
          hourly: costImpact.hourly,
          monthly: costImpact.monthly,
          savings: costImpact.savings || 0
        }
      });
    }
    
    return costed;
  }
  
  private optimizeForCost(
    decisions: CostedDecision[],
    budget: Budget,
    metrics: SystemMetrics
  ): ScalingDecision[] {
    const optimized: ScalingDecision[] = [];
    let projectedCost = budget.currentSpend;
    
    // Sort by cost efficiency (benefit/cost ratio)
    const sorted = decisions.sort((a, b) => {
      const efficiencyA = this.calculateEfficiency(a, metrics);
      const efficiencyB = this.calculateEfficiency(b, metrics);
      return efficiencyB - efficiencyA;
    });
    
    // Select decisions within budget
    for (const decision of sorted) {
      const newCost = projectedCost + decision.costImpact.hourly;
      
      if (newCost <= budget.hourlyLimit) {
        optimized.push(decision);
        projectedCost = newCost;
      } else if (decision.action === 'scale_down') {
        // Always allow scale-down to save costs
        optimized.push(decision);
        projectedCost = newCost;
      }
    }
    
    // Add cost-saving opportunities
    const savings = this.identifySavings(metrics);
    optimized.push(...savings);
    
    return optimized;
  }
  
  private calculateEfficiency(
    decision: CostedDecision,
    metrics: SystemMetrics
  ): number {
    // Calculate expected benefit
    let benefit = 0;
    
    switch (decision.service) {
      case 'compute':
        // Reduced response time benefit
        const currentResponseTime = metrics.compute.responseTime;
        const expectedReduction = decision.action === 'scale_up' ? 0.2 : -0.1;
        benefit = (currentResponseTime * expectedReduction) * 100;
        break;
        
      case 'webrtc':
        // Connection quality benefit
        const currentPacketLoss = metrics.network.packetLoss;
        const expectedImprovement = decision.action === 'scale_up' ? 0.5 : -0.2;
        benefit = (currentPacketLoss * expectedImprovement) * 1000;
        break;
    }
    
    // Calculate efficiency ratio
    const cost = Math.abs(decision.costImpact.hourly);
    return cost > 0 ? benefit / cost : benefit;
  }
  
  private identifySavings(metrics: SystemMetrics): ScalingDecision[] {
    const savings: ScalingDecision[] = [];
    
    // Identify underutilized resources
    if (metrics.compute.cpu < 20 && metrics.compute.instances > 2) {
      savings.push({
        service: 'compute',
        action: 'scale_down',
        targetCapacity: Math.max(2, Math.floor(metrics.compute.instances * 0.7)),
        reason: 'Low CPU utilization - cost optimization'
      });
    }
    
    // Identify over-provisioned cache
    if (metrics.cache.hitRate < 0.5 && metrics.cache.evictionRate < 0.01) {
      savings.push({
        service: 'cache',
        action: 'scale_down',
        targetCapacity: Math.max(1, Math.floor(metrics.cache.nodes * 0.8)),
        reason: 'Low cache utilization - cost optimization'
      });
    }
    
    return savings;
  }
}

// Spot instance manager for cost savings
export class SpotInstanceManager {
  private spotRatio: number = 0.7; // 70% spot instances
  private spotPools: Map<string, SpotPool> = new Map();
  
  async optimizeInstanceMix(
    targetCapacity: number,
    requirements: InstanceRequirements
  ): Promise<InstanceMix> {
    // Calculate optimal mix
    const spotCount = Math.floor(targetCapacity * this.spotRatio);
    const onDemandCount = targetCapacity - spotCount;
    
    // Diversify spot instances across pools
    const spotAllocation = await this.allocateSpotInstances(
      spotCount,
      requirements
    );
    
    return {
      onDemand: {
        count: onDemandCount,
        type: requirements.instanceType
      },
      spot: spotAllocation,
      estimatedSavings: this.calculateSavings(spotAllocation, onDemandCount)
    };
  }
  
  private async allocateSpotInstances(
    count: number,
    requirements: InstanceRequirements
  ): Promise<SpotAllocation[]> {
    // Get available spot pools
    const pools = await this.getAvailableSpotPools(requirements);
    
    // Distribute across pools for reliability
    const allocations: SpotAllocation[] = [];
    const poolCount = Math.min(3, pools.length); // Use up to 3 pools
    const perPool = Math.floor(count / poolCount);
    
    for (let i = 0; i < poolCount; i++) {
      const pool = pools[i];
      const poolCount = i === poolCount - 1 
        ? count - (perPool * i) // Remainder to last pool
        : perPool;
        
      allocations.push({
        pool: pool.id,
        count: poolCount,
        price: pool.currentPrice,
        savings: (pool.onDemandPrice - pool.currentPrice) * poolCount
      });
    }
    
    return allocations;
  }
}
```

### 4. Scaling Coordination
```typescript
// Multi-service scaling coordinator
export class ScalingCoordinator {
  private locks: Map<string, ScalingLock> = new Map();
  private dependencies: Map<string, string[]> = new Map();
  
  constructor() {
    this.initializeDependencies();
  }
  
  private initializeDependencies() {
    // Define service dependencies
    this.dependencies.set('compute', ['cache', 'database']);
    this.dependencies.set('webrtc', ['compute']);
    this.dependencies.set('database', []);
    this.dependencies.set('cache', []);
  }
  
  async validate(
    decision: ScalingDecision,
    metrics: SystemMetrics
  ): Promise<boolean> {
    // Check if service is locked
    if (this.isLocked(decision.service)) {
      console.log(`Service ${decision.service} is locked, skipping scaling`);
      return false;
    }
    
    // Check dependencies
    const deps = this.dependencies.get(decision.service) || [];
    for (const dep of deps) {
      if (!this.isDependencyReady(dep, decision, metrics)) {
        console.log(`Dependency ${dep} not ready for ${decision.service} scaling`);
        return false;
      }
    }
    
    // Validate capacity constraints
    if (!this.validateCapacity(decision, metrics)) {
      return false;
    }
    
    return true;
  }
  
  async coordinate(decisions: ScalingDecision[]): Promise<ScalingPlan> {
    // Build dependency graph
    const graph = this.buildDependencyGraph(decisions);
    
    // Topological sort for execution order
    const order = this.topologicalSort(graph);
    
    // Group by phases
    const phases = this.groupIntoPhases(order);
    
    // Add synchronization points
    const plan = this.addSynchronization(phases);
    
    return plan;
  }
  
  private isDependencyReady(
    dependency: string,
    decision: ScalingDecision,
    metrics: SystemMetrics
  ): boolean {
    // Check if dependency has enough capacity
    switch (dependency) {
      case 'database':
        const dbCapacity = metrics.database.connections;
        const requiredConnections = decision.targetCapacity * 10; // 10 per instance
        return dbCapacity > requiredConnections * 1.2; // 20% headroom
        
      case 'cache':
        const cacheCapacity = metrics.cache.memory;
        const requiredCache = decision.targetCapacity * 1024 * 1024 * 1024; // 1GB per instance
        return cacheCapacity > requiredCache * 1.3; // 30% headroom
        
      default:
        return true;
    }
  }
  
  async acquireLock(service: string): Promise<ScalingLock> {
    const lock: ScalingLock = {
      service,
      acquired: Date.now(),
      expires: Date.now() + 600000 // 10 minutes
    };
    
    this.locks.set(service, lock);
    return lock;
  }
  
  async releaseLock(service: string): Promise<void> {
    this.locks.delete(service);
  }
  
  private buildDependencyGraph(
    decisions: ScalingDecision[]
  ): DependencyGraph {
    const graph = new DependencyGraph();
    
    for (const decision of decisions) {
      graph.addNode(decision.service, decision);
      
      const deps = this.dependencies.get(decision.service) || [];
      for (const dep of deps) {
        // Only add edge if dependency also has a decision
        if (decisions.find(d => d.service === dep)) {
          graph.addEdge(dep, decision.service);
        }
      }
    }
    
    return graph;
  }
}

// Graceful scaling orchestrator
export class GracefulScaler {
  async scaleWithZeroDowntime(
    service: string,
    from: number,
    to: number
  ): Promise<void> {
    console.log(`Graceful scaling ${service} from ${from} to ${to}`);
    
    if (to > from) {
      // Scale up: add new capacity before removing old
      await this.scaleUp(service, from, to);
    } else {
      // Scale down: gradually drain and remove
      await this.scaleDown(service, from, to);
    }
  }
  
  private async scaleUp(
    service: string,
    from: number,
    to: number
  ): Promise<void> {
    const increment = Math.ceil((to - from) / 3); // Scale in 3 phases
    let current = from;
    
    while (current < to) {
      const nextCapacity = Math.min(current + increment, to);
      
      // Add new instances
      await this.addCapacity(service, nextCapacity - current);
      
      // Wait for health checks
      await this.waitForHealthy(service);
      
      // Update load balancer
      await this.updateLoadBalancer(service);
      
      current = nextCapacity;
      
      // Brief stabilization period
      await new Promise(resolve => setTimeout(resolve, 30000));
    }
  }
  
  private async scaleDown(
    service: string,
    from: number,
    to: number
  ): Promise<void> {
    const decrement = Math.ceil((from - to) / 3);
    let current = from;
    
    while (current > to) {
      const nextCapacity = Math.max(current - decrement, to);
      const toRemove = current - nextCapacity;
      
      // Select instances to remove
      const instances = await this.selectInstances(service, toRemove);
      
      // Drain connections
      await this.drainInstances(instances);
      
      // Remove from load balancer
      await this.removeFromLoadBalancer(service, instances);
      
      // Terminate instances
      await this.terminateInstances(instances);
      
      current = nextCapacity;
      
      // Stabilization period
      await new Promise(resolve => setTimeout(resolve, 30000));
    }
  }
}
```

### 5. Monitoring and Alerting
```typescript
// Auto-scaling monitoring dashboard
export function AutoScalingDashboard() {
  const [metrics, setMetrics] = useState<ScalingMetrics>();
  const [events, setEvents] = useState<ScalingEvent[]>([]);
  const [predictions, setPredictions] = useState<TrafficPrediction>();
  
  useEffect(() => {
    const ws = connectToScalingUpdates();
    loadInitialData();
    
    return () => ws.close();
  }, []);
  
  const connectToScalingUpdates = () => {
    const ws = new WebSocket('wss://api.waddle.chat/scaling/stream');
    
    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      
      switch (data.type) {
        case 'metrics':
          setMetrics(data.metrics);
          break;
          
        case 'event':
          setEvents(prev => [data.event, ...prev].slice(0, 100));
          break;
          
        case 'prediction':
          setPredictions(data.prediction);
          break;
      }
    };
    
    return ws;
  };
  
  return (
    <div className="autoscaling-dashboard">
      <div className="dashboard-header">
        <h1>Auto-Scaling Dashboard</h1>
        <div className="scaling-status">
          <StatusIndicator status={metrics?.status || 'unknown'} />
          <span>Auto-scaling {metrics?.enabled ? 'Enabled' : 'Disabled'}</span>
        </div>
      </div>
      
      {metrics && (
        <div className="metrics-grid">
          <ServiceMetric
            service="Compute"
            current={metrics.compute.instances}
            target={metrics.compute.target}
            utilization={metrics.compute.utilization}
            cost={metrics.compute.hourlyCost}
          />
          
          <ServiceMetric
            service="WebRTC"
            current={metrics.webrtc.relays}
            target={metrics.webrtc.target}
            utilization={metrics.webrtc.utilization}
            cost={metrics.webrtc.hourlyCost}
          />
          
          <ServiceMetric
            service="Database"
            current={metrics.database.connections}
            target={metrics.database.target}
            utilization={metrics.database.utilization}
            cost={metrics.database.hourlyCost}
          />
          
          <ServiceMetric
            service="Cache"
            current={metrics.cache.nodes}
            target={metrics.cache.target}
            utilization={metrics.cache.utilization}
            cost={metrics.cache.hourlyCost}
          />
        </div>
      )}
      
      {predictions && (
        <div className="predictions-section">
          <h2>Traffic Predictions</h2>
          <PredictionChart
            current={metrics}
            predicted={predictions}
            confidence={predictions.confidence}
          />
          
          <div className="prediction-factors">
            <h3>Influencing Factors</h3>
            {predictions.factors.map((factor, i) => (
              <Factor key={i} {...factor} />
            ))}
          </div>
        </div>
      )}
      
      <div className="scaling-events">
        <h2>Recent Scaling Events</h2>
        <EventsTable events={events} />
      </div>
      
      <div className="scaling-policies">
        <h2>Scaling Policies</h2>
        <PolicyEditor
          policies={metrics?.policies}
          onUpdate={updatePolicy}
        />
      </div>
    </div>
  );
}

// Scaling alerts
export class ScalingAlertManager {
  private alerts: Map<string, Alert> = new Map();
  
  async checkScalingHealth(metrics: ScalingMetrics): Promise<Alert[]> {
    const alerts: Alert[] = [];
    
    // Check for scaling failures
    if (metrics.failureRate > 0.1) {
      alerts.push({
        severity: 'critical',
        title: 'High scaling failure rate',
        message: `${(metrics.failureRate * 100).toFixed(1)}% of scaling operations are failing`,
        action: 'Check scaling logs and infrastructure capacity'
      });
    }
    
    // Check for oscillation
    if (this.detectOscillation(metrics.history)) {
      alerts.push({
        severity: 'warning',
        title: 'Scaling oscillation detected',
        message: 'Services are scaling up and down frequently',
        action: 'Adjust scaling thresholds and cooldown periods'
      });
    }
    
    // Check for cost overrun
    if (metrics.totalCost > metrics.budgetLimit * 0.9) {
      alerts.push({
        severity: 'warning',
        title: 'Approaching budget limit',
        message: `Current spend: $${metrics.totalCost.toFixed(2)}/hour (90% of limit)`,
        action: 'Review scaling policies and cost optimization'
      });
    }
    
    return alerts;
  }
  
  private detectOscillation(history: ScalingEvent[]): boolean {
    // Count direction changes in recent history
    let changes = 0;
    let lastDirection = null;
    
    for (const event of history.slice(0, 20)) {
      const direction = event.action === 'scale_up' ? 'up' : 'down';
      
      if (lastDirection && direction !== lastDirection) {
        changes++;
      }
      
      lastDirection = direction;
    }
    
    return changes > 5; // More than 5 direction changes
  }
}
```

## Dependencies
- Kubernetes or container orchestration
- Prometheus for metrics
- Machine learning framework (TensorFlow.js)
- Time-series database
- Load balancer APIs

## Estimated Effort
**5 days**
- 1 day: Core auto-scaling engine
- 1 day: Service-specific scalers
- 1 day: Predictive scaling
- 1 day: Cost optimization
- 1 day: Monitoring and coordination

## Notes
- Test scaling policies thoroughly
- Implement gradual rollout
- Monitor for scaling oscillation
- Set appropriate budget limits
- Regular review of scaling efficiency