# Issue #41: Voice to Stream

## User Story
As a **voice channel participant**, I want to **broadcast our voice conversation as a live stream** so that **non-participants can listen to our discussion, podcast, or event without joining the voice channel**.

## Description
Transform active voice channels into live audio streams that can be broadcast to a wider audience. This feature enables podcasting, live shows, and public events while maintaining the interactive nature of voice channels for participants.

## Acceptance Criteria
- [ ] One-click stream activation from voice channel
- [ ] Audio mixing and normalization
- [ ] Stream quality configuration
- [ ] Participant consent management
- [ ] Live listener count display
- [ ] Stream metadata and discovery
- [ ] Recording capabilities
- [ ] Stream monetization support

## Technical Implementation

### 1. Voice Channel Streaming Core
```typescript
// Voice to stream converter
export interface VoiceStreamConfig {
  channelId: string;
  streamTitle: string;
  description?: string;
  quality: 'low' | 'medium' | 'high' | 'ultra';
  privacy: 'public' | 'unlisted' | 'private';
  recordEnabled: boolean;
  chatEnabled: boolean;
  donationsEnabled: boolean;
}

export class VoiceChannelStreamer {
  private activeStreams = new Map<string, VoiceStream>();
  private audioMixers = new Map<string, AudioMixer>();
  private streamProcessors = new Map<string, StreamProcessor>();
  
  constructor(
    private voiceService: VoiceService,
    private streamingService: StreamingService,
    private analytics: AnalyticsService
  ) {}
  
  async startStream(config: VoiceStreamConfig): Promise<VoiceStream> {
    // Validate permissions
    const canStream = await this.validateStreamPermissions(config.channelId);
    if (!canStream) {
      throw new Error('Insufficient permissions to stream this channel');
    }
    
    // Get participant consent
    const consent = await this.getParticipantConsent(config.channelId);
    if (!consent.allConsented) {
      throw new Error('Not all participants have consented to streaming');
    }
    
    // Create voice stream
    const stream: VoiceStream = {
      id: crypto.randomUUID(),
      channelId: config.channelId,
      config,
      startTime: Date.now(),
      state: 'initializing',
      participants: new Map(),
      listeners: new Set(),
      metrics: {
        listenerCount: 0,
        peakListeners: 0,
        totalListeners: 0,
        avgListenTime: 0,
        audioQuality: {
          bitrate: 0,
          sampleRate: 48000,
          channels: 2
        }
      }
    };
    
    // Set up audio pipeline
    await this.setupAudioPipeline(stream);
    
    // Start streaming
    await this.initializeStream(stream);
    
    // Store active stream
    this.activeStreams.set(config.channelId, stream);
    
    // Start monitoring
    this.startStreamMonitoring(stream);
    
    return stream;
  }
  
  private async setupAudioPipeline(stream: VoiceStream) {
    // Create audio mixer for combining participant audio
    const mixer = new AudioMixer({
      sampleRate: 48000,
      channels: 2,
      bitDepth: 16,
      frameSize: 960 // 20ms at 48kHz
    });
    
    // Configure mixer settings
    mixer.setNormalization({
      enabled: true,
      targetLevel: -16, // LUFS
      maxGain: 12, // dB
      compressionRatio: 3
    });
    
    // Add noise gate
    mixer.addProcessor(new NoiseGate({
      threshold: -40, // dB
      attack: 5, // ms
      release: 50, // ms
      hold: 10 // ms
    }));
    
    // Add compressor for broadcast
    mixer.addProcessor(new Compressor({
      threshold: -12, // dB
      ratio: 4,
      attack: 10, // ms
      release: 100, // ms
      makeupGain: 3 // dB
    }));
    
    // Add limiter to prevent clipping
    mixer.addProcessor(new Limiter({
      threshold: -0.3, // dB
      release: 50 // ms
    }));
    
    this.audioMixers.set(stream.id, mixer);
    
    // Set up stream processor
    const processor = new StreamProcessor({
      mixer,
      encoder: this.getEncoder(stream.config.quality),
      format: 'opus'
    });
    
    this.streamProcessors.set(stream.id, processor);
  }
  
  private getEncoder(quality: string): AudioEncoder {
    const encoderConfigs = {
      low: { bitrate: 32000, complexity: 5 },
      medium: { bitrate: 64000, complexity: 8 },
      high: { bitrate: 128000, complexity: 10 },
      ultra: { bitrate: 256000, complexity: 10 }
    };
    
    const config = encoderConfigs[quality];
    
    return new OpusEncoder({
      sampleRate: 48000,
      channels: 2,
      bitrate: config.bitrate,
      complexity: config.complexity,
      frameSize: 20, // ms
      packetLossPercentage: 10, // Expected packet loss
      inbandFEC: true,
      dtx: false // Don't use discontinuous transmission for streams
    });
  }
  
  async addParticipant(
    streamId: string,
    participant: VoiceParticipant
  ): Promise<void> {
    const stream = this.activeStreams.get(streamId);
    if (!stream) throw new Error('Stream not found');
    
    const mixer = this.audioMixers.get(stream.id);
    if (!mixer) throw new Error('Audio mixer not found');
    
    // Create participant audio source
    const audioSource = new ParticipantAudioSource({
      participantId: participant.id,
      track: participant.audioTrack,
      gain: 1.0,
      pan: 0.0
    });
    
    // Add audio processing for participant
    audioSource.addProcessor(new AutoGainControl({
      targetLevel: -20, // dB
      maxGain: 10, // dB
      compressionRatio: 2
    }));
    
    // Add to mixer
    await mixer.addSource(participant.id, audioSource);
    
    // Update stream participants
    stream.participants.set(participant.id, {
      id: participant.id,
      name: participant.name,
      joinedAt: Date.now(),
      speaking: false,
      volume: 1.0,
      muted: participant.muted
    });
    
    // Notify listeners
    await this.notifyParticipantChange(stream, 'joined', participant);
  }
  
  async removeParticipant(
    streamId: string,
    participantId: string
  ): Promise<void> {
    const stream = this.activeStreams.get(streamId);
    if (!stream) return;
    
    const mixer = this.audioMixers.get(stream.id);
    if (mixer) {
      await mixer.removeSource(participantId);
    }
    
    stream.participants.delete(participantId);
    
    // Notify listeners
    await this.notifyParticipantChange(stream, 'left', { id: participantId });
  }
  
  private async initializeStream(stream: VoiceStream) {
    const processor = this.streamProcessors.get(stream.id);
    if (!processor) throw new Error('Stream processor not found');
    
    // Create streaming endpoint
    const endpoint = await this.streamingService.createEndpoint({
      streamId: stream.id,
      format: 'audio/opus',
      bitrate: this.getBitrateForQuality(stream.config.quality)
    });
    
    // Start processing audio
    processor.on('data', async (audioData) => {
      await this.handleAudioData(stream, audioData);
    });
    
    processor.on('error', (error) => {
      console.error('Stream processor error:', error);
      this.handleStreamError(stream, error);
    });
    
    await processor.start();
    
    // Update stream state
    stream.state = 'active';
    stream.endpoint = endpoint;
    
    // Track stream start
    await this.analytics.track('voice_stream_started', {
      streamId: stream.id,
      channelId: stream.channelId,
      quality: stream.config.quality,
      privacy: stream.config.privacy
    });
  }
  
  private async handleAudioData(
    stream: VoiceStream,
    audioData: AudioData
  ) {
    // Send to streaming endpoint
    if (stream.endpoint) {
      await stream.endpoint.send(audioData.buffer);
    }
    
    // Handle recording if enabled
    if (stream.config.recordEnabled && stream.recorder) {
      await stream.recorder.write(audioData);
    }
    
    // Update metrics
    stream.metrics.audioQuality.bitrate = audioData.bitrate;
    
    // Broadcast to WebRTC listeners
    await this.broadcastToListeners(stream, audioData);
  }
  
  private async broadcastToListeners(
    stream: VoiceStream,
    audioData: AudioData
  ) {
    const listeners = Array.from(stream.listeners);
    
    // Batch send to all listeners
    await Promise.all(
      listeners.map(async (listenerId) => {
        try {
          await this.sendToListener(listenerId, audioData);
        } catch (error) {
          console.error(`Failed to send to listener ${listenerId}:`, error);
          stream.listeners.delete(listenerId);
        }
      })
    );
  }
  
  async stopStream(channelId: string): Promise<void> {
    const stream = this.activeStreams.get(channelId);
    if (!stream) return;
    
    console.log(`Stopping stream for channel ${channelId}`);
    
    // Stop processors
    const processor = this.streamProcessors.get(stream.id);
    if (processor) {
      await processor.stop();
      this.streamProcessors.delete(stream.id);
    }
    
    // Stop mixer
    const mixer = this.audioMixers.get(stream.id);
    if (mixer) {
      await mixer.stop();
      this.audioMixers.delete(stream.id);
    }
    
    // Finalize recording
    if (stream.recorder) {
      await stream.recorder.finalize();
    }
    
    // Close endpoint
    if (stream.endpoint) {
      await stream.endpoint.close();
    }
    
    // Update state
    stream.state = 'ended';
    stream.endTime = Date.now();
    
    // Remove from active streams
    this.activeStreams.delete(channelId);
    
    // Track stream end
    await this.analytics.track('voice_stream_ended', {
      streamId: stream.id,
      channelId: stream.channelId,
      duration: stream.endTime - stream.startTime,
      totalListeners: stream.metrics.totalListeners,
      peakListeners: stream.metrics.peakListeners
    });
  }
}
```

### 2. Stream Discovery and Metadata
```typescript
// Stream discovery system
export class StreamDiscoveryService {
  private liveStreams = new Map<string, StreamMetadata>();
  private categories = new Map<string, Set<string>>();
  private searchIndex: SearchIndex;
  
  constructor(
    private storage: StreamStorage,
    private recommendations: RecommendationEngine
  ) {
    this.searchIndex = new SearchIndex();
  }
  
  async registerStream(
    stream: VoiceStream,
    metadata: StreamMetadata
  ): Promise<void> {
    const enrichedMetadata: StreamMetadata = {
      ...metadata,
      streamId: stream.id,
      channelId: stream.channelId,
      waddleId: stream.waddleId,
      startTime: stream.startTime,
      live: true,
      listenerCount: 0,
      tags: this.extractTags(metadata),
      language: await this.detectLanguage(metadata),
      category: metadata.category || 'general',
      thumbnail: metadata.thumbnail || await this.generateThumbnail(stream)
    };
    
    // Store in live streams
    this.liveStreams.set(stream.id, enrichedMetadata);
    
    // Add to category index
    if (!this.categories.has(enrichedMetadata.category)) {
      this.categories.set(enrichedMetadata.category, new Set());
    }
    this.categories.get(enrichedMetadata.category)!.add(stream.id);
    
    // Update search index
    await this.searchIndex.add({
      id: stream.id,
      title: enrichedMetadata.title,
      description: enrichedMetadata.description,
      tags: enrichedMetadata.tags,
      category: enrichedMetadata.category,
      language: enrichedMetadata.language
    });
    
    // Notify discovery feed
    await this.notifyNewStream(enrichedMetadata);
  }
  
  async discoverStreams(
    params: DiscoveryParams
  ): Promise<DiscoveryResult> {
    let streams: StreamMetadata[] = [];
    
    if (params.query) {
      // Search streams
      const searchResults = await this.searchIndex.search(params.query, {
        limit: params.limit || 20,
        offset: params.offset || 0
      });
      
      streams = searchResults.map(id => this.liveStreams.get(id)!)
        .filter(Boolean);
        
    } else if (params.category) {
      // Get streams by category
      const categoryStreams = this.categories.get(params.category) || new Set();
      streams = Array.from(categoryStreams)
        .map(id => this.liveStreams.get(id)!)
        .filter(Boolean);
        
    } else {
      // Get all live streams
      streams = Array.from(this.liveStreams.values());
    }
    
    // Apply filters
    if (params.language) {
      streams = streams.filter(s => s.language === params.language);
    }
    
    if (params.minListeners) {
      streams = streams.filter(s => s.listenerCount >= params.minListeners);
    }
    
    // Sort streams
    streams = this.sortStreams(streams, params.sortBy || 'listeners');
    
    // Get recommendations if requested
    let recommendations: StreamMetadata[] = [];
    if (params.includeRecommendations && params.userId) {
      recommendations = await this.getRecommendations(params.userId);
    }
    
    return {
      streams: streams.slice(params.offset || 0, params.limit || 20),
      total: streams.length,
      recommendations,
      categories: this.getPopularCategories()
    };
  }
  
  private sortStreams(
    streams: StreamMetadata[],
    sortBy: string
  ): StreamMetadata[] {
    switch (sortBy) {
      case 'listeners':
        return streams.sort((a, b) => b.listenerCount - a.listenerCount);
      case 'newest':
        return streams.sort((a, b) => b.startTime - a.startTime);
      case 'trending':
        return streams.sort((a, b) => 
          this.calculateTrendingScore(b) - this.calculateTrendingScore(a)
        );
      default:
        return streams;
    }
  }
  
  private calculateTrendingScore(stream: StreamMetadata): number {
    const age = Date.now() - stream.startTime;
    const ageHours = age / (1000 * 60 * 60);
    
    // Trending score based on listeners and age
    return stream.listenerCount / Math.pow(ageHours + 2, 1.5);
  }
  
  async updateListenerCount(
    streamId: string,
    count: number
  ): Promise<void> {
    const metadata = this.liveStreams.get(streamId);
    if (!metadata) return;
    
    metadata.listenerCount = count;
    metadata.peakListeners = Math.max(metadata.peakListeners || 0, count);
    
    // Update trending scores
    await this.updateTrendingScores();
  }
}
```

### 3. Stream Player UI
```tsx
export function VoiceStreamPlayer({ 
  streamId 
}: { 
  streamId: string 
}) {
  const [stream, setStream] = useState<StreamInfo>();
  const [playing, setPlaying] = useState(false);
  const [volume, setVolume] = useState(100);
  const [quality, setQuality] = useState<'auto' | 'low' | 'medium' | 'high'>('auto');
  const [buffering, setBuffering] = useState(false);
  const [participants, setParticipants] = useState<StreamParticipant[]>([]);
  
  const audioRef = useRef<HTMLAudioElement>(null);
  const playerRef = useRef<StreamPlayer>();
  
  useEffect(() => {
    loadStream();
    
    return () => {
      playerRef.current?.destroy();
    };
  }, [streamId]);
  
  const loadStream = async () => {
    try {
      const streamInfo = await api.getStream(streamId);
      setStream(streamInfo);
      
      // Initialize player
      const player = new StreamPlayer({
        streamId,
        audioElement: audioRef.current!,
        quality: quality === 'auto' ? undefined : quality
      });
      
      player.on('buffering', () => setBuffering(true));
      player.on('playing', () => setBuffering(false));
      player.on('participants', (p) => setParticipants(p));
      player.on('error', (error) => {
        console.error('Player error:', error);
        toast.error('Failed to play stream');
      });
      
      playerRef.current = player;
      
      // Auto-play if requested
      if (streamInfo.autoPlay) {
        await play();
      }
    } catch (error) {
      toast.error('Failed to load stream');
    }
  };
  
  const play = async () => {
    try {
      await playerRef.current?.play();
      setPlaying(true);
    } catch (error) {
      toast.error('Failed to play stream');
    }
  };
  
  const pause = () => {
    playerRef.current?.pause();
    setPlaying(false);
  };
  
  const handleVolumeChange = (newVolume: number) => {
    setVolume(newVolume);
    if (audioRef.current) {
      audioRef.current.volume = newVolume / 100;
    }
  };
  
  const handleQualityChange = (newQuality: typeof quality) => {
    setQuality(newQuality);
    playerRef.current?.setQuality(newQuality === 'auto' ? undefined : newQuality);
  };
  
  if (!stream) return <LoadingSpinner />;
  
  return (
    <div className="voice-stream-player">
      <div className="player-header">
        <StreamThumbnail src={stream.thumbnail} alt={stream.title} />
        
        <div className="stream-info">
          <h3>{stream.title}</h3>
          <p>{stream.description}</p>
          
          <div className="stream-meta">
            <Badge variant="live">LIVE</Badge>
            <span className="listener-count">
              <UsersIcon /> {stream.listenerCount} listening
            </span>
            <span className="duration">
              Started {formatRelativeTime(stream.startTime)}
            </span>
          </div>
        </div>
      </div>
      
      <div className="player-participants">
        <h4>Speaking Now</h4>
        <ParticipantList
          participants={participants}
          showSpeakingIndicator={true}
        />
      </div>
      
      <div className="player-controls">
        <audio ref={audioRef} />
        
        <div className="playback-controls">
          <Button
            variant="primary"
            size="large"
            onClick={playing ? pause : play}
            disabled={buffering}
          >
            {buffering ? (
              <LoadingSpinner size="small" />
            ) : playing ? (
              <PauseIcon />
            ) : (
              <PlayIcon />
            )}
          </Button>
        </div>
        
        <div className="volume-controls">
          <Button
            variant="ghost"
            size="small"
            onClick={() => handleVolumeChange(volume > 0 ? 0 : 100)}
          >
            {volume === 0 ? <VolumeXIcon /> : <VolumeIcon />}
          </Button>
          
          <VolumeSlider
            value={volume}
            onChange={handleVolumeChange}
          />
        </div>
        
        <div className="quality-controls">
          <Select
            value={quality}
            onChange={(e) => handleQualityChange(e.target.value as any)}
            size="small"
          >
            <option value="auto">Auto</option>
            <option value="low">Low (32 kbps)</option>
            <option value="medium">Medium (64 kbps)</option>
            <option value="high">High (128 kbps)</option>
          </Select>
        </div>
        
        <div className="player-actions">
          <ShareButton stream={stream} />
          <FollowButton channelId={stream.channelId} />
          {stream.donationsEnabled && <DonateButton streamId={streamId} />}
        </div>
      </div>
      
      {stream.chatEnabled && (
        <StreamChat streamId={streamId} />
      )}
    </div>
  );
}

export function StreamDiscovery() {
  const [streams, setStreams] = useState<StreamMetadata[]>([]);
  const [loading, setLoading] = useState(true);
  const [category, setCategory] = useState<string>('all');
  const [sortBy, setSortBy] = useState<'listeners' | 'newest' | 'trending'>('listeners');
  const [searchQuery, setSearchQuery] = useState('');
  
  useEffect(() => {
    discoverStreams();
  }, [category, sortBy, searchQuery]);
  
  const discoverStreams = async () => {
    setLoading(true);
    try {
      const result = await api.discoverStreams({
        category: category === 'all' ? undefined : category,
        sortBy,
        query: searchQuery,
        limit: 20
      });
      
      setStreams(result.streams);
    } finally {
      setLoading(false);
    }
  };
  
  return (
    <div className="stream-discovery">
      <div className="discovery-header">
        <h2>Live Voice Streams</h2>
        
        <div className="discovery-filters">
          <SearchInput
            value={searchQuery}
            onChange={setSearchQuery}
            placeholder="Search streams..."
          />
          
          <CategoryFilter
            value={category}
            onChange={setCategory}
            categories={STREAM_CATEGORIES}
          />
          
          <SortSelector
            value={sortBy}
            onChange={setSortBy}
            options={[
              { value: 'listeners', label: 'Most Listeners' },
              { value: 'newest', label: 'Recently Started' },
              { value: 'trending', label: 'Trending' }
            ]}
          />
        </div>
      </div>
      
      {loading ? (
        <LoadingGrid />
      ) : (
        <div className="streams-grid">
          {streams.map(stream => (
            <StreamCard
              key={stream.streamId}
              stream={stream}
              onClick={() => navigateToStream(stream.streamId)}
            />
          ))}
        </div>
      )}
    </div>
  );
}

export function StreamCard({ 
  stream,
  onClick 
}: { 
  stream: StreamMetadata;
  onClick: () => void;
}) {
  return (
    <div className="stream-card" onClick={onClick}>
      <div className="card-thumbnail">
        <img src={stream.thumbnail} alt={stream.title} />
        
        <div className="card-badges">
          <Badge variant="live">LIVE</Badge>
          {stream.listenerCount > 0 && (
            <Badge variant="secondary">
              {stream.listenerCount} listening
            </Badge>
          )}
        </div>
      </div>
      
      <div className="card-info">
        <h4>{stream.title}</h4>
        <p className="card-channel">{stream.channelName}</p>
        <p className="card-category">{stream.category}</p>
        
        <div className="card-tags">
          {stream.tags.slice(0, 3).map(tag => (
            <Tag key={tag}>{tag}</Tag>
          ))}
        </div>
      </div>
    </div>
  );
}
```

### 4. Stream Management Dashboard
```tsx
export function StreamManagementDashboard({ 
  channelId 
}: { 
  channelId: string 
}) {
  const [stream, setStream] = useState<VoiceStream>();
  const [stats, setStats] = useState<StreamStats>();
  const [settings, setSettings] = useState<StreamSettings>();
  const [isStreaming, setIsStreaming] = useState(false);
  
  useEffect(() => {
    checkStreamStatus();
    
    if (isStreaming) {
      const interval = setInterval(updateStats, 5000);
      return () => clearInterval(interval);
    }
  }, [channelId, isStreaming]);
  
  const checkStreamStatus = async () => {
    const status = await api.getStreamStatus(channelId);
    setIsStreaming(status.active);
    if (status.active) {
      setStream(status.stream);
      await loadSettings();
    }
  };
  
  const updateStats = async () => {
    const newStats = await api.getStreamStats(channelId);
    setStats(newStats);
  };
  
  const startStream = async () => {
    try {
      const config: VoiceStreamConfig = {
        channelId,
        streamTitle: settings?.title || 'Live Voice Stream',
        description: settings?.description,
        quality: settings?.quality || 'high',
        privacy: settings?.privacy || 'public',
        recordEnabled: settings?.recordEnabled || false,
        chatEnabled: settings?.chatEnabled || true,
        donationsEnabled: settings?.donationsEnabled || false
      };
      
      const newStream = await api.startVoiceStream(config);
      setStream(newStream);
      setIsStreaming(true);
      
      toast.success('Stream started successfully');
    } catch (error) {
      toast.error('Failed to start stream');
    }
  };
  
  const stopStream = async () => {
    const confirmed = await confirm(
      'Stop Stream',
      'Are you sure you want to stop the stream?'
    );
    
    if (!confirmed) return;
    
    try {
      await api.stopVoiceStream(channelId);
      setIsStreaming(false);
      setStream(undefined);
      
      toast.info('Stream stopped');
    } catch (error) {
      toast.error('Failed to stop stream');
    }
  };
  
  const updateSettings = async (newSettings: Partial<StreamSettings>) => {
    try {
      const updated = { ...settings, ...newSettings };
      await api.updateStreamSettings(channelId, updated);
      setSettings(updated);
      
      toast.success('Settings updated');
    } catch (error) {
      toast.error('Failed to update settings');
    }
  };
  
  return (
    <div className="stream-management">
      <div className="management-header">
        <h3>Voice Stream Management</h3>
        <Badge variant={isStreaming ? 'success' : 'default'}>
          {isStreaming ? 'STREAMING' : 'OFFLINE'}
        </Badge>
      </div>
      
      {!isStreaming ? (
        <StreamSetup
          settings={settings}
          onSettingsChange={updateSettings}
          onStart={startStream}
        />
      ) : (
        <div className="stream-dashboard">
          <StreamControls
            stream={stream!}
            onStop={stopStream}
            onSettingsChange={updateSettings}
          />
          
          <StreamStatsPanel stats={stats} />
          
          <div className="dashboard-grid">
            <ListenerMetrics
              current={stats?.listeners.current || 0}
              peak={stats?.listeners.peak || 0}
              total={stats?.listeners.total || 0}
            />
            
            <AudioQualityMonitor
              bitrate={stats?.audio.bitrate || 0}
              packetLoss={stats?.audio.packetLoss || 0}
            />
            
            <EngagementMetrics
              messages={stats?.engagement.messages || 0}
              reactions={stats?.engagement.reactions || 0}
              donations={stats?.engagement.donations || 0}
            />
          </div>
          
          <ListenerMap listeners={stats?.listeners.geographic} />
          
          <StreamRecording
            streamId={stream!.id}
            recordingEnabled={stream!.config.recordEnabled}
          />
        </div>
      )}
    </div>
  );
}

export function StreamSetup({
  settings,
  onSettingsChange,
  onStart
}: {
  settings?: StreamSettings;
  onSettingsChange: (settings: Partial<StreamSettings>) => void;
  onStart: () => void;
}) {
  const [title, setTitle] = useState(settings?.title || '');
  const [description, setDescription] = useState(settings?.description || '');
  const [quality, setQuality] = useState(settings?.quality || 'high');
  const [privacy, setPrivacy] = useState(settings?.privacy || 'public');
  const [recordEnabled, setRecordEnabled] = useState(settings?.recordEnabled || false);
  const [chatEnabled, setChatEnabled] = useState(settings?.chatEnabled || true);
  const [donationsEnabled, setDonationsEnabled] = useState(settings?.donationsEnabled || false);
  
  const handleSave = () => {
    onSettingsChange({
      title,
      description,
      quality,
      privacy,
      recordEnabled,
      chatEnabled,
      donationsEnabled
    });
  };
  
  return (
    <div className="stream-setup">
      <div className="setup-form">
        <FormField label="Stream Title">
          <Input
            value={title}
            onChange={(e) => setTitle(e.target.value)}
            placeholder="Enter stream title..."
            maxLength={100}
          />
        </FormField>
        
        <FormField label="Description">
          <Textarea
            value={description}
            onChange={(e) => setDescription(e.target.value)}
            placeholder="Describe your stream..."
            rows={3}
            maxLength={500}
          />
        </FormField>
        
        <FormField label="Audio Quality">
          <Select value={quality} onChange={(e) => setQuality(e.target.value)}>
            <option value="low">Low (32 kbps)</option>
            <option value="medium">Medium (64 kbps)</option>
            <option value="high">High (128 kbps)</option>
            <option value="ultra">Ultra (256 kbps)</option>
          </Select>
        </FormField>
        
        <FormField label="Privacy">
          <RadioGroup value={privacy} onChange={setPrivacy}>
            <Radio value="public">
              <div>
                <strong>Public</strong>
                <p>Anyone can discover and listen</p>
              </div>
            </Radio>
            <Radio value="unlisted">
              <div>
                <strong>Unlisted</strong>
                <p>Only people with the link can listen</p>
              </div>
            </Radio>
            <Radio value="private">
              <div>
                <strong>Private</strong>
                <p>Only waddle members can listen</p>
              </div>
            </Radio>
          </RadioGroup>
        </FormField>
        
        <div className="setup-options">
          <Toggle
            checked={recordEnabled}
            onChange={setRecordEnabled}
            label="Record Stream"
            description="Save a recording for later playback"
          />
          
          <Toggle
            checked={chatEnabled}
            onChange={setChatEnabled}
            label="Enable Chat"
            description="Allow listeners to chat during the stream"
          />
          
          <Toggle
            checked={donationsEnabled}
            onChange={setDonationsEnabled}
            label="Accept Donations"
            description="Allow listeners to send tips"
          />
        </div>
        
        <div className="setup-actions">
          <Button variant="secondary" onClick={handleSave}>
            Save Settings
          </Button>
          
          <Button
            variant="primary"
            size="large"
            onClick={onStart}
            disabled={!title}
          >
            Start Streaming
          </Button>
        </div>
      </div>
      
      <StreamingTips />
    </div>
  );
}
```

### 5. Audio Processing Pipeline
```typescript
// Advanced audio processing for streams
export class StreamAudioProcessor {
  private audioContext: AudioContext;
  private sourceNodes = new Map<string, MediaStreamAudioSourceNode>();
  private gainNodes = new Map<string, GainNode>();
  private analyserNodes = new Map<string, AnalyserNode>();
  private processorNode: AudioWorkletNode;
  private outputNode: MediaStreamAudioDestinationNode;
  
  constructor(config: AudioProcessorConfig) {
    this.audioContext = new AudioContext({
      sampleRate: config.sampleRate || 48000,
      latencyHint: 'interactive'
    });
    
    this.setupProcessingPipeline();
  }
  
  private async setupProcessingPipeline() {
    // Load audio worklet for custom processing
    await this.audioContext.audioWorklet.addModule('/audio-processor.js');
    
    // Create processor node
    this.processorNode = new AudioWorkletNode(
      this.audioContext,
      'stream-processor',
      {
        numberOfInputs: 1,
        numberOfOutputs: 1,
        channelCount: 2,
        processorOptions: {
          features: ['noise-gate', 'compressor', 'eq', 'limiter']
        }
      }
    );
    
    // Create output destination
    this.outputNode = this.audioContext.createMediaStreamDestination();
    
    // Connect processor to output
    this.processorNode.connect(this.outputNode);
    
    // Set up message handling
    this.processorNode.port.onmessage = (event) => {
      this.handleProcessorMessage(event.data);
    };
  }
  
  async addParticipant(
    participantId: string,
    stream: MediaStream
  ): Promise<void> {
    // Create source node from stream
    const sourceNode = this.audioContext.createMediaStreamSource(stream);
    
    // Create gain node for individual volume control
    const gainNode = this.audioContext.createGain();
    gainNode.gain.value = 1.0;
    
    // Create analyser for level monitoring
    const analyserNode = this.audioContext.createAnalyser();
    analyserNode.fftSize = 2048;
    analyserNode.smoothingTimeConstant = 0.8;
    
    // Connect nodes
    sourceNode.connect(gainNode);
    gainNode.connect(analyserNode);
    analyserNode.connect(this.processorNode);
    
    // Store nodes
    this.sourceNodes.set(participantId, sourceNode);
    this.gainNodes.set(participantId, gainNode);
    this.analyserNodes.set(participantId, analyserNode);
    
    // Start level monitoring
    this.startLevelMonitoring(participantId);
  }
  
  private startLevelMonitoring(participantId: string) {
    const analyser = this.analyserNodes.get(participantId);
    if (!analyser) return;
    
    const dataArray = new Float32Array(analyser.frequencyBinCount);
    
    const monitor = () => {
      analyser.getFloatTimeDomainData(dataArray);
      
      // Calculate RMS level
      let sum = 0;
      for (let i = 0; i < dataArray.length; i++) {
        sum += dataArray[i] * dataArray[i];
      }
      const rms = Math.sqrt(sum / dataArray.length);
      const db = 20 * Math.log10(rms);
      
      // Emit level update
      this.emit('level', {
        participantId,
        level: db,
        speaking: db > -40
      });
      
      requestAnimationFrame(monitor);
    };
    
    monitor();
  }
  
  setParticipantVolume(participantId: string, volume: number) {
    const gainNode = this.gainNodes.get(participantId);
    if (!gainNode) return;
    
    // Smooth volume change to avoid clicks
    gainNode.gain.linearRampToValueAtTime(
      volume,
      this.audioContext.currentTime + 0.1
    );
  }
  
  muteParticipant(participantId: string, muted: boolean) {
    const gainNode = this.gainNodes.get(participantId);
    if (!gainNode) return;
    
    if (muted) {
      gainNode.gain.linearRampToValueAtTime(
        0,
        this.audioContext.currentTime + 0.05
      );
    } else {
      gainNode.gain.linearRampToValueAtTime(
        1.0,
        this.audioContext.currentTime + 0.05
      );
    }
  }
  
  updateProcessingSettings(settings: ProcessingSettings) {
    this.processorNode.port.postMessage({
      type: 'update-settings',
      settings
    });
  }
  
  getOutputStream(): MediaStream {
    return this.outputNode.stream;
  }
  
  private handleProcessorMessage(data: any) {
    switch (data.type) {
      case 'clipping':
        console.warn('Audio clipping detected');
        this.emit('clipping', data);
        break;
        
      case 'silence':
        this.emit('silence', data);
        break;
        
      case 'metrics':
        this.emit('metrics', data.metrics);
        break;
    }
  }
  
  async removeParticipant(participantId: string) {
    // Disconnect nodes
    const sourceNode = this.sourceNodes.get(participantId);
    const gainNode = this.gainNodes.get(participantId);
    const analyserNode = this.analyserNodes.get(participantId);
    
    if (sourceNode) {
      sourceNode.disconnect();
      this.sourceNodes.delete(participantId);
    }
    
    if (gainNode) {
      gainNode.disconnect();
      this.gainNodes.delete(participantId);
    }
    
    if (analyserNode) {
      analyserNode.disconnect();
      this.analyserNodes.delete(participantId);
    }
  }
  
  async destroy() {
    // Disconnect all nodes
    for (const [id] of this.sourceNodes) {
      await this.removeParticipant(id);
    }
    
    // Close audio context
    await this.audioContext.close();
  }
}
```

### 6. Stream Analytics
```typescript
// Stream analytics and insights
export class StreamAnalytics {
  private activeStreams = new Map<string, StreamMetrics>();
  
  constructor(
    private analytics: AnalyticsService,
    private storage: MetricsStorage
  ) {}
  
  async trackStreamStart(stream: VoiceStream) {
    const metrics: StreamMetrics = {
      streamId: stream.id,
      channelId: stream.channelId,
      startTime: stream.startTime,
      listeners: {
        current: 0,
        peak: 0,
        total: 0,
        uniqueListeners: new Set(),
        avgListenTime: 0,
        geographic: new Map()
      },
      audio: {
        bitrate: 0,
        packetLoss: 0,
        quality: 'unknown'
      },
      engagement: {
        messages: 0,
        reactions: 0,
        donations: 0,
        shares: 0
      },
      participants: {
        total: 0,
        speakingTime: new Map()
      }
    };
    
    this.activeStreams.set(stream.id, metrics);
    
    await this.analytics.track('stream_started', {
      streamId: stream.id,
      channelId: stream.channelId,
      quality: stream.config.quality,
      privacy: stream.config.privacy
    });
  }
  
  async trackListenerJoin(
    streamId: string,
    listener: ListenerInfo
  ) {
    const metrics = this.activeStreams.get(streamId);
    if (!metrics) return;
    
    metrics.listeners.current++;
    metrics.listeners.total++;
    metrics.listeners.uniqueListeners.add(listener.id);
    metrics.listeners.peak = Math.max(
      metrics.listeners.peak,
      metrics.listeners.current
    );
    
    // Track geographic distribution
    const country = listener.location?.country || 'unknown';
    const currentCount = metrics.listeners.geographic.get(country) || 0;
    metrics.listeners.geographic.set(country, currentCount + 1);
    
    await this.analytics.track('listener_joined', {
      streamId,
      listenerId: listener.id,
      location: listener.location,
      device: listener.device
    });
  }
  
  async trackEngagement(
    streamId: string,
    type: 'message' | 'reaction' | 'donation' | 'share',
    data?: any
  ) {
    const metrics = this.activeStreams.get(streamId);
    if (!metrics) return;
    
    metrics.engagement[type + 's']++;
    
    await this.analytics.track(`stream_${type}`, {
      streamId,
      ...data
    });
  }
  
  async generateStreamReport(streamId: string): Promise<StreamReport> {
    const metrics = this.activeStreams.get(streamId);
    if (!metrics) throw new Error('Stream metrics not found');
    
    const duration = Date.now() - metrics.startTime;
    
    return {
      summary: {
        streamId,
        duration,
        totalListeners: metrics.listeners.uniqueListeners.size,
        peakListeners: metrics.listeners.peak,
        avgListenTime: metrics.listeners.avgListenTime,
        engagementRate: this.calculateEngagementRate(metrics)
      },
      geographic: {
        countries: Array.from(metrics.listeners.geographic.entries())
          .map(([country, count]) => ({ country, count }))
          .sort((a, b) => b.count - a.count)
      },
      engagement: {
        messages: metrics.engagement.messages,
        reactions: metrics.engagement.reactions,
        donations: metrics.engagement.donations,
        shares: metrics.engagement.shares,
        messagesPerListener: metrics.engagement.messages / 
          Math.max(1, metrics.listeners.uniqueListeners.size)
      },
      audio: {
        avgBitrate: metrics.audio.bitrate,
        avgPacketLoss: metrics.audio.packetLoss,
        qualityScore: this.calculateQualityScore(metrics.audio)
      },
      highlights: await this.generateHighlights(metrics)
    };
  }
  
  private calculateEngagementRate(metrics: StreamMetrics): number {
    const totalEngagements = 
      metrics.engagement.messages +
      metrics.engagement.reactions +
      metrics.engagement.donations +
      metrics.engagement.shares;
      
    return totalEngagements / 
      Math.max(1, metrics.listeners.uniqueListeners.size);
  }
  
  private calculateQualityScore(audio: any): number {
    let score = 100;
    
    // Deduct for packet loss
    score -= Math.min(audio.packetLoss * 10, 30);
    
    // Deduct for low bitrate
    if (audio.bitrate < 32000) score -= 20;
    else if (audio.bitrate < 64000) score -= 10;
    
    return Math.max(0, score);
  }
}
```

## Dependencies
- Voice channel infrastructure
- Audio processing pipeline
- Streaming service (HLS/WebRTC)
- Discovery and search system
- Analytics platform
- Storage for recordings

## Estimated Effort
**6 days**
- 1 day: Core streaming functionality
- 1 day: Audio processing pipeline
- 1 day: Stream discovery system
- 1 day: Player and UI components
- 1 day: Management dashboard
- 1 day: Analytics and monitoring

## Notes
- Ensure low latency for live experience
- Implement consent management
- Add monetization options
- Consider copyright detection
- Enable scheduled streams
- Support multi-language streams
- Plan for scalability