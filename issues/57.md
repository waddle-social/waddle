# Issue #57: Load Testing

## User Story
As a **platform operator**, I want to **conduct comprehensive load testing for 10K concurrent users** so that **we can ensure Waddle performs reliably at scale**.

## Description
Implement a comprehensive load testing framework that can simulate 10,000 concurrent users across various usage patterns. This includes voice/video calls, screen sharing, chat messaging, and file uploads to validate system performance under extreme load conditions.

## Acceptance Criteria
- [ ] Support 10K concurrent WebSocket connections
- [ ] Simulate realistic user behavior patterns
- [ ] Test voice/video with 1000+ simultaneous calls
- [ ] Validate chat message throughput (100K+ msgs/min)
- [ ] Test file upload under load (500+ concurrent)
- [ ] Monitor resource utilization across services
- [ ] Generate detailed performance reports
- [ ] Identify and document bottlenecks

## Technical Implementation

### 1. Load Testing Framework
```typescript
// Load testing orchestrator
export class LoadTestOrchestrator {
  private workers: LoadTestWorker[] = [];
  private metrics: MetricsCollector;
  private scenarios: Map<string, TestScenario>;
  
  constructor(
    private config: LoadTestConfig,
    private monitoring: MonitoringService
  ) {
    this.metrics = new MetricsCollector();
    this.scenarios = this.buildScenarios();
  }
  
  async runLoadTest(testPlan: TestPlan): Promise<LoadTestResult> {
    console.log(`Starting load test: ${testPlan.name}`);
    
    // Initialize workers
    await this.initializeWorkers(testPlan.workerCount);
    
    // Start monitoring
    const monitoringSession = await this.monitoring.startSession({
      testId: testPlan.id,
      metrics: ['cpu', 'memory', 'network', 'latency', 'errors']
    });
    
    // Execute test phases
    const results: PhaseResult[] = [];
    
    for (const phase of testPlan.phases) {
      console.log(`Executing phase: ${phase.name}`);
      const phaseResult = await this.executePhase(phase);
      results.push(phaseResult);
      
      // Check for stop conditions
      if (this.shouldStopTest(phaseResult)) {
        console.log('Stop condition met, ending test');
        break;
      }
    }
    
    // Stop monitoring and collect results
    const monitoringData = await monitoringSession.stop();
    
    // Generate report
    return this.generateReport({
      testPlan,
      phases: results,
      monitoring: monitoringData,
      summary: this.calculateSummary(results)
    });
  }
  
  private async executePhase(phase: TestPhase): Promise<PhaseResult> {
    const startTime = Date.now();
    const phaseMetrics = new PhaseMetrics();
    
    // Ramp up users
    await this.rampUpUsers(phase.targetUsers, phase.rampUpTime);
    
    // Execute scenarios
    const scenarioPromises = phase.scenarios.map(scenarioConfig => 
      this.executeScenario(scenarioConfig, phaseMetrics)
    );
    
    // Run for specified duration
    const duration = phase.duration || 300000; // 5 minutes default
    await Promise.race([
      Promise.all(scenarioPromises),
      new Promise(resolve => setTimeout(resolve, duration))
    ]);
    
    // Collect results
    return {
      phase: phase.name,
      duration: Date.now() - startTime,
      metrics: phaseMetrics.getResults(),
      errors: phaseMetrics.getErrors()
    };
  }
  
  private async executeScenario(
    config: ScenarioConfig,
    metrics: PhaseMetrics
  ): Promise<void> {
    const scenario = this.scenarios.get(config.type);
    if (!scenario) throw new Error(`Unknown scenario: ${config.type}`);
    
    // Distribute scenario across workers
    const usersPerWorker = Math.ceil(config.users / this.workers.length);
    
    const workerTasks = this.workers.map((worker, index) => {
      const userCount = Math.min(
        usersPerWorker,
        config.users - (index * usersPerWorker)
      );
      
      return worker.executeScenario({
        scenario: scenario.name,
        users: userCount,
        config: config.parameters,
        metricsCollector: metrics
      });
    });
    
    await Promise.all(workerTasks);
  }
}

// Load test scenarios
export class TestScenario {
  constructor(
    public name: string,
    private actions: UserAction[]
  ) {}
  
  async execute(context: UserContext): Promise<void> {
    for (const action of this.actions) {
      try {
        await action.execute(context);
        
        // Record success
        context.metrics.recordSuccess(action.name);
        
        // Think time
        if (action.thinkTime) {
          await this.sleep(action.thinkTime);
        }
      } catch (error) {
        // Record failure
        context.metrics.recordError(action.name, error);
        
        if (action.critical) {
          throw error; // Stop scenario on critical action failure
        }
      }
    }
  }
}

// Common scenarios
export const SCENARIOS = {
  voiceCall: new TestScenario('Voice Call', [
    new ConnectWebSocketAction(),
    new JoinWaddleAction(),
    new JoinVoiceChannelAction(),
    new SimulateAudioStreamAction({ duration: 180000 }), // 3 minutes
    new LeaveVoiceChannelAction()
  ]),
  
  videoCall: new TestScenario('Video Call', [
    new ConnectWebSocketAction(),
    new JoinWaddleAction(),
    new JoinVoiceChannelAction(),
    new EnableVideoAction(),
    new SimulateVideoStreamAction({ 
      duration: 120000, // 2 minutes
      resolution: '720p',
      fps: 30
    }),
    new DisableVideoAction(),
    new LeaveVoiceChannelAction()
  ]),
  
  screenShare: new TestScenario('Screen Share', [
    new ConnectWebSocketAction(),
    new JoinWaddleAction(),
    new JoinVoiceChannelAction(),
    new StartScreenShareAction({
      resolution: '1080p',
      fps: 15
    }),
    new SimulateScreenContentAction({ duration: 90000 }),
    new StopScreenShareAction(),
    new LeaveVoiceChannelAction()
  ]),
  
  chatMessaging: new TestScenario('Chat Messaging', [
    new ConnectWebSocketAction(),
    new JoinWaddleAction(),
    new SendMessagesAction({
      count: 100,
      interval: 2000, // 2 seconds between messages
      sizeRange: { min: 10, max: 200 }
    }),
    new ReceiveMessagesAction({
      expectedRate: 50 // messages per minute
    })
  ]),
  
  fileUpload: new TestScenario('File Upload', [
    new ConnectWebSocketAction(),
    new JoinWaddleAction(),
    new UploadFileAction({
      size: 10 * 1024 * 1024, // 10MB
      chunkSize: 64 * 1024 // 64KB chunks
    }),
    new VerifyFileUploadAction()
  ]),
  
  mixedUsage: new TestScenario('Mixed Usage', [
    new ConnectWebSocketAction(),
    new JoinWaddleAction(),
    new ParallelActions([
      new JoinVoiceChannelAction(),
      new SendMessagesAction({ 
        count: 50, 
        interval: 5000 
      }),
      new ReactToMessagesAction({
        probability: 0.3
      })
    ]),
    new ConditionalAction(
      () => Math.random() > 0.5,
      new EnableVideoAction()
    ),
    new WaitAction(60000), // 1 minute
    new LeaveVoiceChannelAction()
  ])
};
```

### 2. Load Test Worker
```typescript
// Distributed load test worker
export class LoadTestWorker {
  private virtualUsers: Map<string, VirtualUser> = new Map();
  private websocketPool: WebSocketPool;
  private resourceMonitor: ResourceMonitor;
  
  constructor(
    private workerId: string,
    private config: WorkerConfig
  ) {
    this.websocketPool = new WebSocketPool(config.maxConnections);
    this.resourceMonitor = new ResourceMonitor();
  }
  
  async executeScenario(params: ScenarioExecutionParams): Promise<void> {
    const users: VirtualUser[] = [];
    
    // Create virtual users
    for (let i = 0; i < params.users; i++) {
      const user = new VirtualUser({
        id: `${this.workerId}-user-${i}`,
        scenario: params.scenario,
        config: params.config
      });
      
      users.push(user);
      this.virtualUsers.set(user.id, user);
    }
    
    // Execute scenarios in parallel with controlled concurrency
    const concurrency = this.config.maxConcurrency || 100;
    const chunks = this.chunkArray(users, concurrency);
    
    for (const chunk of chunks) {
      await Promise.all(
        chunk.map(user => this.runUserScenario(user, params.metricsCollector))
      );
    }
  }
  
  private async runUserScenario(
    user: VirtualUser,
    metrics: MetricsCollector
  ): Promise<void> {
    const context = new UserContext({
      user,
      websocket: await this.websocketPool.acquire(),
      metrics,
      startTime: Date.now()
    });
    
    try {
      const scenario = SCENARIOS[user.scenario];
      await scenario.execute(context);
    } finally {
      // Release resources
      this.websocketPool.release(context.websocket);
      this.virtualUsers.delete(user.id);
    }
  }
}

// Virtual user simulation
export class VirtualUser {
  public state: UserState;
  private behaviorProfile: BehaviorProfile;
  
  constructor(private config: VirtualUserConfig) {
    this.state = new UserState();
    this.behaviorProfile = this.generateBehaviorProfile();
  }
  
  private generateBehaviorProfile(): BehaviorProfile {
    // Create realistic user behavior patterns
    return {
      messageFrequency: this.randomGaussian(30, 10), // msgs per hour
      voiceActivity: this.randomGaussian(0.4, 0.1), // 40% speaking time
      videoEnabled: Math.random() > 0.3, // 70% use video
      screenShareProbability: 0.1, // 10% share screen
      reactionTime: this.randomGaussian(2000, 500), // 2s avg reaction
      sessionDuration: this.randomGaussian(1800000, 600000) // 30min avg
    };
  }
  
  async simulateAudioStream(params: AudioStreamParams): Promise<void> {
    const audioGenerator = new AudioStreamGenerator({
      sampleRate: 48000,
      channels: 1,
      bitDepth: 16,
      codec: 'opus'
    });
    
    const voiceDetector = new VoiceActivityDetector();
    let speaking = false;
    
    while (params.active) {
      // Simulate voice activity based on profile
      const shouldSpeak = Math.random() < this.behaviorProfile.voiceActivity;
      
      if (shouldSpeak !== speaking) {
        speaking = shouldSpeak;
        await params.onVoiceStateChange(speaking);
      }
      
      if (speaking) {
        // Generate and send audio packets
        const audioData = audioGenerator.generatePacket();
        await params.sendAudioPacket({
          timestamp: Date.now(),
          data: audioData,
          speaking: true
        });
      }
      
      // Opus frame time (20ms)
      await this.sleep(20);
    }
  }
  
  async simulateVideoStream(params: VideoStreamParams): Promise<void> {
    const videoGenerator = new VideoStreamGenerator({
      width: params.width || 1280,
      height: params.height || 720,
      fps: params.fps || 30,
      codec: 'h264'
    });
    
    const frameInterval = 1000 / params.fps;
    let lastFrameTime = Date.now();
    
    while (params.active) {
      const now = Date.now();
      const elapsed = now - lastFrameTime;
      
      if (elapsed >= frameInterval) {
        // Generate and send video frame
        const frame = videoGenerator.generateFrame();
        
        await params.sendVideoFrame({
          timestamp: now,
          frame: frame,
          keyFrame: frame.isKeyFrame
        });
        
        lastFrameTime = now;
      }
      
      // Small sleep to prevent CPU spinning
      await this.sleep(5);
    }
  }
}
```

### 3. Performance Metrics Collection
```typescript
// Metrics collector for load testing
export class MetricsCollector {
  private metrics: Map<string, Metric> = new Map();
  private errors: ErrorLog[] = [];
  private startTime: number = Date.now();
  
  recordLatency(operation: string, latency: number): void {
    this.getMetric(operation).recordLatency(latency);
  }
  
  recordThroughput(operation: string, count: number = 1): void {
    this.getMetric(operation).recordThroughput(count);
  }
  
  recordError(operation: string, error: any): void {
    this.errors.push({
      timestamp: Date.now(),
      operation,
      error: error.message || error,
      stack: error.stack
    });
    
    this.getMetric(operation).recordError();
  }
  
  private getMetric(name: string): Metric {
    if (!this.metrics.has(name)) {
      this.metrics.set(name, new Metric(name));
    }
    return this.metrics.get(name)!;
  }
  
  getResults(): MetricsResult {
    const results: MetricsResult = {
      duration: Date.now() - this.startTime,
      operations: {}
    };
    
    for (const [name, metric] of this.metrics) {
      results.operations[name] = metric.getSummary();
    }
    
    return results;
  }
}

export class Metric {
  private latencies: number[] = [];
  private throughput: number = 0;
  private errors: number = 0;
  private startTime: number = Date.now();
  
  constructor(public name: string) {}
  
  recordLatency(latency: number): void {
    this.latencies.push(latency);
  }
  
  recordThroughput(count: number): void {
    this.throughput += count;
  }
  
  recordError(): void {
    this.errors++;
  }
  
  getSummary(): MetricSummary {
    const sorted = [...this.latencies].sort((a, b) => a - b);
    const duration = (Date.now() - this.startTime) / 1000; // seconds
    
    return {
      count: this.latencies.length,
      throughput: this.throughput,
      throughputPerSecond: this.throughput / duration,
      errors: this.errors,
      errorRate: this.errors / (this.latencies.length + this.errors),
      latency: {
        min: sorted[0] || 0,
        max: sorted[sorted.length - 1] || 0,
        mean: this.calculateMean(sorted),
        median: this.calculatePercentile(sorted, 50),
        p95: this.calculatePercentile(sorted, 95),
        p99: this.calculatePercentile(sorted, 99)
      }
    };
  }
  
  private calculateMean(values: number[]): number {
    if (values.length === 0) return 0;
    return values.reduce((a, b) => a + b, 0) / values.length;
  }
  
  private calculatePercentile(sorted: number[], percentile: number): number {
    if (sorted.length === 0) return 0;
    const index = Math.ceil((percentile / 100) * sorted.length) - 1;
    return sorted[Math.max(0, index)];
  }
}
```

### 4. Resource Monitoring
```typescript
// System resource monitoring during load tests
export class ResourceMonitor {
  private samples: ResourceSample[] = [];
  private interval: NodeJS.Timer;
  
  startMonitoring(intervalMs: number = 1000): void {
    this.interval = setInterval(() => {
      this.collectSample();
    }, intervalMs);
  }
  
  stopMonitoring(): ResourceReport {
    clearInterval(this.interval);
    return this.generateReport();
  }
  
  private async collectSample(): Promise<void> {
    const sample: ResourceSample = {
      timestamp: Date.now(),
      cpu: await this.getCPUUsage(),
      memory: this.getMemoryUsage(),
      network: await this.getNetworkStats(),
      connections: await this.getConnectionStats()
    };
    
    this.samples.push(sample);
  }
  
  private async getCPUUsage(): Promise<CPUStats> {
    // Platform-specific CPU monitoring
    const usage = process.cpuUsage();
    const cores = os.cpus().length;
    
    return {
      user: usage.user / 1000000, // Convert to seconds
      system: usage.system / 1000000,
      total: (usage.user + usage.system) / 1000000,
      cores,
      loadAverage: os.loadavg()
    };
  }
  
  private getMemoryUsage(): MemoryStats {
    const nodeMemory = process.memoryUsage();
    const systemMemory = {
      total: os.totalmem(),
      free: os.freemem()
    };
    
    return {
      heapUsed: nodeMemory.heapUsed,
      heapTotal: nodeMemory.heapTotal,
      rss: nodeMemory.rss,
      external: nodeMemory.external,
      systemTotal: systemMemory.total,
      systemFree: systemMemory.free,
      systemUsedPercent: ((systemMemory.total - systemMemory.free) / systemMemory.total) * 100
    };
  }
  
  private async getNetworkStats(): Promise<NetworkStats> {
    // Implement network monitoring
    // This would integrate with system tools or APIs
    return {
      bytesIn: 0,
      bytesOut: 0,
      packetsIn: 0,
      packetsOut: 0,
      errors: 0,
      dropped: 0
    };
  }
  
  private async getConnectionStats(): Promise<ConnectionStats> {
    return {
      websockets: WebSocketPool.getActiveConnections(),
      http: await this.getHTTPConnections(),
      database: await this.getDatabaseConnections(),
      redis: await this.getRedisConnections()
    };
  }
  
  private generateReport(): ResourceReport {
    if (this.samples.length === 0) {
      return { samples: [], summary: {} };
    }
    
    return {
      samples: this.samples,
      summary: {
        cpu: this.summarizeCPU(),
        memory: this.summarizeMemory(),
        network: this.summarizeNetwork()
      }
    };
  }
}
```

### 5. Load Test Configuration
```typescript
// Test configuration and plans
export interface LoadTestConfig {
  target: {
    url: string;
    environment: 'staging' | 'production';
  };
  workers: {
    count: number;
    regions: string[];
    instanceType: string;
  };
  monitoring: {
    metricsInterval: number;
    alertThresholds: AlertThresholds;
  };
  limits: {
    maxDuration: number;
    maxErrors: number;
    maxLatency: number;
  };
}

export interface TestPlan {
  id: string;
  name: string;
  description: string;
  workerCount: number;
  phases: TestPhase[];
  successCriteria: SuccessCriteria;
}

// Pre-defined test plans
export const TEST_PLANS = {
  baseline: {
    id: 'baseline',
    name: 'Baseline Performance',
    description: 'Establish baseline metrics with light load',
    workerCount: 1,
    phases: [
      {
        name: 'Warm-up',
        targetUsers: 100,
        rampUpTime: 60000,
        duration: 300000,
        scenarios: [
          { type: 'mixedUsage', users: 100, parameters: {} }
        ]
      }
    ],
    successCriteria: {
      maxErrorRate: 0.01,
      maxLatencyP99: 1000
    }
  },
  
  stress: {
    id: 'stress',
    name: '10K User Stress Test',
    description: 'Test system limits with 10,000 concurrent users',
    workerCount: 10,
    phases: [
      {
        name: 'Ramp-up',
        targetUsers: 1000,
        rampUpTime: 300000, // 5 minutes
        duration: 600000, // 10 minutes
        scenarios: [
          { type: 'voiceCall', users: 300 },
          { type: 'videoCall', users: 200 },
          { type: 'chatMessaging', users: 400 },
          { type: 'fileUpload', users: 100 }
        ]
      },
      {
        name: 'Sustained Load',
        targetUsers: 5000,
        rampUpTime: 600000, // 10 minutes
        duration: 1800000, // 30 minutes
        scenarios: [
          { type: 'voiceCall', users: 1500 },
          { type: 'videoCall', users: 1000 },
          { type: 'screenShare', users: 500 },
          { type: 'chatMessaging', users: 1500 },
          { type: 'fileUpload', users: 500 }
        ]
      },
      {
        name: 'Peak Load',
        targetUsers: 10000,
        rampUpTime: 600000, // 10 minutes
        duration: 1800000, // 30 minutes
        scenarios: [
          { type: 'voiceCall', users: 3000 },
          { type: 'videoCall', users: 2000 },
          { type: 'screenShare', users: 1000 },
          { type: 'chatMessaging', users: 3000 },
          { type: 'fileUpload', users: 1000 }
        ]
      }
    ],
    successCriteria: {
      maxErrorRate: 0.05,
      maxLatencyP99: 5000,
      minThroughput: {
        messages: 100000, // per minute
        voicePackets: 1000000 // per minute
      }
    }
  },
  
  spike: {
    id: 'spike',
    name: 'Spike Test',
    description: 'Test system response to sudden traffic spikes',
    workerCount: 10,
    phases: [
      {
        name: 'Normal Load',
        targetUsers: 1000,
        rampUpTime: 60000,
        duration: 300000,
        scenarios: [
          { type: 'mixedUsage', users: 1000 }
        ]
      },
      {
        name: 'Spike',
        targetUsers: 8000,
        rampUpTime: 30000, // 30 seconds
        duration: 300000,
        scenarios: [
          { type: 'voiceCall', users: 4000 },
          { type: 'chatMessaging', users: 4000 }
        ]
      },
      {
        name: 'Recovery',
        targetUsers: 1000,
        rampUpTime: 60000,
        duration: 300000,
        scenarios: [
          { type: 'mixedUsage', users: 1000 }
        ]
      }
    ],
    successCriteria: {
      maxErrorRate: 0.1,
      recoveryTime: 120000 // 2 minutes
    }
  }
};
```

### 6. Report Generation
```typescript
// Load test report generator
export class LoadTestReporter {
  constructor(
    private storage: StorageService,
    private analytics: AnalyticsService
  ) {}
  
  async generateReport(result: LoadTestResult): Promise<TestReport> {
    const report: TestReport = {
      id: result.testPlan.id,
      timestamp: Date.now(),
      summary: this.generateSummary(result),
      phases: this.analyzePhases(result.phases),
      metrics: this.aggregateMetrics(result),
      resources: this.analyzeResources(result.monitoring),
      bottlenecks: this.identifyBottlenecks(result),
      recommendations: this.generateRecommendations(result)
    };
    
    // Store report
    await this.storage.saveReport(report);
    
    // Generate visualizations
    const charts = await this.generateCharts(result);
    
    // Create HTML report
    const html = await this.renderHTMLReport(report, charts);
    
    return {
      ...report,
      artifacts: {
        html,
        charts,
        rawData: await this.storage.getReportUrl(report.id)
      }
    };
  }
  
  private identifyBottlenecks(result: LoadTestResult): Bottleneck[] {
    const bottlenecks: Bottleneck[] = [];
    
    // Analyze latency spikes
    for (const [operation, metrics] of Object.entries(result.aggregatedMetrics)) {
      if (metrics.latency.p99 > metrics.latency.p95 * 2) {
        bottlenecks.push({
          type: 'latency_spike',
          component: operation,
          severity: 'high',
          details: `P99 latency (${metrics.latency.p99}ms) is significantly higher than P95 (${metrics.latency.p95}ms)`,
          recommendation: 'Investigate timeout handling and retry logic'
        });
      }
    }
    
    // Analyze error rates
    for (const phase of result.phases) {
      for (const [operation, metrics] of Object.entries(phase.metrics.operations)) {
        if (metrics.errorRate > 0.05) {
          bottlenecks.push({
            type: 'high_error_rate',
            component: operation,
            severity: 'critical',
            details: `Error rate ${(metrics.errorRate * 100).toFixed(2)}% exceeds threshold`,
            recommendation: 'Review error logs and add circuit breakers'
          });
        }
      }
    }
    
    // Analyze resource utilization
    const cpuBottleneck = this.analyzeCPUBottleneck(result.monitoring);
    if (cpuBottleneck) bottlenecks.push(cpuBottleneck);
    
    const memoryBottleneck = this.analyzeMemoryBottleneck(result.monitoring);
    if (memoryBottleneck) bottlenecks.push(memoryBottleneck);
    
    return bottlenecks;
  }
  
  private generateRecommendations(result: LoadTestResult): Recommendation[] {
    const recommendations: Recommendation[] = [];
    
    // Based on bottlenecks
    const bottlenecks = this.identifyBottlenecks(result);
    
    for (const bottleneck of bottlenecks) {
      recommendations.push({
        priority: bottleneck.severity === 'critical' ? 'high' : 'medium',
        category: 'performance',
        title: `Address ${bottleneck.type} in ${bottleneck.component}`,
        description: bottleneck.recommendation,
        estimatedImpact: 'high'
      });
    }
    
    // Scaling recommendations
    if (result.summary.peakConcurrentUsers > 8000) {
      recommendations.push({
        priority: 'high',
        category: 'scaling',
        title: 'Implement auto-scaling',
        description: 'System approached capacity limits. Implement auto-scaling to handle traffic spikes.',
        estimatedImpact: 'high'
      });
    }
    
    // Caching recommendations
    const cacheableOperations = this.identifyCacheableOperations(result);
    if (cacheableOperations.length > 0) {
      recommendations.push({
        priority: 'medium',
        category: 'optimization',
        title: 'Implement caching',
        description: `Add caching for: ${cacheableOperations.join(', ')}`,
        estimatedImpact: 'medium'
      });
    }
    
    return recommendations;
  }
}

// Test report UI
export function LoadTestReport({ reportId }: { reportId: string }) {
  const [report, setReport] = useState<TestReport>();
  const [activeTab, setActiveTab] = useState('summary');
  
  useEffect(() => {
    loadReport();
  }, [reportId]);
  
  const loadReport = async () => {
    const data = await api.getLoadTestReport(reportId);
    setReport(data);
  };
  
  if (!report) return <LoadingSpinner />;
  
  return (
    <div className="load-test-report">
      <div className="report-header">
        <h1>{report.testPlan.name}</h1>
        <div className="test-status">
          <StatusBadge status={report.summary.passed ? 'passed' : 'failed'} />
          <span className="test-date">{formatDate(report.timestamp)}</span>
        </div>
      </div>
      
      <Tabs value={activeTab} onChange={setActiveTab}>
        <Tab value="summary">Summary</Tab>
        <Tab value="metrics">Metrics</Tab>
        <Tab value="resources">Resources</Tab>
        <Tab value="bottlenecks">Bottlenecks</Tab>
        <Tab value="recommendations">Recommendations</Tab>
      </Tabs>
      
      <div className="report-content">
        {activeTab === 'summary' && (
          <SummaryView summary={report.summary} phases={report.phases} />
        )}
        
        {activeTab === 'metrics' && (
          <MetricsView metrics={report.metrics} charts={report.artifacts.charts} />
        )}
        
        {activeTab === 'resources' && (
          <ResourcesView resources={report.resources} />
        )}
        
        {activeTab === 'bottlenecks' && (
          <BottlenecksView bottlenecks={report.bottlenecks} />
        )}
        
        {activeTab === 'recommendations' && (
          <RecommendationsView recommendations={report.recommendations} />
        )}
      </div>
      
      <div className="report-actions">
        <Button
          variant="secondary"
          onClick={() => window.open(report.artifacts.html, '_blank')}
        >
          View Full Report
        </Button>
        
        <Button
          variant="secondary"
          onClick={() => downloadFile(report.artifacts.rawData, `${reportId}.json`)}
        >
          Download Raw Data
        </Button>
      </div>
    </div>
  );
}
```

## Dependencies
- K6 or custom load testing framework
- Prometheus for metrics collection
- Grafana for visualization
- Multiple cloud regions for distributed testing
- WebSocket client libraries

## Estimated Effort
**5 days**
- 1 day: Load testing framework setup
- 1 day: Scenario implementation
- 1 day: Metrics collection system
- 1 day: Resource monitoring
- 1 day: Report generation and analysis

## Notes
- Run tests in staging environment first
- Monitor production metrics during tests
- Have rollback plan ready
- Test during off-peak hours
- Document all performance baselines