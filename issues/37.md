# Issue #37: Noise Suppression

## User Story
As a **voice channel participant**, I want **background noise automatically suppressed** so that **my voice comes through clearly without distracting sounds**.

## Description
Implement advanced noise suppression for voice channels using WebRTC's noise suppression capabilities combined with custom audio processing. This includes keyboard typing, background conversations, fans, and other ambient noise removal while preserving voice clarity.

## Acceptance Criteria
- [ ] Built-in browser noise suppression
- [ ] Custom AI noise suppression option
- [ ] Configurable suppression levels
- [ ] Per-user noise suppression settings
- [ ] Visual noise level indicators
- [ ] Bypass option for music/streaming
- [ ] Performance impact monitoring
- [ ] Mobile device support

## Technical Implementation

### 1. WebRTC Noise Suppression
```typescript
// Audio Processing Configuration
export interface NoiseSuppressionConfig {
  enabled: boolean;
  mode: 'browser' | 'ai' | 'hybrid';
  strength: 'low' | 'medium' | 'high' | 'auto';
  bypassForMusic: boolean;
  customSettings?: {
    echoCancellation: boolean;
    autoGainControl: boolean;
    noiseSuppression: boolean;
    typingDetection: boolean;
  };
}

export class NoiseSuppressionManager {
  private audioContext: AudioContext;
  private processors = new Map<string, AudioWorkletNode>();
  private aiProcessor?: AINoiseProcessor;
  
  constructor(
    private rtcManager: RTCManager,
    private analyticsService: AnalyticsService
  ) {
    this.audioContext = new AudioContext();
    this.initializeProcessors();
  }
  
  async enableNoiseSuppression(
    stream: MediaStream,
    config: NoiseSuppressionConfig
  ): Promise<MediaStream> {
    const source = this.audioContext.createMediaStreamSource(stream);
    const destination = this.audioContext.createMediaStreamDestination();
    
    // Chain of audio processors
    let currentNode: AudioNode = source;
    
    // Step 1: Browser-native suppression
    if (config.mode === 'browser' || config.mode === 'hybrid') {
      currentNode = await this.applyBrowserSuppression(currentNode, config);
    }
    
    // Step 2: AI-based suppression
    if (config.mode === 'ai' || config.mode === 'hybrid') {
      currentNode = await this.applyAISuppression(currentNode, config);
    }
    
    // Step 3: Additional processing
    if (config.customSettings?.typingDetection) {
      currentNode = await this.applyTypingDetection(currentNode);
    }
    
    // Connect to destination
    currentNode.connect(destination);
    
    // Track configuration
    await this.analyticsService.track('noise_suppression_enabled', {
      mode: config.mode,
      strength: config.strength,
      features: Object.keys(config.customSettings || {})
    });
    
    return destination.stream;
  }
  
  private async applyBrowserSuppression(
    input: AudioNode,
    config: NoiseSuppressionConfig
  ): Promise<AudioNode> {
    // Apply constraints to the original stream
    const constraints: MediaTrackConstraints = {
      echoCancellation: config.customSettings?.echoCancellation ?? true,
      autoGainControl: config.customSettings?.autoGainControl ?? true,
      noiseSuppression: config.customSettings?.noiseSuppression ?? true,
      // Advanced constraints
      googEchoCancellation: true,
      googAutoGainControl: true,
      googNoiseSuppression: true,
      googHighpassFilter: true,
      googTypingNoiseDetection: config.customSettings?.typingDetection ?? true
    };
    
    // Create a new processed stream
    const processedStream = await this.reprocessStream(input, constraints);
    
    return this.audioContext.createMediaStreamSource(processedStream);
  }
  
  private async applyAISuppression(
    input: AudioNode,
    config: NoiseSuppressionConfig
  ): Promise<AudioNode> {
    // Initialize AI processor if not already done
    if (!this.aiProcessor) {
      this.aiProcessor = new AINoiseProcessor(this.audioContext);
      await this.aiProcessor.initialize();
    }
    
    // Create worklet node for AI processing
    const aiNode = new AudioWorkletNode(
      this.audioContext,
      'ai-noise-suppressor',
      {
        processorOptions: {
          strength: this.getSuppressionStrength(config.strength),
          bypassForMusic: config.bypassForMusic,
          modelType: 'rnnoise' // or 'custom-model'
        }
      }
    );
    
    // Connect input to AI processor
    input.connect(aiNode);
    
    // Monitor processing metrics
    aiNode.port.onmessage = (event) => {
      if (event.data.type === 'metrics') {
        this.handleProcessingMetrics(event.data.metrics);
      }
    };
    
    return aiNode;
  }
  
  private getSuppressionStrength(strength: string): number {
    const strengthMap = {
      'low': 0.3,
      'medium': 0.6,
      'high': 0.9,
      'auto': -1 // Adaptive mode
    };
    return strengthMap[strength] || 0.6;
  }
}

// AI Noise Processor
export class AINoiseProcessor {
  private model?: tf.LayersModel;
  private processingWorker?: Worker;
  
  constructor(private audioContext: AudioContext) {}
  
  async initialize() {
    // Load AI model
    this.model = await tf.loadLayersModel('/models/noise-suppression/model.json');
    
    // Initialize processing worker
    this.processingWorker = new Worker('/workers/ai-noise-processor.js');
    
    // Register AudioWorklet
    await this.audioContext.audioWorklet.addModule('/worklets/ai-noise-suppressor.js');
  }
  
  async processAudioBuffer(
    inputBuffer: Float32Array,
    sampleRate: number
  ): Promise<Float32Array> {
    // Convert to frequency domain
    const fftSize = 512;
    const fft = new FFT(fftSize);
    const spectrum = fft.forward(inputBuffer);
    
    // Prepare input for model
    const modelInput = tf.tensor2d([spectrum.real, spectrum.imag]);
    
    // Run inference
    const prediction = await this.model.predict(modelInput) as tf.Tensor;
    const cleanSpectrum = await prediction.array();
    
    // Convert back to time domain
    const cleanAudio = fft.inverse({
      real: cleanSpectrum[0],
      imag: cleanSpectrum[1]
    });
    
    // Cleanup tensors
    modelInput.dispose();
    prediction.dispose();
    
    return cleanAudio;
  }
}
```

### 2. Audio Worklet Implementation
```javascript
// worklets/ai-noise-suppressor.js
class AINoiseSuppressionProcessor extends AudioWorkletProcessor {
  constructor(options) {
    super();
    
    this.strength = options.processorOptions.strength;
    this.bypassForMusic = options.processorOptions.bypassForMusic;
    this.isProcessing = false;
    
    // Ring buffer for processing
    this.inputBuffer = new Float32Array(4096);
    this.outputBuffer = new Float32Array(4096);
    this.bufferIndex = 0;
    
    // Initialize noise gate
    this.noiseGate = new NoiseGate({
      threshold: -40, // dB
      ratio: 10,
      attack: 0.001,
      release: 0.1
    });
    
    // Music detection
    this.musicDetector = new MusicDetector();
  }
  
  process(inputs, outputs, parameters) {
    const input = inputs[0];
    const output = outputs[0];
    
    if (!input || !input[0]) {
      return true;
    }
    
    const inputChannel = input[0];
    const outputChannel = output[0];
    
    // Check if we should bypass for music
    if (this.bypassForMusic && this.musicDetector.isMusicDetected(inputChannel)) {
      outputChannel.set(inputChannel);
      return true;
    }
    
    // Apply noise suppression
    for (let i = 0; i < inputChannel.length; i++) {
      // Add to ring buffer
      this.inputBuffer[this.bufferIndex] = inputChannel[i];
      
      // Process when buffer is full
      if (this.bufferIndex === this.inputBuffer.length - 1) {
        this.processBuffer();
      }
      
      // Output processed sample
      outputChannel[i] = this.outputBuffer[this.bufferIndex];
      
      this.bufferIndex = (this.bufferIndex + 1) % this.inputBuffer.length;
    }
    
    // Send metrics periodically
    if (currentFrame % (sampleRate * 0.1) === 0) {
      this.port.postMessage({
        type: 'metrics',
        metrics: {
          inputLevel: this.calculateRMS(inputChannel),
          outputLevel: this.calculateRMS(outputChannel),
          noiseReduction: this.calculateNoiseReduction(),
          cpuUsage: this.estimateCPUUsage()
        }
      });
    }
    
    return true;
  }
  
  processBuffer() {
    // Apply spectral subtraction
    const spectrum = this.fft(this.inputBuffer);
    const noiseProfile = this.estimateNoiseProfile(spectrum);
    
    // Subtract noise spectrum
    for (let i = 0; i < spectrum.length; i++) {
      const magnitude = Math.sqrt(spectrum[i].real ** 2 + spectrum[i].imag ** 2);
      const phase = Math.atan2(spectrum[i].imag, spectrum[i].real);
      
      // Spectral subtraction with oversubtraction factor
      let cleanMagnitude = magnitude - (this.strength * noiseProfile[i]);
      cleanMagnitude = Math.max(cleanMagnitude, magnitude * 0.1); // Noise floor
      
      spectrum[i].real = cleanMagnitude * Math.cos(phase);
      spectrum[i].imag = cleanMagnitude * Math.sin(phase);
    }
    
    // Convert back to time domain
    this.outputBuffer = this.ifft(spectrum);
    
    // Apply noise gate
    this.noiseGate.process(this.outputBuffer);
  }
  
  estimateNoiseProfile(spectrum) {
    // Simple noise estimation based on minimum statistics
    if (!this.noiseHistory) {
      this.noiseHistory = new Array(spectrum.length).fill(0);
    }
    
    for (let i = 0; i < spectrum.length; i++) {
      const magnitude = Math.sqrt(spectrum[i].real ** 2 + spectrum[i].imag ** 2);
      
      // Update noise estimate using minimum statistics
      if (magnitude < this.noiseHistory[i] || Math.random() < 0.05) {
        this.noiseHistory[i] = magnitude;
      } else {
        this.noiseHistory[i] *= 1.01; // Slow increase
      }
    }
    
    return this.noiseHistory;
  }
}

registerProcessor('ai-noise-suppressor', AINoiseSuppressionProcessor);
```

### 3. Typing Detection
```typescript
// Typing Noise Detection
export class TypingNoiseDetector {
  private detectionThreshold = 0.7;
  private typingPatterns: AudioPattern[] = [];
  
  constructor() {
    this.loadTypingPatterns();
  }
  
  private async loadTypingPatterns() {
    // Load pre-recorded typing sound patterns
    const patterns = await fetch('/audio/typing-patterns.json');
    this.typingPatterns = await patterns.json();
  }
  
  detectTyping(audioBuffer: Float32Array, sampleRate: number): TypingDetectionResult {
    // Extract features
    const features = this.extractAudioFeatures(audioBuffer, sampleRate);
    
    // Check against typing patterns
    let maxSimilarity = 0;
    let matchedPattern = null;
    
    for (const pattern of this.typingPatterns) {
      const similarity = this.calculateSimilarity(features, pattern.features);
      if (similarity > maxSimilarity) {
        maxSimilarity = similarity;
        matchedPattern = pattern;
      }
    }
    
    const isTyping = maxSimilarity > this.detectionThreshold;
    
    return {
      detected: isTyping,
      confidence: maxSimilarity,
      pattern: matchedPattern?.name,
      timestamp: Date.now()
    };
  }
  
  private extractAudioFeatures(buffer: Float32Array, sampleRate: number): AudioFeatures {
    return {
      // Spectral features
      spectralCentroid: this.calculateSpectralCentroid(buffer, sampleRate),
      spectralRolloff: this.calculateSpectralRolloff(buffer, sampleRate),
      zeroCrossingRate: this.calculateZeroCrossingRate(buffer),
      
      // Temporal features
      energy: this.calculateEnergy(buffer),
      rms: this.calculateRMS(buffer),
      
      // Onset detection
      onsetStrength: this.calculateOnsetStrength(buffer),
      
      // Rhythmic features
      tempo: this.estimateTempo(buffer, sampleRate),
      rhythm: this.extractRhythmPattern(buffer, sampleRate)
    };
  }
  
  suppressTypingNoise(
    audioBuffer: Float32Array,
    detectionResult: TypingDetectionResult
  ): Float32Array {
    if (!detectionResult.detected) {
      return audioBuffer;
    }
    
    // Apply targeted suppression
    const suppressed = new Float32Array(audioBuffer.length);
    
    // Frequency-domain processing
    const fftSize = 2048;
    const hopSize = fftSize / 4;
    
    for (let i = 0; i < audioBuffer.length - fftSize; i += hopSize) {
      const frame = audioBuffer.slice(i, i + fftSize);
      const spectrum = this.fft(frame);
      
      // Suppress typing frequencies (typically 1-4 kHz)
      for (let bin = 0; bin < spectrum.length; bin++) {
        const freq = (bin * 44100) / fftSize;
        if (freq > 1000 && freq < 4000) {
          const suppression = detectionResult.confidence * 0.8;
          spectrum[bin].real *= (1 - suppression);
          spectrum[bin].imag *= (1 - suppression);
        }
      }
      
      // Inverse transform
      const processedFrame = this.ifft(spectrum);
      
      // Overlap-add
      for (let j = 0; j < fftSize; j++) {
        if (i + j < suppressed.length) {
          suppressed[i + j] += processedFrame[j] * this.hannWindow(j, fftSize);
        }
      }
    }
    
    return suppressed;
  }
}
```

### 4. UI Components
```tsx
export function NoiseSuppressionSettings({ 
  userId 
}: { 
  userId: string 
}) {
  const [config, setConfig] = useState<NoiseSuppressionConfig>({
    enabled: true,
    mode: 'browser',
    strength: 'medium',
    bypassForMusic: false
  });
  const [testActive, setTestActive] = useState(false);
  const [noiseLevel, setNoiseLevel] = useState(0);
  
  useEffect(() => {
    loadUserSettings();
  }, [userId]);
  
  const loadUserSettings = async () => {
    const settings = await api.getUserNoiseSuppressionSettings(userId);
    setConfig(settings);
  };
  
  const saveSettings = async () => {
    await api.updateUserNoiseSuppressionSettings(userId, config);
    toast.success('Noise suppression settings updated');
  };
  
  const testNoiseSuppression = async () => {
    setTestActive(true);
    
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const processor = new NoiseSuppressionManager();
      
      // Apply current settings
      const processedStream = await processor.enableNoiseSuppression(stream, config);
      
      // Visualize noise levels
      const analyser = new AudioAnalyser(processedStream);
      analyser.onNoiseLevel = (level) => setNoiseLevel(level);
      
      // Play back processed audio
      const audio = new Audio();
      audio.srcObject = processedStream;
      audio.play();
      
      // Stop after 10 seconds
      setTimeout(() => {
        stream.getTracks().forEach(track => track.stop());
        processedStream.getTracks().forEach(track => track.stop());
        audio.pause();
        setTestActive(false);
      }, 10000);
      
    } catch (error) {
      console.error('Failed to test noise suppression:', error);
      setTestActive(false);
    }
  };
  
  return (
    <div className="noise-suppression-settings">
      <div className="settings-header">
        <h3>Noise Suppression</h3>
        <p>Remove background noise from your microphone</p>
      </div>
      
      <div className="settings-content">
        <ToggleSwitch
          label="Enable Noise Suppression"
          checked={config.enabled}
          onChange={(enabled) => setConfig({ ...config, enabled })}
        />
        
        {config.enabled && (
          <>
            <RadioGroup
              label="Suppression Mode"
              value={config.mode}
              onChange={(mode) => setConfig({ ...config, mode })}
              options={[
                { value: 'browser', label: 'Browser (Low CPU)' },
                { value: 'ai', label: 'AI-Powered (Best Quality)' },
                { value: 'hybrid', label: 'Hybrid (Balanced)' }
              ]}
            />
            
            <Slider
              label="Suppression Strength"
              value={config.strength}
              onChange={(strength) => setConfig({ ...config, strength })}
              options={['low', 'medium', 'high', 'auto']}
              descriptions={{
                low: 'Light suppression, preserves more detail',
                medium: 'Balanced suppression',
                high: 'Aggressive suppression, may affect voice',
                auto: 'Automatically adjust based on noise level'
              }}
            />
            
            <div className="advanced-settings">
              <h4>Advanced Settings</h4>
              
              <ToggleSwitch
                label="Echo Cancellation"
                checked={config.customSettings?.echoCancellation ?? true}
                onChange={(checked) => setConfig({
                  ...config,
                  customSettings: {
                    ...config.customSettings,
                    echoCancellation: checked
                  }
                })}
              />
              
              <ToggleSwitch
                label="Auto Gain Control"
                checked={config.customSettings?.autoGainControl ?? true}
                onChange={(checked) => setConfig({
                  ...config,
                  customSettings: {
                    ...config.customSettings,
                    autoGainControl: checked
                  }
                })}
              />
              
              <ToggleSwitch
                label="Typing Detection"
                checked={config.customSettings?.typingDetection ?? true}
                onChange={(checked) => setConfig({
                  ...config,
                  customSettings: {
                    ...config.customSettings,
                    typingDetection: checked
                  }
                })}
              />
              
              <ToggleSwitch
                label="Bypass for Music"
                checked={config.bypassForMusic}
                onChange={(bypassForMusic) => setConfig({ ...config, bypassForMusic })}
                helpText="Disable suppression when music is detected"
              />
            </div>
          </>
        )}
        
        <div className="test-section">
          <Button
            variant="secondary"
            onClick={testNoiseSuppression}
            disabled={testActive}
          >
            {testActive ? 'Testing... (10s)' : 'Test Noise Suppression'}
          </Button>
          
          {testActive && (
            <div className="noise-visualization">
              <NoiseLevel level={noiseLevel} />
              <p>Make some noise to test suppression!</p>
            </div>
          )}
        </div>
        
        <div className="action-buttons">
          <Button variant="primary" onClick={saveSettings}>
            Save Settings
          </Button>
        </div>
      </div>
    </div>
  );
}

function NoiseLevel({ level }: { level: number }) {
  return (
    <div className="noise-level">
      <div className="level-bar">
        <div 
          className="level-fill"
          style={{ width: `${level * 100}%` }}
        />
      </div>
      <div className="level-labels">
        <span>Silent</span>
        <span>Moderate</span>
        <span>Loud</span>
      </div>
    </div>
  );
}
```

### 5. Performance Monitoring
```typescript
// Performance Monitor
export class NoiseSuppressionPerformance {
  private metrics: PerformanceMetrics = {
    cpuUsage: [],
    latency: [],
    qualityScore: []
  };
  
  constructor(
    private analyticsService: AnalyticsService
  ) {}
  
  async measurePerformance(
    processor: NoiseSuppressionManager,
    duration: number = 5000
  ): Promise<PerformanceReport> {
    const startTime = performance.now();
    const measurements: Measurement[] = [];
    
    const interval = setInterval(() => {
      const measurement = this.takeMeasurement(processor);
      measurements.push(measurement);
    }, 100);
    
    // Run test
    await new Promise(resolve => setTimeout(resolve, duration));
    clearInterval(interval);
    
    // Analyze results
    const report = this.analyzeResults(measurements);
    
    // Log to analytics
    await this.analyticsService.track('noise_suppression_performance', report);
    
    return report;
  }
  
  private takeMeasurement(processor: NoiseSuppressionManager): Measurement {
    return {
      timestamp: Date.now(),
      cpuUsage: this.measureCPUUsage(),
      memoryUsage: performance.memory?.usedJSHeapSize || 0,
      audioLatency: processor.getCurrentLatency(),
      processingTime: processor.getLastProcessingTime(),
      qualityMetrics: processor.getQualityMetrics()
    };
  }
  
  private measureCPUUsage(): number {
    // Estimate CPU usage based on processing time
    if ('measureUserAgentSpecificMemory' in performance) {
      // Use new API if available
      return performance.measureUserAgentSpecificMemory().then(result => {
        return result.breakdown.reduce((sum, entry) => sum + entry.bytes, 0);
      });
    }
    
    // Fallback estimation
    return performance.now() % 100; // Simplified for example
  }
  
  optimizeSettings(
    currentConfig: NoiseSuppressionConfig,
    performanceReport: PerformanceReport
  ): NoiseSuppressionConfig {
    const optimized = { ...currentConfig };
    
    // If CPU usage is too high, reduce processing
    if (performanceReport.averageCPU > 80) {
      if (optimized.mode === 'hybrid') {
        optimized.mode = 'browser';
      } else if (optimized.mode === 'ai') {
        optimized.mode = 'hybrid';
      }
    }
    
    // If latency is too high, reduce strength
    if (performanceReport.averageLatency > 20) {
      if (optimized.strength === 'high') {
        optimized.strength = 'medium';
      } else if (optimized.strength === 'medium') {
        optimized.strength = 'low';
      }
    }
    
    return optimized;
  }
}
```

## Dependencies
- WebRTC Audio API
- TensorFlow.js for AI models
- Web Audio API
- AudioWorklet support
- FFT library for spectral processing

## Estimated Effort
**5 days**
- 1 day: WebRTC integration
- 1 day: AI model implementation
- 1 day: Typing detection
- 1 day: UI components
- 1 day: Performance optimization

## Notes
- Consider pre-trained models like RNNoise
- Test on various noise types
- Monitor CPU usage carefully
- Provide fallback for older browsers
- Consider server-side processing option