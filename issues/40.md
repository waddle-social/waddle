# Issue #40: WHIP Broadcasting

## User Story
As a **content creator or event host**, I want to **broadcast high-quality live streams to my waddle** so that **members can watch live events, presentations, or shows with low latency and professional quality**.

## Description
Implement WebRTC-HTTP Ingress Protocol (WHIP) support for Waddle, enabling professional broadcasting tools (OBS, Wirecast, etc.) to stream directly to voice channels. This feature transforms voice channels into broadcast-capable spaces supporting one-to-many streaming with sub-second latency.

## Acceptance Criteria
- [ ] WHIP endpoint implementation
- [ ] Stream authentication and authorization
- [ ] Multi-bitrate encoding support
- [ ] Adaptive bitrate streaming
- [ ] Stream health monitoring
- [ ] Broadcast controls and moderation
- [ ] Recording capabilities
- [ ] Stream analytics and metrics

## Technical Implementation

### 1. WHIP Server Implementation
```typescript
// WHIP protocol handler
export interface WHIPConfig {
  endpoint: string;
  authentication: 'bearer' | 'basic' | 'custom';
  maxBitrate: number;
  supportedCodecs: string[];
  iceServers: RTCIceServer[];
  timeout: number;
}

export class WHIPServer {
  private activeSessions = new Map<string, WHIPSession>();
  private pendingOffers = new Map<string, PendingOffer>();
  
  constructor(
    private config: WHIPConfig,
    private auth: AuthService,
    private storage: StreamStorage,
    private rtc: RTCEngine
  ) {}
  
  async handleWHIPRequest(request: Request): Promise<Response> {
    // Validate request method
    if (request.method !== 'POST') {
      return new Response('Method not allowed', { 
        status: 405,
        headers: { 'Allow': 'POST' }
      });
    }
    
    // Authenticate broadcaster
    const auth = await this.authenticateBroadcaster(request);
    if (!auth.valid) {
      return new Response('Unauthorized', { 
        status: 401,
        headers: { 'WWW-Authenticate': 'Bearer' }
      });
    }
    
    // Parse SDP offer
    const contentType = request.headers.get('content-type');
    if (contentType !== 'application/sdp') {
      return new Response('Invalid content type', { status: 400 });
    }
    
    const offer = await request.text();
    const parsedOffer = this.parseSDPOffer(offer);
    
    // Validate stream configuration
    const validation = await this.validateStreamConfig(parsedOffer, auth);
    if (!validation.valid) {
      return new Response(validation.error, { status: 400 });
    }
    
    // Create WHIP session
    const session = await this.createWHIPSession(auth, parsedOffer);
    
    try {
      // Generate answer
      const answer = await this.generateAnswer(session, parsedOffer);
      
      // Store session
      this.activeSessions.set(session.id, session);
      
      // Start ingress handling
      await this.startIngress(session);
      
      return new Response(answer.sdp, {
        status: 201,
        headers: {
          'Content-Type': 'application/sdp',
          'Location': `${this.config.endpoint}/resource/${session.id}`,
          'ETag': `"${session.etag}"`
        }
      });
      
    } catch (error) {
      console.error('WHIP session creation failed:', error);
      await this.cleanupSession(session);
      return new Response('Internal server error', { status: 500 });
    }
  }
  
  private async authenticateBroadcaster(
    request: Request
  ): Promise<AuthResult> {
    const authorization = request.headers.get('authorization');
    
    if (!authorization) {
      return { valid: false, error: 'Missing authorization' };
    }
    
    if (this.config.authentication === 'bearer') {
      const token = authorization.replace('Bearer ', '');
      const decoded = await this.auth.verifyStreamToken(token);
      
      if (!decoded) {
        return { valid: false, error: 'Invalid token' };
      }
      
      // Check permissions
      const hasPermission = await this.auth.canBroadcast(
        decoded.userId,
        decoded.waddleId,
        decoded.channelId
      );
      
      if (!hasPermission) {
        return { valid: false, error: 'Insufficient permissions' };
      }
      
      return {
        valid: true,
        userId: decoded.userId,
        waddleId: decoded.waddleId,
        channelId: decoded.channelId,
        streamKey: decoded.streamKey
      };
    }
    
    // Other auth methods...
    return { valid: false, error: 'Unsupported authentication' };
  }
  
  private async createWHIPSession(
    auth: AuthResult,
    offer: ParsedSDP
  ): Promise<WHIPSession> {
    const sessionId = crypto.randomUUID();
    const etag = crypto.randomUUID();
    
    // Create peer connection
    const pc = new RTCPeerConnection({
      iceServers: this.config.iceServers,
      iceTransportPolicy: 'all',
      bundlePolicy: 'max-bundle',
      rtcpMuxPolicy: 'require'
    });
    
    // Configure for receiving
    pc.addTransceiver('audio', { direction: 'recvonly' });
    pc.addTransceiver('video', { direction: 'recvonly' });
    
    const session: WHIPSession = {
      id: sessionId,
      etag,
      auth,
      peerConnection: pc,
      state: 'connecting',
      startTime: Date.now(),
      metrics: {
        bytesReceived: 0,
        packetsReceived: 0,
        packetsLost: 0,
        jitter: 0,
        roundTripTime: 0
      },
      tracks: new Map(),
      quality: {
        video: { width: 0, height: 0, frameRate: 0, bitrate: 0 },
        audio: { bitrate: 0, packetLoss: 0 }
      }
    };
    
    // Set up event handlers
    this.setupPeerConnectionHandlers(session);
    
    return session;
  }
  
  private setupPeerConnectionHandlers(session: WHIPSession) {
    const pc = session.peerConnection;
    
    pc.ontrack = (event) => {
      console.log(`Received ${event.track.kind} track`);
      
      session.tracks.set(event.track.id, {
        track: event.track,
        transceiver: event.transceiver,
        stats: {
          bytesReceived: 0,
          packetsReceived: 0,
          packetsLost: 0
        }
      });
      
      // Forward to distribution
      this.forwardTrackToDistribution(session, event.track);
    };
    
    pc.oniceconnectionstatechange = () => {
      console.log(`ICE state: ${pc.iceConnectionState}`);
      
      switch (pc.iceConnectionState) {
        case 'connected':
        case 'completed':
          session.state = 'active';
          this.onSessionConnected(session);
          break;
        case 'failed':
          session.state = 'failed';
          this.onSessionFailed(session);
          break;
        case 'disconnected':
          session.state = 'disconnected';
          this.onSessionDisconnected(session);
          break;
      }
    };
    
    pc.onconnectionstatechange = () => {
      console.log(`Connection state: ${pc.connectionState}`);
      
      if (pc.connectionState === 'failed') {
        this.handleConnectionFailure(session);
      }
    };
  }
  
  private async generateAnswer(
    session: WHIPSession,
    offer: ParsedSDP
  ): Promise<RTCSessionDescriptionInit> {
    const pc = session.peerConnection;
    
    // Set remote description
    await pc.setRemoteDescription({
      type: 'offer',
      sdp: offer.raw
    });
    
    // Create answer
    const answer = await pc.createAnswer({
      offerToReceiveAudio: true,
      offerToReceiveVideo: true
    });
    
    // Modify SDP for optimal settings
    answer.sdp = this.optimizeAnswerSDP(answer.sdp!, offer);
    
    // Set local description
    await pc.setLocalDescription(answer);
    
    // Wait for ICE gathering
    await this.waitForIceGathering(pc);
    
    return pc.localDescription!;
  }
  
  private optimizeAnswerSDP(sdp: string, offer: ParsedSDP): string {
    let optimized = sdp;
    
    // Set video bitrate constraints
    if (offer.hasVideo) {
      optimized = this.setVideoBitrate(optimized, this.config.maxBitrate);
    }
    
    // Set audio bitrate
    if (offer.hasAudio) {
      optimized = this.setAudioBitrate(optimized, 128000); // 128 kbps
    }
    
    // Enable transport-cc for BWE
    optimized = this.enableTransportCC(optimized);
    
    // Set preferred codecs
    optimized = this.setPreferredCodecs(optimized, this.config.supportedCodecs);
    
    return optimized;
  }
  
  private async startIngress(session: WHIPSession) {
    // Start quality monitoring
    this.startQualityMonitoring(session);
    
    // Start recording if enabled
    if (session.auth.recordingEnabled) {
      await this.startRecording(session);
    }
    
    // Notify channel about new broadcast
    await this.notifyChannelBroadcastStarted(session);
    
    // Start metrics collection
    this.startMetricsCollection(session);
  }
  
  async handleResourceRequest(
    request: Request,
    sessionId: string
  ): Promise<Response> {
    const session = this.activeSessions.get(sessionId);
    
    if (!session) {
      return new Response('Not found', { status: 404 });
    }
    
    // Handle different methods
    switch (request.method) {
      case 'GET':
        return this.getSessionInfo(session);
        
      case 'PATCH':
        return this.updateSession(session, request);
        
      case 'DELETE':
        return this.deleteSession(session);
        
      default:
        return new Response('Method not allowed', { 
          status: 405,
          headers: { 'Allow': 'GET, PATCH, DELETE' }
        });
    }
  }
  
  private async updateSession(
    session: WHIPSession,
    request: Request
  ): Promise<Response> {
    // Validate ETag
    const ifMatch = request.headers.get('if-match');
    if (ifMatch && ifMatch !== `"${session.etag}"`) {
      return new Response('Precondition failed', { status: 412 });
    }
    
    const contentType = request.headers.get('content-type');
    
    if (contentType === 'application/trickle-ice-sdpfrag') {
      // Handle ICE candidate
      const candidate = await request.text();
      return this.handleIceCandidate(session, candidate);
    }
    
    return new Response('Unsupported media type', { status: 415 });
  }
  
  private async deleteSession(session: WHIPSession): Promise<Response> {
    await this.terminateSession(session, 'client_request');
    return new Response(null, { status: 204 });
  }
  
  private async terminateSession(
    session: WHIPSession,
    reason: string
  ) {
    console.log(`Terminating WHIP session ${session.id}: ${reason}`);
    
    // Stop recording
    if (session.recordingId) {
      await this.stopRecording(session);
    }
    
    // Close peer connection
    session.peerConnection.close();
    
    // Remove from active sessions
    this.activeSessions.delete(session.id);
    
    // Notify channel
    await this.notifyChannelBroadcastEnded(session, reason);
    
    // Store final metrics
    await this.storeFinalMetrics(session);
  }
}
```

### 2. Stream Distribution System
```typescript
// Stream distribution and transcoding
export class StreamDistributor {
  private distributions = new Map<string, Distribution>();
  private transcoders = new Map<string, Transcoder>();
  
  constructor(
    private mediaServer: MediaServer,
    private storage: StreamStorage,
    private cdn: CDNService
  ) {}
  
  async createDistribution(
    session: WHIPSession,
    track: MediaStreamTrack
  ): Promise<Distribution> {
    const distributionId = crypto.randomUUID();
    
    // Create source pipeline
    const source = await this.mediaServer.createSource({
      id: distributionId,
      track,
      kind: track.kind
    });
    
    // Set up transcoding for multiple qualities
    const transcoder = await this.setupTranscoding(source, track.kind);
    this.transcoders.set(distributionId, transcoder);
    
    // Create distribution endpoints
    const endpoints = await this.createEndpoints(transcoder);
    
    const distribution: Distribution = {
      id: distributionId,
      sessionId: session.id,
      source,
      transcoder,
      endpoints,
      viewers: new Set(),
      startTime: Date.now(),
      state: 'active'
    };
    
    this.distributions.set(distributionId, distribution);
    
    // Start adaptive bitrate ladder
    if (track.kind === 'video') {
      await this.startABRLadder(distribution);
    }
    
    return distribution;
  }
  
  private async setupTranscoding(
    source: MediaSource,
    kind: 'audio' | 'video'
  ): Promise<Transcoder> {
    if (kind === 'video') {
      return this.setupVideoTranscoding(source);
    } else {
      return this.setupAudioTranscoding(source);
    }
  }
  
  private async setupVideoTranscoding(
    source: MediaSource
  ): Promise<VideoTranscoder> {
    const transcoder = new VideoTranscoder(source);
    
    // Define quality ladder
    const qualities: VideoQuality[] = [
      { name: '1080p', width: 1920, height: 1080, bitrate: 5000000, fps: 30 },
      { name: '720p', width: 1280, height: 720, bitrate: 2500000, fps: 30 },
      { name: '480p', width: 854, height: 480, bitrate: 1000000, fps: 30 },
      { name: '360p', width: 640, height: 360, bitrate: 600000, fps: 30 },
      { name: '240p', width: 426, height: 240, bitrate: 300000, fps: 30 }
    ];
    
    // Detect source resolution
    const sourceStats = await source.getStats();
    const sourceHeight = sourceStats.height || 1080;
    
    // Only create qualities lower than source
    const applicableQualities = qualities.filter(q => q.height <= sourceHeight);
    
    // Create encoding profiles
    for (const quality of applicableQualities) {
      await transcoder.addProfile({
        id: quality.name,
        codec: 'h264',
        profile: 'main',
        level: '4.0',
        width: quality.width,
        height: quality.height,
        bitrate: quality.bitrate,
        maxBitrate: quality.bitrate * 1.2,
        bufferSize: quality.bitrate * 2,
        frameRate: quality.fps,
        keyFrameInterval: 2,
        bFrames: 2,
        preset: 'medium',
        tune: 'zerolatency'
      });
    }
    
    await transcoder.start();
    return transcoder;
  }
  
  private async setupAudioTranscoding(
    source: MediaSource
  ): Promise<AudioTranscoder> {
    const transcoder = new AudioTranscoder(source);
    
    // Audio quality profiles
    const profiles: AudioProfile[] = [
      { id: 'high', codec: 'opus', bitrate: 128000, channels: 2 },
      { id: 'medium', codec: 'opus', bitrate: 64000, channels: 2 },
      { id: 'low', codec: 'opus', bitrate: 32000, channels: 1 }
    ];
    
    for (const profile of profiles) {
      await transcoder.addProfile(profile);
    }
    
    await transcoder.start();
    return transcoder;
  }
  
  private async startABRLadder(distribution: Distribution) {
    const ladder = new ABRLadder(distribution.transcoder);
    
    // Configure ABR segments
    await ladder.configure({
      segmentDuration: 2, // 2 second segments
      playlistLength: 10, // Keep 10 segments
      targetLatency: 3, // 3 second target latency
      minUpdatePeriod: 1 // Update every second
    });
    
    // Generate manifests
    const manifests = await ladder.generateManifests();
    
    // Upload to CDN
    for (const [quality, manifest] of manifests) {
      const url = await this.cdn.uploadManifest(
        distribution.id,
        quality,
        manifest
      );
      
      distribution.endpoints.set(quality, {
        url,
        type: 'hls',
        quality,
        lastUpdated: Date.now()
      });
    }
    
    // Start segment generation
    ladder.on('segment', async (segment) => {
      await this.handleNewSegment(distribution, segment);
    });
    
    await ladder.start();
  }
  
  private async createEndpoints(
    transcoder: Transcoder
  ): Promise<Map<string, Endpoint>> {
    const endpoints = new Map<string, Endpoint>();
    
    // Create WebRTC endpoints for ultra-low latency
    const webrtcEndpoint = await this.createWebRTCEndpoint(transcoder);
    endpoints.set('webrtc', webrtcEndpoint);
    
    // Create HLS endpoints for compatibility
    const hlsEndpoint = await this.createHLSEndpoint(transcoder);
    endpoints.set('hls', hlsEndpoint);
    
    // Create DASH endpoint if needed
    if (this.config.enableDASH) {
      const dashEndpoint = await this.createDASHEndpoint(transcoder);
      endpoints.set('dash', dashEndpoint);
    }
    
    return endpoints;
  }
  
  async handleViewerJoin(
    distributionId: string,
    viewerId: string,
    preferences: ViewerPreferences
  ): Promise<ViewerSession> {
    const distribution = this.distributions.get(distributionId);
    if (!distribution) {
      throw new Error('Distribution not found');
    }
    
    // Select best endpoint based on preferences
    const endpoint = this.selectEndpoint(distribution, preferences);
    
    // Create viewer session
    const session: ViewerSession = {
      id: crypto.randomUUID(),
      viewerId,
      distributionId,
      endpoint: endpoint.type,
      quality: this.selectInitialQuality(preferences),
      startTime: Date.now(),
      metrics: {
        buffering: 0,
        bitrateSwitches: 0,
        averageBitrate: 0,
        errors: 0
      }
    };
    
    // Add to distribution
    distribution.viewers.add(viewerId);
    
    // Start quality adaptation
    this.startQualityAdaptation(session);
    
    return session;
  }
  
  private selectEndpoint(
    distribution: Distribution,
    preferences: ViewerPreferences
  ): Endpoint {
    // Prefer WebRTC for lowest latency
    if (preferences.lowLatency && distribution.endpoints.has('webrtc')) {
      return distribution.endpoints.get('webrtc')!;
    }
    
    // Use HLS for compatibility
    if (distribution.endpoints.has('hls')) {
      return distribution.endpoints.get('hls')!;
    }
    
    // Fallback to first available
    return distribution.endpoints.values().next().value;
  }
  
  private startQualityAdaptation(session: ViewerSession) {
    const adapter = new QualityAdapter(session);
    
    adapter.on('qualityChange', async (newQuality) => {
      await this.switchViewerQuality(session, newQuality);
    });
    
    adapter.start();
  }
}
```

### 3. Broadcast Control Interface
```tsx
export function BroadcastControls({ 
  channelId,
  streamKey 
}: { 
  channelId: string;
  streamKey: string;
}) {
  const [broadcasting, setBroadcasting] = useState(false);
  const [streamHealth, setStreamHealth] = useState<StreamHealth>();
  const [settings, setSettings] = useState<BroadcastSettings>();
  const [viewers, setViewers] = useState(0);
  
  useEffect(() => {
    if (broadcasting) {
      const interval = setInterval(updateStreamHealth, 1000);
      return () => clearInterval(interval);
    }
  }, [broadcasting]);
  
  const updateStreamHealth = async () => {
    const health = await api.getStreamHealth(channelId);
    setStreamHealth(health);
    setViewers(health.viewerCount);
  };
  
  const startBroadcast = async () => {
    try {
      await api.startBroadcast(channelId, streamKey);
      setBroadcasting(true);
      toast.success('Broadcast started');
    } catch (error) {
      toast.error('Failed to start broadcast');
    }
  };
  
  const stopBroadcast = async () => {
    const confirmed = await confirm(
      'Stop Broadcasting',
      'Are you sure you want to stop the broadcast?'
    );
    
    if (!confirmed) return;
    
    try {
      await api.stopBroadcast(channelId);
      setBroadcasting(false);
      toast.info('Broadcast stopped');
    } catch (error) {
      toast.error('Failed to stop broadcast');
    }
  };
  
  return (
    <div className="broadcast-controls">
      <div className="controls-header">
        <h3>Broadcast Controls</h3>
        <Badge variant={broadcasting ? 'success' : 'default'}>
          {broadcasting ? 'LIVE' : 'OFFLINE'}
        </Badge>
      </div>
      
      {!broadcasting ? (
        <div className="broadcast-setup">
          <StreamKeyDisplay streamKey={streamKey} />
          
          <BroadcastSettings
            settings={settings}
            onChange={setSettings}
          />
          
          <Button
            variant="primary"
            size="large"
            onClick={startBroadcast}
            leftIcon={<BroadcastIcon />}
          >
            Start Broadcasting
          </Button>
          
          <StreamingGuide />
        </div>
      ) : (
        <div className="broadcast-active">
          <StreamHealthMonitor health={streamHealth} />
          
          <div className="broadcast-stats">
            <StatCard
              label="Viewers"
              value={viewers}
              icon={<UsersIcon />}
            />
            <StatCard
              label="Duration"
              value={formatDuration(streamHealth?.duration || 0)}
              icon={<ClockIcon />}
            />
            <StatCard
              label="Bitrate"
              value={formatBitrate(streamHealth?.bitrate || 0)}
              icon={<SignalIcon />}
            />
          </div>
          
          <BroadcastActions
            onStop={stopBroadcast}
            onRecord={() => toggleRecording()}
            onSnapshot={() => takeSnapshot()}
          />
          
          <ViewerList channelId={channelId} />
        </div>
      )}
    </div>
  );
}

export function StreamKeyDisplay({ 
  streamKey 
}: { 
  streamKey: string 
}) {
  const [revealed, setRevealed] = useState(false);
  const [copied, setCopied] = useState(false);
  
  const copyStreamKey = async () => {
    await navigator.clipboard.writeText(streamKey);
    setCopied(true);
    setTimeout(() => setCopied(false), 2000);
  };
  
  const regenerateKey = async () => {
    const confirmed = await confirm(
      'Regenerate Stream Key',
      'This will invalidate your current stream key. Continue?'
    );
    
    if (confirmed) {
      await api.regenerateStreamKey();
      toast.success('Stream key regenerated');
    }
  };
  
  return (
    <div className="stream-key-display">
      <h4>Stream Configuration</h4>
      
      <div className="stream-url">
        <label>Stream URL</label>
        <code>{WHIP_ENDPOINT}</code>
      </div>
      
      <div className="stream-key">
        <label>Stream Key</label>
        <div className="key-input">
          <input
            type={revealed ? 'text' : 'password'}
            value={streamKey}
            readOnly
          />
          <Button
            variant="ghost"
            size="small"
            onClick={() => setRevealed(!revealed)}
          >
            {revealed ? <EyeOffIcon /> : <EyeIcon />}
          </Button>
          <Button
            variant="ghost"
            size="small"
            onClick={copyStreamKey}
          >
            {copied ? <CheckIcon /> : <CopyIcon />}
          </Button>
        </div>
      </div>
      
      <Button
        variant="secondary"
        size="small"
        onClick={regenerateKey}
      >
        Regenerate Key
      </Button>
    </div>
  );
}

export function StreamHealthMonitor({ 
  health 
}: { 
  health?: StreamHealth 
}) {
  if (!health) return null;
  
  const getHealthStatus = () => {
    if (health.score > 0.9) return 'excellent';
    if (health.score > 0.7) return 'good';
    if (health.score > 0.5) return 'fair';
    return 'poor';
  };
  
  const status = getHealthStatus();
  
  return (
    <div className="stream-health">
      <div className="health-header">
        <h4>Stream Health</h4>
        <Badge variant={status}>
          {status.toUpperCase()}
        </Badge>
      </div>
      
      <div className="health-metrics">
        <HealthMetric
          label="Video"
          value={`${health.video.resolution} @ ${health.video.fps}fps`}
          status={health.video.stable ? 'good' : 'warning'}
        />
        <HealthMetric
          label="Audio"
          value={health.audio.codec}
          status={health.audio.stable ? 'good' : 'warning'}
        />
        <HealthMetric
          label="Network"
          value={`${health.network.packetLoss.toFixed(1)}% loss`}
          status={health.network.packetLoss < 1 ? 'good' : 'warning'}
        />
        <HealthMetric
          label="Latency"
          value={`${health.latency.toFixed(0)}ms`}
          status={health.latency < 100 ? 'good' : 'warning'}
        />
      </div>
      
      {health.issues.length > 0 && (
        <HealthIssues issues={health.issues} />
      )}
    </div>
  );
}
```

### 4. Viewer Experience
```tsx
export function BroadcastViewer({ 
  channelId,
  broadcastId 
}: { 
  channelId: string;
  broadcastId: string;
}) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [player, setPlayer] = useState<BroadcastPlayer>();
  const [quality, setQuality] = useState<string>('auto');
  const [stats, setStats] = useState<ViewerStats>();
  const [isFullscreen, setIsFullscreen] = useState(false);
  
  useEffect(() => {
    initializePlayer();
    
    return () => {
      player?.destroy();
    };
  }, [broadcastId]);
  
  const initializePlayer = async () => {
    if (!videoRef.current) return;
    
    const newPlayer = new BroadcastPlayer(videoRef.current, {
      broadcastId,
      lowLatency: true,
      autoplay: true,
      muted: false // Unmuted for broadcasts
    });
    
    // Set up event handlers
    newPlayer.on('ready', () => {
      console.log('Player ready');
    });
    
    newPlayer.on('error', (error) => {
      console.error('Player error:', error);
      toast.error('Failed to load broadcast');
    });
    
    newPlayer.on('statistics', (newStats) => {
      setStats(newStats);
    });
    
    newPlayer.on('qualityChanged', (newQuality) => {
      console.log(`Quality changed to ${newQuality}`);
    });
    
    await newPlayer.load();
    setPlayer(newPlayer);
  };
  
  const handleQualityChange = (newQuality: string) => {
    setQuality(newQuality);
    player?.setQuality(newQuality);
  };
  
  const toggleFullscreen = async () => {
    const container = videoRef.current?.parentElement;
    if (!container) return;
    
    if (!isFullscreen) {
      await container.requestFullscreen();
      setIsFullscreen(true);
    } else {
      await document.exitFullscreen();
      setIsFullscreen(false);
    }
  };
  
  return (
    <div className="broadcast-viewer">
      <div className="video-container">
        <video
          ref={videoRef}
          playsInline
          controls={false}
          className="broadcast-video"
        />
        
        <BroadcastOverlay
          channelName={channel.name}
          broadcasterName={broadcast.broadcasterName}
          viewerCount={broadcast.viewerCount}
        />
        
        <VideoControls
          player={player}
          quality={quality}
          onQualityChange={handleQualityChange}
          onFullscreen={toggleFullscreen}
          isFullscreen={isFullscreen}
        />
      </div>
      
      <BroadcastInfo broadcast={broadcast} />
      
      {stats && (
        <ViewerStatsPanel stats={stats} />
      )}
    </div>
  );
}

export function VideoControls({
  player,
  quality,
  onQualityChange,
  onFullscreen,
  isFullscreen
}: {
  player?: BroadcastPlayer;
  quality: string;
  onQualityChange: (quality: string) => void;
  onFullscreen: () => void;
  isFullscreen: boolean;
}) {
  const [volume, setVolume] = useState(100);
  const [muted, setMuted] = useState(false);
  const [showControls, setShowControls] = useState(true);
  const [qualities, setQualities] = useState<string[]>(['auto']);
  
  useEffect(() => {
    if (player) {
      setQualities(['auto', ...player.getAvailableQualities()]);
    }
  }, [player]);
  
  const handleVolumeChange = (newVolume: number) => {
    setVolume(newVolume);
    player?.setVolume(newVolume / 100);
  };
  
  const toggleMute = () => {
    const newMuted = !muted;
    setMuted(newMuted);
    player?.setMuted(newMuted);
  };
  
  return (
    <div 
      className={`video-controls ${showControls ? 'visible' : 'hidden'}`}
      onMouseEnter={() => setShowControls(true)}
      onMouseLeave={() => setShowControls(false)}
    >
      <div className="controls-left">
        <Button
          variant="ghost"
          size="small"
          onClick={toggleMute}
        >
          {muted ? <VolumeXIcon /> : <VolumeIcon />}
        </Button>
        
        <VolumeSlider
          value={muted ? 0 : volume}
          onChange={handleVolumeChange}
        />
      </div>
      
      <div className="controls-right">
        <QualitySelector
          qualities={qualities}
          current={quality}
          onChange={onQualityChange}
        />
        
        <Button
          variant="ghost"
          size="small"
          onClick={onFullscreen}
        >
          {isFullscreen ? <MinimizeIcon /> : <MaximizeIcon />}
        </Button>
      </div>
    </div>
  );
}
```

### 5. Recording and Storage
```typescript
// Broadcast recording system
export class BroadcastRecorder {
  private recordings = new Map<string, Recording>();
  private mediaRecorders = new Map<string, MediaRecorder>();
  
  constructor(
    private storage: StorageService,
    private transcoder: TranscodingService
  ) {}
  
  async startRecording(
    session: WHIPSession,
    options: RecordingOptions = {}
  ): Promise<string> {
    const recordingId = crypto.randomUUID();
    
    // Create recording entry
    const recording: Recording = {
      id: recordingId,
      sessionId: session.id,
      waddleId: session.auth.waddleId,
      channelId: session.auth.channelId,
      startTime: Date.now(),
      state: 'recording',
      options: {
        format: options.format || 'mp4',
        quality: options.quality || 'high',
        maxDuration: options.maxDuration || 7200000, // 2 hours
        includeChat: options.includeChat || false
      },
      segments: [],
      metadata: {
        title: options.title || 'Untitled Broadcast',
        description: options.description,
        broadcaster: session.auth.userId
      }
    };
    
    this.recordings.set(recordingId, recording);
    
    // Start media recording
    await this.startMediaRecording(recording, session);
    
    // Start chat recording if enabled
    if (options.includeChat) {
      await this.startChatRecording(recording);
    }
    
    return recordingId;
  }
  
  private async startMediaRecording(
    recording: Recording,
    session: WHIPSession
  ) {
    // Get combined stream
    const stream = await this.getCombinedStream(session);
    
    // Configure media recorder
    const mimeType = this.getMimeType(recording.options.format);
    const mediaRecorder = new MediaRecorder(stream, {
      mimeType,
      videoBitsPerSecond: this.getBitrate(recording.options.quality)
    });
    
    // Handle data
    const chunks: Blob[] = [];
    let segmentIndex = 0;
    
    mediaRecorder.ondataavailable = async (event) => {
      if (event.data.size > 0) {
        chunks.push(event.data);
        
        // Save segments periodically
        if (chunks.length >= 10) { // Every 10 seconds
          await this.saveSegment(recording, chunks, segmentIndex++);
          chunks.length = 0;
        }
      }
    };
    
    mediaRecorder.onerror = (error) => {
      console.error('Recording error:', error);
      this.handleRecordingError(recording, error);
    };
    
    // Start recording
    mediaRecorder.start(1000); // 1 second chunks
    this.mediaRecorders.set(recording.id, mediaRecorder);
    
    // Set max duration timer
    if (recording.options.maxDuration) {
      setTimeout(() => {
        this.stopRecording(recording.id, 'max_duration');
      }, recording.options.maxDuration);
    }
  }
  
  private async saveSegment(
    recording: Recording,
    chunks: Blob[],
    index: number
  ) {
    const blob = new Blob(chunks, { 
      type: this.getMimeType(recording.options.format) 
    });
    
    // Upload to storage
    const key = `recordings/${recording.id}/segment-${index}.${recording.options.format}`;
    const url = await this.storage.upload(key, blob);
    
    // Update recording
    recording.segments.push({
      index,
      url,
      size: blob.size,
      duration: chunks.length * 1000, // Approximate
      timestamp: Date.now()
    });
  }
  
  async stopRecording(
    recordingId: string,
    reason: string = 'manual'
  ): Promise<void> {
    const recording = this.recordings.get(recordingId);
    if (!recording) return;
    
    const mediaRecorder = this.mediaRecorders.get(recordingId);
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
      mediaRecorder.stop();
    }
    
    recording.state = 'processing';
    recording.endTime = Date.now();
    recording.stopReason = reason;
    
    // Process recording
    await this.processRecording(recording);
  }
  
  private async processRecording(recording: Recording) {
    try {
      // Concatenate segments
      const finalFile = await this.concatenateSegments(recording);
      
      // Generate thumbnails
      const thumbnails = await this.generateThumbnails(finalFile);
      
      // Extract metadata
      const metadata = await this.extractMetadata(finalFile);
      
      // Transcode to different qualities
      const variants = await this.createQualityVariants(finalFile, recording);
      
      // Update recording
      recording.state = 'completed';
      recording.finalFile = finalFile;
      recording.thumbnails = thumbnails;
      recording.metadata = { ...recording.metadata, ...metadata };
      recording.variants = variants;
      
      // Notify completion
      await this.notifyRecordingComplete(recording);
      
    } catch (error) {
      console.error('Recording processing failed:', error);
      recording.state = 'failed';
      recording.error = error.message;
    }
  }
  
  private async createQualityVariants(
    sourceFile: string,
    recording: Recording
  ): Promise<QualityVariant[]> {
    const variants: QualityVariant[] = [];
    
    // Define quality targets
    const qualities = [
      { name: '1080p', height: 1080, bitrate: 4000000 },
      { name: '720p', height: 720, bitrate: 2000000 },
      { name: '480p', height: 480, bitrate: 1000000 }
    ];
    
    for (const quality of qualities) {
      const variant = await this.transcoder.transcode({
        input: sourceFile,
        output: {
          format: 'mp4',
          video: {
            codec: 'h264',
            height: quality.height,
            bitrate: quality.bitrate,
            preset: 'medium'
          },
          audio: {
            codec: 'aac',
            bitrate: 128000
          }
        }
      });
      
      variants.push({
        quality: quality.name,
        url: variant.url,
        size: variant.size,
        bitrate: quality.bitrate
      });
    }
    
    return variants;
  }
}
```

### 6. Analytics and Monitoring
```typescript
// Broadcast analytics
export class BroadcastAnalytics {
  private metrics = new Map<string, BroadcastMetrics>();
  
  constructor(
    private analytics: AnalyticsService,
    private storage: MetricsStorage
  ) {}
  
  async trackBroadcastStart(session: WHIPSession) {
    const metrics: BroadcastMetrics = {
      sessionId: session.id,
      broadcastId: crypto.randomUUID(),
      startTime: Date.now(),
      waddleId: session.auth.waddleId,
      channelId: session.auth.channelId,
      broadcasterId: session.auth.userId,
      viewers: {
        current: 0,
        peak: 0,
        total: 0,
        averageWatchTime: 0
      },
      quality: {
        averageBitrate: 0,
        peakBitrate: 0,
        resolution: '',
        frameRate: 0,
        audioCodec: '',
        videoCodec: ''
      },
      engagement: {
        reactions: 0,
        messages: 0,
        shares: 0
      },
      technical: {
        rebufferingRatio: 0,
        startupTime: 0,
        errors: 0,
        qualitySwitches: 0
      }
    };
    
    this.metrics.set(session.id, metrics);
    
    await this.analytics.track('broadcast_started', {
      broadcastId: metrics.broadcastId,
      waddleId: metrics.waddleId,
      channelId: metrics.channelId
    });
  }
  
  async updateViewerCount(
    sessionId: string,
    count: number
  ) {
    const metrics = this.metrics.get(sessionId);
    if (!metrics) return;
    
    metrics.viewers.current = count;
    metrics.viewers.peak = Math.max(metrics.viewers.peak, count);
    
    // Real-time update
    await this.broadcastMetricsUpdate(sessionId, {
      viewerCount: count,
      peakViewers: metrics.viewers.peak
    });
  }
  
  async trackViewerJoin(
    sessionId: string,
    viewer: ViewerInfo
  ) {
    const metrics = this.metrics.get(sessionId);
    if (!metrics) return;
    
    metrics.viewers.total++;
    
    await this.analytics.track('viewer_joined', {
      broadcastId: metrics.broadcastId,
      viewerId: viewer.id,
      location: viewer.location,
      device: viewer.device,
      connectionType: viewer.connectionType
    });
  }
  
  async trackQualityMetrics(
    sessionId: string,
    quality: QualityMetrics
  ) {
    const metrics = this.metrics.get(sessionId);
    if (!metrics) return;
    
    // Update rolling averages
    metrics.quality.averageBitrate = this.updateAverage(
      metrics.quality.averageBitrate,
      quality.bitrate
    );
    
    metrics.quality.peakBitrate = Math.max(
      metrics.quality.peakBitrate,
      quality.bitrate
    );
    
    metrics.quality.resolution = quality.resolution;
    metrics.quality.frameRate = quality.frameRate;
    
    // Track quality issues
    if (quality.bitrate < 1000000) { // Less than 1 Mbps
      await this.trackQualityIssue(sessionId, 'low_bitrate', quality);
    }
    
    if (quality.frameRate < 24) {
      await this.trackQualityIssue(sessionId, 'low_framerate', quality);
    }
  }
  
  async generateBroadcastReport(
    sessionId: string
  ): Promise<BroadcastReport> {
    const metrics = this.metrics.get(sessionId);
    if (!metrics) throw new Error('Metrics not found');
    
    const duration = Date.now() - metrics.startTime;
    
    return {
      summary: {
        broadcastId: metrics.broadcastId,
        duration,
        peakViewers: metrics.viewers.peak,
        totalViewers: metrics.viewers.total,
        averageWatchTime: metrics.viewers.averageWatchTime,
        engagementRate: this.calculateEngagementRate(metrics)
      },
      quality: {
        averageBitrate: metrics.quality.averageBitrate,
        peakBitrate: metrics.quality.peakBitrate,
        resolution: metrics.quality.resolution,
        stability: this.calculateStabilityScore(metrics)
      },
      audience: await this.getAudienceAnalytics(metrics),
      technical: metrics.technical,
      highlights: await this.generateHighlights(metrics)
    };
  }
  
  private calculateEngagementRate(metrics: BroadcastMetrics): number {
    const totalEngagements = 
      metrics.engagement.reactions +
      metrics.engagement.messages +
      metrics.engagement.shares;
      
    return totalEngagements / Math.max(1, metrics.viewers.total);
  }
  
  private async getAudienceAnalytics(
    metrics: BroadcastMetrics
  ): Promise<AudienceAnalytics> {
    const sessions = await this.storage.getViewerSessions(
      metrics.broadcastId
    );
    
    return {
      geography: this.analyzeGeography(sessions),
      devices: this.analyzeDevices(sessions),
      watchTime: this.analyzeWatchTime(sessions),
      dropOffPoints: this.analyzeDropOff(sessions)
    };
  }
}
```

## Dependencies
- WebRTC infrastructure
- WHIP protocol implementation
- Media server (GStreamer/FFmpeg)
- CDN for distribution
- Transcoding service
- Analytics platform

## Estimated Effort
**7 days**
- 2 days: WHIP server implementation
- 1 day: Stream distribution system
- 1 day: Broadcast control UI
- 1 day: Viewer experience
- 1 day: Recording system
- 1 day: Analytics and monitoring

## Notes
- Support multiple streaming protocols
- Implement stream key management
- Add co-streaming capabilities
- Consider bandwidth optimization
- Enable stream scheduling
- Support custom RTMP if needed
- Plan for global distribution