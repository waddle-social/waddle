# Issue #54: Smart Audio

## User Story
As a **waddle participant**, I want to **experience crystal-clear audio with intelligent noise suppression and enhancement** so that **conversations are always professional and distraction-free**.

## Description
Implement advanced audio processing capabilities including AI-powered noise suppression, echo cancellation, automatic gain control, and intelligent audio gating. This feature ensures professional-quality audio in any environment, with smart detection and removal of background noise, keyboard typing, pets, and other distractions.

## Acceptance Criteria
- [ ] AI-powered noise suppression
- [ ] Intelligent echo cancellation
- [ ] Automatic gain control
- [ ] Smart audio gating
- [ ] Background noise detection
- [ ] Voice enhancement
- [ ] Audio quality monitoring
- [ ] Per-participant audio controls

## Technical Implementation

### 1. Smart Audio Engine
```typescript
// Smart Audio Processing Core
export interface SmartAudioConfig {
  noiseSuppressionLevel: 'low' | 'medium' | 'high' | 'auto';
  echoCancellation: boolean;
  autoGainControl: boolean;
  voiceEnhancement: boolean;
  backgroundDetection: boolean;
  customProfiles: AudioProfile[];
}

export class SmartAudioEngine {
  private audioContext: AudioContext;
  private processors = new Map<string, AudioProcessor>();
  private noiseModels = new Map<string, NoiseModel>();
  private voiceDetector: VoiceActivityDetector;
  
  constructor(
    private config: SmartAudioConfig,
    private mlService: MLService
  ) {
    this.audioContext = new AudioContext({
      sampleRate: 48000,
      latencyHint: 'interactive'
    });
    this.voiceDetector = new VoiceActivityDetector();
    this.initializeProcessors();
  }
  
  async processAudioStream(
    stream: MediaStream,
    participantId: string
  ): Promise<ProcessedAudioStream> {
    const source = this.audioContext.createMediaStreamSource(stream);
    
    // Create processing chain
    const chain = await this.createProcessingChain(participantId);
    
    // Connect nodes
    let currentNode: AudioNode = source;
    
    // 1. Pre-processing (high-pass filter)
    const highPass = this.createHighPassFilter();
    currentNode.connect(highPass);
    currentNode = highPass;
    
    // 2. Noise suppression
    if (this.config.noiseSuppressionLevel !== 'off') {
      const noiseSuppressor = await this.createNoiseSuppressor(participantId);
      currentNode.connect(noiseSuppressor);
      currentNode = noiseSuppressor;
    }
    
    // 3. Echo cancellation
    if (this.config.echoCancellation) {
      const echoCanceller = await this.createEchoCanceller();
      currentNode.connect(echoCanceller);
      currentNode = echoCanceller;
    }
    
    // 4. Auto gain control
    if (this.config.autoGainControl) {
      const agc = await this.createAutoGainControl();
      currentNode.connect(agc);
      currentNode = agc;
    }
    
    // 5. Voice enhancement
    if (this.config.voiceEnhancement) {
      const enhancer = await this.createVoiceEnhancer();
      currentNode.connect(enhancer);
      currentNode = enhancer;
    }
    
    // 6. Smart gating
    const gate = await this.createSmartGate(participantId);
    currentNode.connect(gate);
    currentNode = gate;
    
    // Create output stream
    const destination = this.audioContext.createMediaStreamDestination();
    currentNode.connect(destination);
    
    // Start monitoring
    this.startAudioMonitoring(participantId, chain);
    
    return {
      stream: destination.stream,
      controls: this.createControls(participantId, chain),
      metrics: this.createMetricsCollector(participantId, chain)
    };
  }
  
  private async createNoiseSuppressor(
    participantId: string
  ): Promise<AudioWorkletNode> {
    // Load noise suppression worklet
    await this.audioContext.audioWorklet.addModule(
      '/audio-worklets/noise-suppressor.js'
    );
    
    const suppressor = new AudioWorkletNode(
      this.audioContext,
      'noise-suppressor-processor',
      {
        processorOptions: {
          suppressionLevel: this.config.noiseSuppressionLevel,
          adaptiveMode: this.config.noiseSuppressionLevel === 'auto'
        }
      }
    );
    
    // Load ML model for noise detection
    const model = await this.mlService.loadModel('noise-detection-v2');
    this.noiseModels.set(participantId, model);
    
    // Configure suppressor with ML model
    suppressor.port.postMessage({
      type: 'configure',
      model: model.serialize()
    });
    
    // Listen for noise detection events
    suppressor.port.onmessage = (event) => {
      if (event.data.type === 'noise-detected') {
        this.handleNoiseDetection(participantId, event.data);
      }
    };
    
    return suppressor;
  }
  
  private async createSmartGate(
    participantId: string
  ): Promise<AudioWorkletNode> {
    await this.audioContext.audioWorklet.addModule(
      '/audio-worklets/smart-gate.js'
    );
    
    const gate = new AudioWorkletNode(
      this.audioContext,
      'smart-gate-processor',
      {
        processorOptions: {
          threshold: -40, // dB
          attack: 10, // ms
          hold: 100, // ms
          release: 500, // ms
          lookAhead: 5 // ms
        }
      }
    );
    
    // Configure with voice activity detection
    this.voiceDetector.onActivity(participantId, (isActive) => {
      gate.port.postMessage({
        type: 'voice-activity',
        active: isActive
      });
    });
    
    return gate;
  }
  
  private async createVoiceEnhancer(): Promise<AudioWorkletNode> {
    await this.audioContext.audioWorklet.addModule(
      '/audio-worklets/voice-enhancer.js'
    );
    
    const enhancer = new AudioWorkletNode(
      this.audioContext,
      'voice-enhancer-processor',
      {
        processorOptions: {
          clarity: 0.7,
          warmth: 0.3,
          presence: 0.5,
          deEsser: true
        }
      }
    );
    
    return enhancer;
  }
}

// Noise Detection and Classification
export class NoiseDetector {
  private detectionBuffer: Float32Array;
  private model: TensorFlowModel;
  private noiseTypes = [
    'keyboard', 'mouse', 'fan', 'traffic',
    'construction', 'pets', 'door', 'conversation',
    'music', 'tv', 'other'
  ];
  
  constructor(
    private sampleRate: number,
    private frameSize: number
  ) {
    this.detectionBuffer = new Float32Array(frameSize);
  }
  
  async detectNoise(
    audioData: Float32Array
  ): Promise<NoiseDetectionResult> {
    // Extract features
    const features = await this.extractFeatures(audioData);
    
    // Run inference
    const predictions = await this.model.predict(features);
    
    // Get noise types with confidence
    const detectedNoises = this.noiseTypes
      .map((type, index) => ({
        type,
        confidence: predictions[index]
      }))
      .filter(n => n.confidence > 0.5)
      .sort((a, b) => b.confidence - a.confidence);
    
    return {
      hasNoise: detectedNoises.length > 0,
      noises: detectedNoises,
      overallNoiseLevel: this.calculateNoiseLevel(audioData),
      shouldSuppress: this.shouldSuppress(detectedNoises)
    };
  }
  
  private async extractFeatures(
    audioData: Float32Array
  ): Promise<Float32Array> {
    // Compute spectral features
    const fft = new FFT(this.frameSize);
    const spectrum = fft.forward(audioData);
    
    // Extract MFCC features
    const mfcc = this.computeMFCC(spectrum);
    
    // Extract temporal features
    const temporal = this.computeTemporalFeatures(audioData);
    
    // Combine features
    return new Float32Array([
      ...mfcc,
      ...temporal,
      ...this.computeSpectralFeatures(spectrum)
    ]);
  }
  
  private shouldSuppress(noises: DetectedNoise[]): boolean {
    // Suppress known problematic noises
    const suppressibleNoises = [
      'keyboard', 'mouse', 'fan', 'pets'
    ];
    
    return noises.some(n => 
      suppressibleNoises.includes(n.type) && 
      n.confidence > 0.7
    );
  }
}
```

### 2. Audio Enhancement Algorithms
```typescript
// Advanced Audio Processing Algorithms
export class AudioEnhancementProcessor {
  private spectralSubtractor: SpectralSubtractor;
  private adaptiveFilter: AdaptiveFilter;
  private psychoacousticModel: PsychoacousticModel;
  
  constructor() {
    this.spectralSubtractor = new SpectralSubtractor();
    this.adaptiveFilter = new AdaptiveFilter();
    this.psychoacousticModel = new PsychoacousticModel();
  }
  
  async enhanceVoice(
    audioBuffer: AudioBuffer,
    profile: VoiceProfile
  ): Promise<AudioBuffer> {
    // Multi-band processing
    const bands = this.splitIntoBands(audioBuffer);
    
    // Process each band
    const processedBands = await Promise.all(
      bands.map(async (band, index) => {
        // Apply band-specific processing
        let processed = band;
        
        // Low frequencies (< 250Hz) - reduce rumble
        if (index === 0) {
          processed = await this.reduceRumble(processed);
        }
        
        // Mid frequencies (250Hz - 4kHz) - enhance clarity
        if (index >= 1 && index <= 3) {
          processed = await this.enhanceClarity(processed, profile);
        }
        
        // High frequencies (> 4kHz) - control sibilance
        if (index >= 4) {
          processed = await this.controlSibilance(processed);
        }
        
        return processed;
      })
    );
    
    // Recombine bands
    return this.combineBands(processedBands);
  }
  
  private async enhanceClarity(
    audioData: Float32Array,
    profile: VoiceProfile
  ): Promise<Float32Array> {
    // Formant enhancement
    const formants = await this.detectFormants(audioData);
    const enhanced = new Float32Array(audioData.length);
    
    // Apply psychoacoustic enhancement
    for (let i = 0; i < audioData.length; i++) {
      const sample = audioData[i];
      
      // Enhance formant regions
      let enhancement = 0;
      for (const formant of formants) {
        const distance = Math.abs(i - formant.position);
        const gain = this.calculateFormantGain(distance, formant);
        enhancement += sample * gain;
      }
      
      // Apply subtle harmonic excitation
      const harmonic = this.generateHarmonic(sample, profile.fundamentalFreq);
      
      enhanced[i] = sample + (enhancement * 0.3) + (harmonic * 0.1);
    }
    
    // Apply dynamic range optimization
    return this.optimizeDynamicRange(enhanced);
  }
  
  private async reduceRumble(
    audioData: Float32Array
  ): Promise<Float32Array> {
    // Adaptive high-pass filtering
    const cutoffFreq = await this.detectRumbleFrequency(audioData);
    
    // Apply steep high-pass filter
    const filter = new ButterworthFilter({
      type: 'highpass',
      frequency: cutoffFreq,
      order: 4,
      sampleRate: 48000
    });
    
    return filter.process(audioData);
  }
}

// Echo Cancellation System
export class EchoCancellationSystem {
  private adaptiveFilter: NLMSFilter;
  private delayEstimator: DelayEstimator;
  private doubleDetector: DoubleTalkDetector;
  
  constructor(
    private config: EchoCancellationConfig
  ) {
    this.adaptiveFilter = new NLMSFilter({
      filterLength: config.filterLength || 2048,
      stepSize: config.stepSize || 0.1,
      regularization: config.regularization || 0.01
    });
    
    this.delayEstimator = new DelayEstimator();
    this.doubleDetector = new DoubleTalkDetector();
  }
  
  async process(
    nearEnd: Float32Array, // Microphone signal
    farEnd: Float32Array   // Speaker signal
  ): Promise<Float32Array> {
    // Estimate delay between speaker and microphone
    const delay = await this.delayEstimator.estimate(farEnd, nearEnd);
    
    // Align signals
    const alignedFarEnd = this.alignSignal(farEnd, delay);
    
    // Detect double-talk
    const isDoubleTalk = await this.doubleDetector.detect(
      nearEnd,
      alignedFarEnd
    );
    
    // Apply adaptive filtering
    const output = new Float32Array(nearEnd.length);
    
    for (let i = 0; i < nearEnd.length; i++) {
      // Predict echo
      const echoEstimate = this.adaptiveFilter.predict(alignedFarEnd[i]);
      
      // Subtract echo from microphone signal
      output[i] = nearEnd[i] - echoEstimate;
      
      // Update filter (only when not double-talking)
      if (!isDoubleTalk) {
        this.adaptiveFilter.update(
          alignedFarEnd[i],
          output[i]
        );
      }
    }
    
    // Post-processing to remove residual echo
    return this.postProcess(output);
  }
  
  private postProcess(signal: Float32Array): Float32Array {
    // Non-linear processing for residual echo suppression
    const processed = new Float32Array(signal.length);
    
    for (let i = 0; i < signal.length; i++) {
      const sample = signal[i];
      const magnitude = Math.abs(sample);
      
      // Comfort noise injection for very low levels
      if (magnitude < 0.001) {
        processed[i] = (Math.random() - 0.5) * 0.0001;
      } else {
        // Soft limiting for residual echo
        processed[i] = sample * this.softLimiter(magnitude);
      }
    }
    
    return processed;
  }
}
```

### 3. Audio Quality Monitoring
```typescript
// Real-time Audio Quality Monitor
export class AudioQualityMonitor {
  private metrics = new Map<string, AudioMetrics>();
  private thresholds: QualityThresholds;
  private alertCallbacks = new Set<(alert: QualityAlert) => void>();
  
  constructor(config: MonitorConfig) {
    this.thresholds = config.thresholds;
    this.startMonitoring();
  }
  
  async analyzeAudioStream(
    participantId: string,
    audioData: Float32Array
  ): Promise<AudioMetrics> {
    const metrics: AudioMetrics = {
      timestamp: Date.now(),
      level: this.calculateLevel(audioData),
      peakLevel: this.calculatePeakLevel(audioData),
      noiseFloor: await this.calculateNoiseFloor(audioData),
      snr: 0, // Calculated below
      clarity: await this.calculateClarity(audioData),
      distortion: this.calculateDistortion(audioData),
      bandwidth: await this.estimateBandwidth(audioData),
      voicePresence: await this.detectVoicePresence(audioData)
    };
    
    // Calculate SNR
    metrics.snr = metrics.level - metrics.noiseFloor;
    
    // Store metrics
    this.metrics.set(participantId, metrics);
    
    // Check for quality issues
    this.checkQualityThresholds(participantId, metrics);
    
    return metrics;
  }
  
  private checkQualityThresholds(
    participantId: string,
    metrics: AudioMetrics
  ): void {
    const alerts: QualityAlert[] = [];
    
    // Check level issues
    if (metrics.level < this.thresholds.minLevel) {
      alerts.push({
        type: 'low_level',
        severity: 'warning',
        participantId,
        message: 'Audio level too low',
        suggestion: 'Move closer to microphone or increase gain'
      });
    } else if (metrics.peakLevel > this.thresholds.maxLevel) {
      alerts.push({
        type: 'clipping',
        severity: 'error',
        participantId,
        message: 'Audio clipping detected',
        suggestion: 'Reduce microphone gain or move back'
      });
    }
    
    // Check noise issues
    if (metrics.snr < this.thresholds.minSNR) {
      alerts.push({
        type: 'high_noise',
        severity: 'warning',
        participantId,
        message: 'High background noise detected',
        suggestion: 'Enable noise suppression or move to quieter location'
      });
    }
    
    // Check clarity
    if (metrics.clarity < this.thresholds.minClarity) {
      alerts.push({
        type: 'low_clarity',
        severity: 'info',
        participantId,
        message: 'Voice clarity could be improved',
        suggestion: 'Check microphone position and room acoustics'
      });
    }
    
    // Emit alerts
    alerts.forEach(alert => {
      this.alertCallbacks.forEach(callback => callback(alert));
    });
  }
  
  async generateQualityReport(
    participantId: string,
    duration: number
  ): Promise<QualityReport> {
    const samples = await this.getMetricsSamples(participantId, duration);
    
    return {
      participantId,
      duration,
      averageLevel: this.calculateAverage(samples, 'level'),
      averageSNR: this.calculateAverage(samples, 'snr'),
      averageClarity: this.calculateAverage(samples, 'clarity'),
      issues: this.identifyRecurringIssues(samples),
      recommendations: await this.generateRecommendations(samples),
      score: this.calculateOverallScore(samples)
    };
  }
}
```

### 4. Smart Audio UI Components
```tsx
export function SmartAudioControls({ participantId }: { participantId: string }) {
  const [settings, setSettings] = useState<AudioSettings>();
  const [metrics, setMetrics] = useState<AudioMetrics>();
  const [showAdvanced, setShowAdvanced] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  
  const audioEngine = useSmartAudioEngine();
  
  useEffect(() => {
    // Subscribe to audio metrics
    const unsubscribe = audioEngine.subscribeToMetrics(
      participantId,
      setMetrics
    );
    
    return unsubscribe;
  }, [participantId]);
  
  const updateSetting = async (key: string, value: any) => {
    setIsProcessing(true);
    try {
      await audioEngine.updateSettings(participantId, { [key]: value });
      setSettings(prev => ({ ...prev!, [key]: value }));
    } finally {
      setIsProcessing(false);
    }
  };
  
  return (
    <div className="smart-audio-controls">
      <div className="audio-header">
        <h3>Smart Audio</h3>
        <AudioQualityIndicator metrics={metrics} />
      </div>
      
      <div className="audio-meters">
        <VolumeLevel
          level={metrics?.level || 0}
          peak={metrics?.peakLevel || 0}
          threshold={-20}
        />
        
        <NoiseLevel
          noise={metrics?.noiseFloor || -60}
          snr={metrics?.snr || 0}
        />
      </div>
      
      <div className="audio-settings">
        <ToggleSetting
          label="Noise Suppression"
          value={settings?.noiseSuppression || false}
          onChange={(v) => updateSetting('noiseSuppression', v)}
          disabled={isProcessing}
        />
        
        <SliderSetting
          label="Suppression Level"
          value={settings?.suppressionLevel || 'medium'}
          options={['low', 'medium', 'high', 'auto']}
          onChange={(v) => updateSetting('suppressionLevel', v)}
          disabled={!settings?.noiseSuppression || isProcessing}
        />
        
        <ToggleSetting
          label="Echo Cancellation"
          value={settings?.echoCancellation || false}
          onChange={(v) => updateSetting('echoCancellation', v)}
          disabled={isProcessing}
        />
        
        <ToggleSetting
          label="Auto Gain Control"
          value={settings?.autoGainControl || false}
          onChange={(v) => updateSetting('autoGainControl', v)}
          disabled={isProcessing}
        />
        
        <ToggleSetting
          label="Voice Enhancement"
          value={settings?.voiceEnhancement || false}
          onChange={(v) => updateSetting('voiceEnhancement', v)}
          disabled={isProcessing}
        />
      </div>
      
      {showAdvanced && (
        <AdvancedAudioSettings
          settings={settings}
          onUpdate={updateSetting}
          metrics={metrics}
        />
      )}
      
      <button
        className="advanced-toggle"
        onClick={() => setShowAdvanced(!showAdvanced)}
      >
        {showAdvanced ? 'Hide' : 'Show'} Advanced Settings
      </button>
      
      <AudioDiagnostics
        participantId={participantId}
        metrics={metrics}
      />
    </div>
  );
}

function AudioQualityIndicator({ metrics }: { metrics?: AudioMetrics }) {
  if (!metrics) return null;
  
  const quality = calculateQuality(metrics);
  
  return (
    <div className={`audio-quality-indicator quality-${quality.level}`}>
      <div className="quality-dots">
        {[1, 2, 3, 4, 5].map(i => (
          <div
            key={i}
            className={`quality-dot ${i <= quality.score ? 'active' : ''}`}
          />
        ))}
      </div>
      <span className="quality-label">{quality.label}</span>
      {quality.issue && (
        <Tooltip content={quality.suggestion}>
          <WarningIcon className="quality-warning" />
        </Tooltip>
      )}
    </div>
  );
}

function NoiseDetectionPanel({ 
  participantId 
}: { 
  participantId: string 
}) {
  const [detectedNoises, setDetectedNoises] = useState<DetectedNoise[]>([]);
  const [isSupressing, setIsSuppressing] = useState<string[]>([]);
  
  useSubscription(`noise.${participantId}`, (event: NoiseEvent) => {
    setDetectedNoises(event.noises);
  });
  
  return (
    <div className="noise-detection-panel">
      <h4>Background Noise Detection</h4>
      
      {detectedNoises.length === 0 ? (
        <p className="no-noise">No background noise detected</p>
      ) : (
        <div className="noise-list">
          {detectedNoises.map(noise => (
            <NoiseItem
              key={noise.type}
              noise={noise}
              isSuppressed={isSupressing.includes(noise.type)}
              onToggleSuppression={(suppress) => {
                if (suppress) {
                  setIsSuppressing(prev => [...prev, noise.type]);
                } else {
                  setIsSuppressing(prev => 
                    prev.filter(t => t !== noise.type)
                  );
                }
              }}
            />
          ))}
        </div>
      )}
      
      <div className="noise-visualization">
        <SpectrumAnalyzer
          participantId={participantId}
          highlightNoises={detectedNoises}
        />
      </div>
    </div>
  );
}
```

### 5. Audio Profiles & Presets
```typescript
// Audio Profile Manager
export class AudioProfileManager {
  private profiles = new Map<string, AudioProfile>();
  private activeProfiles = new Map<string, string>();
  
  constructor(
    private storage: ProfileStorage,
    private audioEngine: SmartAudioEngine
  ) {
    this.loadDefaultProfiles();
  }
  
  private loadDefaultProfiles() {
    const defaults: AudioProfile[] = [
      {
        id: 'voice-focus',
        name: 'Voice Focus',
        description: 'Optimized for clear speech',
        settings: {
          noiseSuppression: true,
          suppressionLevel: 'high',
          echoCancellation: true,
          autoGainControl: true,
          voiceEnhancement: true,
          enhancementSettings: {
            clarity: 0.8,
            warmth: 0.2,
            presence: 0.6
          }
        }
      },
      {
        id: 'music-friendly',
        name: 'Music Friendly',
        description: 'Preserves musical content',
        settings: {
          noiseSuppression: true,
          suppressionLevel: 'low',
          echoCancellation: true,
          autoGainControl: false,
          voiceEnhancement: false,
          preserveHighFrequencies: true
        }
      },
      {
        id: 'podcast',
        name: 'Podcast',
        description: 'Professional podcast quality',
        settings: {
          noiseSuppression: true,
          suppressionLevel: 'medium',
          echoCancellation: true,
          autoGainControl: true,
          voiceEnhancement: true,
          enhancementSettings: {
            clarity: 0.7,
            warmth: 0.5,
            presence: 0.8,
            deEsser: true
          },
          compression: {
            threshold: -20,
            ratio: 3,
            attack: 10,
            release: 100
          }
        }
      },
      {
        id: 'noisy-environment',
        name: 'Noisy Environment',
        description: 'Maximum noise reduction',
        settings: {
          noiseSuppression: true,
          suppressionLevel: 'auto',
          echoCancellation: true,
          autoGainControl: true,
          voiceEnhancement: true,
          gateSettings: {
            threshold: -35,
            attack: 5,
            release: 200
          }
        }
      }
    ];
    
    defaults.forEach(profile => {
      this.profiles.set(profile.id, profile);
    });
  }
  
  async createCustomProfile(
    name: string,
    baseProfileId?: string
  ): Promise<AudioProfile> {
    const baseProfile = baseProfileId ? 
      this.profiles.get(baseProfileId) : 
      this.profiles.get('voice-focus');
    
    const customProfile: AudioProfile = {
      id: generateId(),
      name,
      description: 'Custom profile',
      settings: { ...baseProfile!.settings },
      isCustom: true,
      createdAt: Date.now()
    };
    
    await this.storage.saveProfile(customProfile);
    this.profiles.set(customProfile.id, customProfile);
    
    return customProfile;
  }
  
  async applyProfile(
    participantId: string,
    profileId: string
  ): Promise<void> {
    const profile = this.profiles.get(profileId);
    if (!profile) {
      throw new Error(`Profile ${profileId} not found`);
    }
    
    // Apply all settings from profile
    await this.audioEngine.updateSettings(
      participantId,
      profile.settings
    );
    
    // Track active profile
    this.activeProfiles.set(participantId, profileId);
    
    // Save preference
    await this.storage.savePreference(participantId, profileId);
  }
  
  async autoSelectProfile(
    participantId: string,
    environment: EnvironmentAnalysis
  ): Promise<AudioProfile> {
    // Analyze environment and select best profile
    let selectedProfile: AudioProfile;
    
    if (environment.noiseLevel > 60) {
      selectedProfile = this.profiles.get('noisy-environment')!;
    } else if (environment.hasMusic) {
      selectedProfile = this.profiles.get('music-friendly')!;
    } else if (environment.isProfessional) {
      selectedProfile = this.profiles.get('podcast')!;
    } else {
      selectedProfile = this.profiles.get('voice-focus')!;
    }
    
    await this.applyProfile(participantId, selectedProfile.id);
    
    return selectedProfile;
  }
}

// Profile Selection UI
export function AudioProfileSelector({ 
  participantId 
}: { 
  participantId: string 
}) {
  const [profiles, setProfiles] = useState<AudioProfile[]>([]);
  const [activeProfile, setActiveProfile] = useState<string>();
  const [showCustomizer, setShowCustomizer] = useState(false);
  
  const profileManager = useAudioProfileManager();
  
  useEffect(() => {
    loadProfiles();
  }, []);
  
  const loadProfiles = async () => {
    const [available, active] = await Promise.all([
      profileManager.getProfiles(),
      profileManager.getActiveProfile(participantId)
    ]);
    
    setProfiles(available);
    setActiveProfile(active?.id);
  };
  
  const selectProfile = async (profileId: string) => {
    await profileManager.applyProfile(participantId, profileId);
    setActiveProfile(profileId);
    toast.success('Audio profile applied');
  };
  
  return (
    <div className="audio-profile-selector">
      <div className="profile-header">
        <h4>Audio Profiles</h4>
        <button
          className="create-profile-btn"
          onClick={() => setShowCustomizer(true)}
        >
          Create Custom
        </button>
      </div>
      
      <div className="profile-grid">
        {profiles.map(profile => (
          <ProfileCard
            key={profile.id}
            profile={profile}
            isActive={profile.id === activeProfile}
            onSelect={() => selectProfile(profile.id)}
            onEdit={profile.isCustom ? 
              () => editProfile(profile) : undefined
            }
          />
        ))}
      </div>
      
      {showCustomizer && (
        <ProfileCustomizer
          onSave={async (profile) => {
            await loadProfiles();
            setShowCustomizer(false);
          }}
          onCancel={() => setShowCustomizer(false)}
        />
      )}
    </div>
  );
}
```

### 6. Audio Analytics & Insights
```typescript
// Audio Analytics System
export class AudioAnalytics {
  private metricsCollector: MetricsCollector;
  private insightsEngine: InsightsEngine;
  
  constructor(
    private storage: AnalyticsStorage
  ) {
    this.metricsCollector = new MetricsCollector();
    this.insightsEngine = new InsightsEngine();
  }
  
  async analyzeSession(
    sessionId: string,
    participants: string[]
  ): Promise<SessionAnalysis> {
    const metrics = await this.metricsCollector.collectSessionMetrics(
      sessionId,
      participants
    );
    
    const analysis: SessionAnalysis = {
      sessionId,
      duration: metrics.duration,
      participants: await Promise.all(
        participants.map(p => this.analyzeParticipant(p, metrics))
      ),
      overallQuality: this.calculateOverallQuality(metrics),
      issues: this.identifyIssues(metrics),
      improvements: await this.suggestImprovements(metrics),
      timeline: this.createQualityTimeline(metrics)
    };
    
    await this.storage.saveAnalysis(analysis);
    
    return analysis;
  }
  
  private async analyzeParticipant(
    participantId: string,
    metrics: SessionMetrics
  ): Promise<ParticipantAnalysis> {
    const participantMetrics = metrics.participants[participantId];
    
    return {
      participantId,
      averageQuality: this.calculateAverageQuality(participantMetrics),
      speakingTime: participantMetrics.speakingTime,
      noiseIncidents: participantMetrics.noiseIncidents,
      audioIssues: this.categorizeIssues(participantMetrics.issues),
      recommendations: await this.generateRecommendations(
        participantMetrics
      )
    };
  }
  
  async generateInsights(
    userId: string,
    timeRange: TimeRange
  ): Promise<AudioInsights> {
    const sessions = await this.storage.getSessionsForUser(
      userId,
      timeRange
    );
    
    const insights = await this.insightsEngine.analyze(sessions);
    
    return {
      userId,
      timeRange,
      summary: {
        totalSessions: sessions.length,
        averageQuality: insights.averageQuality,
        commonIssues: insights.commonIssues,
        improvements: insights.improvements
      },
      trends: {
        qualityTrend: insights.qualityTrend,
        issueFrequency: insights.issueFrequency,
        environmentChanges: insights.environmentChanges
      },
      recommendations: await this.generatePersonalizedRecommendations(
        userId,
        insights
      )
    };
  }
}

// Audio Insights Dashboard
export function AudioInsightsDashboard({ userId }: { userId: string }) {
  const [insights, setInsights] = useState<AudioInsights>();
  const [timeRange, setTimeRange] = useState<TimeRange>({ days: 30 });
  const [loading, setLoading] = useState(true);
  
  useEffect(() => {
    loadInsights();
  }, [userId, timeRange]);
  
  const loadInsights = async () => {
    setLoading(true);
    try {
      const data = await api.getAudioInsights(userId, timeRange);
      setInsights(data);
    } finally {
      setLoading(false);
    }
  };
  
  if (loading) return <LoadingSpinner />;
  if (!insights) return <EmptyState />;
  
  return (
    <div className="audio-insights-dashboard">
      <div className="insights-header">
        <h2>Audio Quality Insights</h2>
        <TimeRangeSelector value={timeRange} onChange={setTimeRange} />
      </div>
      
      <div className="insights-summary">
        <SummaryCard
          title="Average Quality"
          value={`${Math.round(insights.summary.averageQuality)}%`}
          trend={insights.trends.qualityTrend}
        />
        
        <SummaryCard
          title="Sessions"
          value={insights.summary.totalSessions}
          subtitle="Total sessions"
        />
        
        <SummaryCard
          title="Common Issue"
          value={insights.summary.commonIssues[0]?.type || 'None'}
          subtitle={`${insights.summary.commonIssues[0]?.count || 0} occurrences`}
        />
      </div>
      
      <div className="insights-charts">
        <QualityTrendChart data={insights.trends.qualityTrend} />
        <IssueFrequencyChart data={insights.trends.issueFrequency} />
        <EnvironmentAnalysis data={insights.trends.environmentChanges} />
      </div>
      
      <div className="insights-recommendations">
        <h3>Recommendations</h3>
        <RecommendationsList 
          recommendations={insights.recommendations}
          onApply={applyRecommendation}
        />
      </div>
    </div>
  );
}
```

## Dependencies
- Web Audio API for processing
- TensorFlow.js for ML models
- Audio worklets for real-time processing
- WebRTC for audio streaming
- FFT libraries for spectral analysis

## Estimated Effort
**5 days**
- 1 day: Core audio engine setup
- 1 day: Noise suppression and enhancement
- 1 day: Echo cancellation system
- 1 day: Quality monitoring and UI
- 1 day: Profiles and analytics

## Notes
- Implement adaptive processing based on CPU usage
- Add support for spatial audio processing
- Consider hardware acceleration options
- Implement audio fingerprinting for feedback detection
- Add support for external audio interfaces
- Create audio testing/calibration wizard
- Consider perceptual audio coding optimizations