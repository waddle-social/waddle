# Issue #38: Screen Sharing

## User Story
As a **waddle participant**, I want to **share my screen during voice calls** so that **I can present content, collaborate on documents, or demonstrate software to other participants**.

## Description
Implement screen sharing capabilities in Waddle voice channels using WebRTC screen capture APIs. This feature allows participants to share their entire screen, specific application windows, or browser tabs during voice conversations. The implementation should include both desktop capture and application-specific sharing with optimized encoding for different content types.

## Acceptance Criteria
- [ ] Screen capture initialization
- [ ] Multiple source selection (screen, window, tab)
- [ ] Dynamic resolution adjustment
- [ ] Screen share quality settings
- [ ] Simultaneous screen shares support
- [ ] Permission handling and errors
- [ ] Mobile screen sharing support
- [ ] Screen annotation tools

## Technical Implementation

### 1. Screen Capture Manager
```typescript
// Screen capture types and interfaces
export interface ScreenShareOptions {
  video: {
    width?: { ideal: number; max: number };
    height?: { ideal: number; max: number };
    frameRate?: { ideal: number; max: number };
    displaySurface?: 'monitor' | 'window' | 'application' | 'browser';
    logicalSurface?: boolean;
    cursor?: 'always' | 'motion' | 'never';
  };
  audio?: boolean | {
    echoCancellation?: boolean;
    noiseSuppression?: boolean;
    sampleRate?: number;
  };
  preferCurrentTab?: boolean;
  selfBrowserSurface?: 'include' | 'exclude';
  systemAudio?: 'include' | 'exclude';
  surfaceSwitching?: 'include' | 'exclude';
  monitorTypeSurfaces?: 'include' | 'exclude';
}

export class ScreenCaptureManager {
  private currentStream: MediaStream | null = null;
  private screenTracks = new Map<string, MediaStreamTrack>();
  private qualityController: QualityController;
  private encodingOptimizer: EncodingOptimizer;
  
  constructor(
    private rtcEngine: RTCEngine,
    private analytics: AnalyticsService
  ) {
    this.qualityController = new QualityController();
    this.encodingOptimizer = new EncodingOptimizer();
  }
  
  async startScreenShare(
    options: ScreenShareOptions = {}
  ): Promise<ScreenShareSession> {
    try {
      // Default options optimized for screen content
      const defaultOptions: ScreenShareOptions = {
        video: {
          width: { ideal: 1920, max: 3840 },
          height: { ideal: 1080, max: 2160 },
          frameRate: { ideal: 30, max: 60 },
          cursor: 'always',
          displaySurface: 'monitor'
        },
        audio: false,
        preferCurrentTab: false,
        selfBrowserSurface: 'exclude',
        systemAudio: 'exclude',
        surfaceSwitching: 'include',
        monitorTypeSurfaces: 'include'
      };
      
      const mergedOptions = { ...defaultOptions, ...options };
      
      // Request screen capture
      const stream = await navigator.mediaDevices.getDisplayMedia(mergedOptions);
      
      if (!stream) {
        throw new Error('Screen capture cancelled or failed');
      }
      
      this.currentStream = stream;
      
      // Get video track
      const videoTrack = stream.getVideoTracks()[0];
      if (!videoTrack) {
        throw new Error('No video track in screen capture');
      }
      
      // Apply content hint for better encoding
      if ('contentHint' in videoTrack) {
        videoTrack.contentHint = this.detectContentType(videoTrack);
      }
      
      // Store track reference
      const trackId = crypto.randomUUID();
      this.screenTracks.set(trackId, videoTrack);
      
      // Handle track ended event
      videoTrack.addEventListener('ended', () => {
        this.handleScreenShareEnded(trackId);
      });
      
      // Get capture details
      const settings = videoTrack.getSettings();
      const capabilities = videoTrack.getCapabilities();
      
      // Create screen share session
      const session: ScreenShareSession = {
        id: trackId,
        stream,
        videoTrack,
        audioTrack: stream.getAudioTracks()[0] || null,
        settings: {
          width: settings.width || 1920,
          height: settings.height || 1080,
          frameRate: settings.frameRate || 30,
          displaySurface: settings.displaySurface || 'monitor',
          cursor: settings.cursor || 'always'
        },
        capabilities,
        startTime: Date.now(),
        quality: await this.qualityController.getInitialQuality(settings)
      };
      
      // Optimize encoding based on content
      await this.optimizeEncoding(session);
      
      // Track analytics
      await this.analytics.track('screen_share_started', {
        sessionId: session.id,
        displaySurface: session.settings.displaySurface,
        resolution: `${session.settings.width}x${session.settings.height}`,
        frameRate: session.settings.frameRate,
        hasAudio: !!session.audioTrack
      });
      
      return session;
      
    } catch (error) {
      if (error.name === 'NotAllowedError') {
        throw new Error('Screen sharing permission denied');
      } else if (error.name === 'NotFoundError') {
        throw new Error('No screen sharing sources available');
      } else if (error.name === 'NotReadableError') {
        throw new Error('Screen source is not readable');
      } else if (error.name === 'OverconstrainedError') {
        throw new Error('Screen sharing constraints cannot be satisfied');
      }
      
      throw error;
    }
  }
  
  private detectContentType(track: MediaStreamTrack): string {
    const settings = track.getSettings();
    
    // Detect based on display surface
    if (settings.displaySurface === 'browser') {
      return 'text'; // Web content, optimize for text
    } else if (settings.displaySurface === 'window') {
      // Could be anything, default to detail
      return 'detail';
    } else {
      // Full screen, likely mixed content
      return 'motion';
    }
  }
  
  private async optimizeEncoding(session: ScreenShareSession) {
    const { width, height, frameRate } = session.settings;
    
    // Calculate optimal bitrate based on resolution and content
    const baseBitrate = this.calculateBaseBitrate(width, height);
    const contentMultiplier = this.getContentMultiplier(session.videoTrack);
    const optimalBitrate = baseBitrate * contentMultiplier;
    
    // Configure encoding parameters
    const encodingParams: RTCRtpEncodingParameters = {
      maxBitrate: optimalBitrate,
      maxFramerate: frameRate,
      scaleResolutionDownBy: 1.0,
      networkPriority: 'high',
      priority: 'high'
    };
    
    // Apply scalability layers for better quality adaptation
    if (width >= 1920 && height >= 1080) {
      encodingParams.scalabilityMode = 'L3T3'; // 3 temporal, 3 spatial layers
    } else {
      encodingParams.scalabilityMode = 'L2T2'; // 2 temporal, 2 spatial layers
    }
    
    await this.rtcEngine.updateEncodingParameters(
      session.videoTrack,
      encodingParams
    );
  }
  
  private calculateBaseBitrate(width: number, height: number): number {
    const pixels = width * height;
    
    // Base bitrate calculation for screen content
    if (pixels <= 921600) { // 720p
      return 1500000; // 1.5 Mbps
    } else if (pixels <= 2073600) { // 1080p
      return 3000000; // 3 Mbps
    } else if (pixels <= 3686400) { // 1440p
      return 5000000; // 5 Mbps
    } else { // 4K and above
      return 8000000; // 8 Mbps
    }
  }
  
  async stopScreenShare(sessionId: string): Promise<void> {
    const track = this.screenTracks.get(sessionId);
    if (!track) {
      throw new Error('Screen share session not found');
    }
    
    // Stop the track
    track.stop();
    
    // Cleanup
    this.screenTracks.delete(sessionId);
    
    if (this.currentStream) {
      this.currentStream.getTracks().forEach(track => track.stop());
      this.currentStream = null;
    }
    
    // Track analytics
    await this.analytics.track('screen_share_stopped', {
      sessionId,
      duration: Date.now() - this.getSessionStartTime(sessionId)
    });
  }
  
  private handleScreenShareEnded(sessionId: string) {
    console.log(`Screen share ended: ${sessionId}`);
    
    // Cleanup
    this.screenTracks.delete(sessionId);
    
    // Notify listeners
    this.emit('screenShareEnded', { sessionId });
    
    // Track analytics
    this.analytics.track('screen_share_ended_by_user', {
      sessionId
    });
  }
}
```

### 2. Screen Share Transport
```typescript
// WebRTC transport for screen sharing
export class ScreenShareTransport {
  private peerConnection: RTCPeerConnection;
  private dataChannel: RTCDataChannel | null = null;
  private statsCollector: StatsCollector;
  
  constructor(
    private sessionId: string,
    private iceServers: RTCIceServer[],
    private signaling: SignalingService
  ) {
    this.peerConnection = new RTCPeerConnection({
      iceServers,
      iceTransportPolicy: 'all',
      bundlePolicy: 'max-bundle',
      rtcpMuxPolicy: 'require'
    });
    
    this.statsCollector = new StatsCollector(this.peerConnection);
    this.setupPeerConnection();
  }
  
  private setupPeerConnection() {
    // Handle ICE candidates
    this.peerConnection.onicecandidate = (event) => {
      if (event.candidate) {
        this.signaling.sendCandidate(this.sessionId, event.candidate);
      }
    };
    
    // Handle connection state changes
    this.peerConnection.onconnectionstatechange = () => {
      console.log(`Connection state: ${this.peerConnection.connectionState}`);
      
      if (this.peerConnection.connectionState === 'failed') {
        this.handleConnectionFailure();
      }
    };
    
    // Create data channel for annotations
    this.dataChannel = this.peerConnection.createDataChannel('annotations', {
      ordered: true,
      maxRetransmits: 3
    });
    
    this.setupDataChannel();
  }
  
  private setupDataChannel() {
    if (!this.dataChannel) return;
    
    this.dataChannel.onopen = () => {
      console.log('Annotation channel opened');
    };
    
    this.dataChannel.onmessage = (event) => {
      this.handleAnnotation(JSON.parse(event.data));
    };
    
    this.dataChannel.onerror = (error) => {
      console.error('Data channel error:', error);
    };
  }
  
  async addScreenShareTrack(
    track: MediaStreamTrack,
    stream: MediaStream
  ): Promise<RTCRtpSender> {
    // Add track with specific encoding for screen content
    const sender = this.peerConnection.addTrack(track, stream);
    
    // Get and modify parameters for screen content
    const params = sender.getParameters();
    
    if (!params.encodings) {
      params.encodings = [{}];
    }
    
    // Configure for screen content
    params.encodings[0] = {
      ...params.encodings[0],
      maxBitrate: 3000000, // 3 Mbps
      maxFramerate: 30,
      networkPriority: 'high',
      priority: 'high',
      scaleResolutionDownBy: 1.0
    };
    
    // Set degradation preference for screen content
    params.degradationPreference = 'maintain-resolution';
    
    await sender.setParameters(params);
    
    return sender;
  }
  
  async updateQuality(quality: ScreenShareQuality) {
    const senders = this.peerConnection.getSenders();
    const videoSender = senders.find(s => s.track?.kind === 'video');
    
    if (!videoSender) return;
    
    const params = videoSender.getParameters();
    if (!params.encodings || !params.encodings[0]) return;
    
    // Update encoding based on quality preset
    switch (quality) {
      case 'low':
        params.encodings[0].maxBitrate = 500000; // 500 Kbps
        params.encodings[0].scaleResolutionDownBy = 4.0;
        params.encodings[0].maxFramerate = 5;
        break;
      case 'medium':
        params.encodings[0].maxBitrate = 1500000; // 1.5 Mbps
        params.encodings[0].scaleResolutionDownBy = 2.0;
        params.encodings[0].maxFramerate = 15;
        break;
      case 'high':
        params.encodings[0].maxBitrate = 3000000; // 3 Mbps
        params.encodings[0].scaleResolutionDownBy = 1.0;
        params.encodings[0].maxFramerate = 30;
        break;
      case 'ultra':
        params.encodings[0].maxBitrate = 8000000; // 8 Mbps
        params.encodings[0].scaleResolutionDownBy = 1.0;
        params.encodings[0].maxFramerate = 60;
        break;
    }
    
    await videoSender.setParameters(params);
  }
  
  async getStats(): Promise<ScreenShareStats> {
    const stats = await this.statsCollector.collect();
    
    return {
      bitrate: stats.video.bitrate,
      frameRate: stats.video.frameRate,
      resolution: stats.video.resolution,
      packetLoss: stats.video.packetLoss,
      jitter: stats.video.jitter,
      roundTripTime: stats.connection.rtt,
      bandwidth: stats.connection.availableBandwidth
    };
  }
  
  sendAnnotation(annotation: ScreenAnnotation) {
    if (this.dataChannel && this.dataChannel.readyState === 'open') {
      this.dataChannel.send(JSON.stringify(annotation));
    }
  }
  
  private handleAnnotation(annotation: ScreenAnnotation) {
    this.emit('annotation', annotation);
  }
  
  private async handleConnectionFailure() {
    console.error('Screen share connection failed');
    
    // Attempt to restart ICE
    try {
      await this.peerConnection.restartIce();
    } catch (error) {
      console.error('Failed to restart ICE:', error);
      this.emit('connectionFailed');
    }
  }
  
  async close() {
    this.statsCollector.stop();
    
    if (this.dataChannel) {
      this.dataChannel.close();
    }
    
    this.peerConnection.close();
  }
}
```

### 3. Screen Share UI Components
```tsx
export function ScreenShareButton({ channelId }: { channelId: string }) {
  const [isSharing, setIsSharing] = useState(false);
  const [showSourcePicker, setShowSourcePicker] = useState(false);
  const [shareQuality, setShareQuality] = useState<ScreenShareQuality>('high');
  const [shareSession, setShareSession] = useState<ScreenShareSession | null>(null);
  
  const startScreenShare = async (options?: ScreenShareOptions) => {
    try {
      const session = await screenCaptureManager.startScreenShare(options);
      
      // Add to voice channel
      await voiceChannel.addScreenShare(session);
      
      setShareSession(session);
      setIsSharing(true);
      setShowSourcePicker(false);
      
      toast.success('Screen sharing started');
    } catch (error) {
      if (error.message.includes('permission denied')) {
        toast.error('Screen sharing permission denied');
      } else {
        toast.error('Failed to start screen sharing');
      }
      console.error('Screen share error:', error);
    }
  };
  
  const stopScreenShare = async () => {
    if (!shareSession) return;
    
    try {
      await screenCaptureManager.stopScreenShare(shareSession.id);
      await voiceChannel.removeScreenShare(shareSession.id);
      
      setIsSharing(false);
      setShareSession(null);
      
      toast.info('Screen sharing stopped');
    } catch (error) {
      toast.error('Failed to stop screen sharing');
      console.error('Stop screen share error:', error);
    }
  };
  
  if (isSharing && shareSession) {
    return (
      <ScreenShareControls
        session={shareSession}
        quality={shareQuality}
        onQualityChange={setShareQuality}
        onStop={stopScreenShare}
      />
    );
  }
  
  return (
    <>
      <Button
        variant="secondary"
        onClick={() => setShowSourcePicker(true)}
        leftIcon={<ScreenShareIcon />}
      >
        Share Screen
      </Button>
      
      {showSourcePicker && (
        <ScreenSourcePicker
          onSelect={startScreenShare}
          onCancel={() => setShowSourcePicker(false)}
        />
      )}
    </>
  );
}

export function ScreenSourcePicker({ 
  onSelect, 
  onCancel 
}: { 
  onSelect: (options: ScreenShareOptions) => void;
  onCancel: () => void;
}) {
  const [selectedSource, setSelectedSource] = useState<'screen' | 'window' | 'tab'>('screen');
  const [includeAudio, setIncludeAudio] = useState(false);
  const [optimizeFor, setOptimizeFor] = useState<'auto' | 'text' | 'motion'>('auto');
  
  const handleStart = () => {
    const options: ScreenShareOptions = {
      video: {
        displaySurface: selectedSource === 'tab' ? 'browser' : selectedSource === 'window' ? 'window' : 'monitor',
        cursor: 'always'
      },
      audio: includeAudio,
      preferCurrentTab: selectedSource === 'tab'
    };
    
    // Add optimization hints
    if (optimizeFor === 'text') {
      options.video!.frameRate = { ideal: 5, max: 10 };
    } else if (optimizeFor === 'motion') {
      options.video!.frameRate = { ideal: 30, max: 60 };
    }
    
    onSelect(options);
  };
  
  return (
    <Modal
      title="Share Your Screen"
      onClose={onCancel}
      size="medium"
    >
      <div className="screen-source-picker">
        <div className="source-options">
          <h3>What would you like to share?</h3>
          
          <RadioGroup value={selectedSource} onChange={setSelectedSource}>
            <Radio value="screen">
              <div className="source-option">
                <ScreenIcon />
                <div>
                  <h4>Entire Screen</h4>
                  <p>Share everything on your display</p>
                </div>
              </div>
            </Radio>
            
            <Radio value="window">
              <div className="source-option">
                <WindowIcon />
                <div>
                  <h4>Application Window</h4>
                  <p>Share a specific application</p>
                </div>
              </div>
            </Radio>
            
            <Radio value="tab">
              <div className="source-option">
                <TabIcon />
                <div>
                  <h4>Browser Tab</h4>
                  <p>Share a single browser tab</p>
                </div>
              </div>
            </Radio>
          </RadioGroup>
        </div>
        
        <div className="share-options">
          <h3>Options</h3>
          
          <Toggle
            checked={includeAudio}
            onChange={setIncludeAudio}
            label="Share audio"
            description="Include system audio with your screen"
          />
          
          <div className="optimize-section">
            <label>Optimize for:</label>
            <Select value={optimizeFor} onChange={setOptimizeFor}>
              <option value="auto">Automatic</option>
              <option value="text">Text & Presentations</option>
              <option value="motion">Video & Motion</option>
            </Select>
          </div>
        </div>
        
        <div className="picker-actions">
          <Button variant="secondary" onClick={onCancel}>
            Cancel
          </Button>
          <Button variant="primary" onClick={handleStart}>
            Start Sharing
          </Button>
        </div>
      </div>
    </Modal>
  );
}

export function ScreenShareControls({
  session,
  quality,
  onQualityChange,
  onStop
}: {
  session: ScreenShareSession;
  quality: ScreenShareQuality;
  onQualityChange: (quality: ScreenShareQuality) => void;
  onStop: () => void;
}) {
  const [isPaused, setIsPaused] = useState(false);
  const [showAnnotations, setShowAnnotations] = useState(false);
  const [stats, setStats] = useState<ScreenShareStats>();
  
  useEffect(() => {
    const interval = setInterval(async () => {
      const newStats = await session.transport.getStats();
      setStats(newStats);
    }, 1000);
    
    return () => clearInterval(interval);
  }, [session]);
  
  const togglePause = () => {
    if (isPaused) {
      session.videoTrack.enabled = true;
      setIsPaused(false);
    } else {
      session.videoTrack.enabled = false;
      setIsPaused(true);
    }
  };
  
  return (
    <div className="screen-share-controls">
      <div className="control-bar">
        <Button
          variant="secondary"
          size="small"
          onClick={togglePause}
          leftIcon={isPaused ? <PlayIcon /> : <PauseIcon />}
        >
          {isPaused ? 'Resume' : 'Pause'}
        </Button>
        
        <Select
          value={quality}
          onChange={(e) => onQualityChange(e.target.value as ScreenShareQuality)}
          size="small"
        >
          <option value="low">Low Quality</option>
          <option value="medium">Medium Quality</option>
          <option value="high">High Quality</option>
          <option value="ultra">Ultra Quality</option>
        </Select>
        
        <Button
          variant="secondary"
          size="small"
          onClick={() => setShowAnnotations(!showAnnotations)}
          leftIcon={<PenIcon />}
        >
          Annotate
        </Button>
        
        <Button
          variant="danger"
          size="small"
          onClick={onStop}
          leftIcon={<StopIcon />}
        >
          Stop Sharing
        </Button>
      </div>
      
      {stats && (
        <div className="share-stats">
          <div className="stat">
            <span className="label">Resolution</span>
            <span className="value">{stats.resolution}</span>
          </div>
          <div className="stat">
            <span className="label">FPS</span>
            <span className="value">{stats.frameRate}</span>
          </div>
          <div className="stat">
            <span className="label">Bitrate</span>
            <span className="value">{formatBitrate(stats.bitrate)}</span>
          </div>
        </div>
      )}
      
      {showAnnotations && (
        <AnnotationToolbar session={session} />
      )}
    </div>
  );
}
```

### 4. Screen Viewer Component
```tsx
export function ScreenShareViewer({ 
  sessionId,
  participantName 
}: { 
  sessionId: string;
  participantName: string;
}) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [stream, setStream] = useState<MediaStream>();
  const [isFullscreen, setIsFullscreen] = useState(false);
  const [showControls, setShowControls] = useState(true);
  const [annotations, setAnnotations] = useState<ScreenAnnotation[]>([]);
  const [fitMode, setFitMode] = useState<'contain' | 'cover'>('contain');
  
  useEffect(() => {
    subscribeToScreenShare();
    
    return () => {
      unsubscribeFromScreenShare();
    };
  }, [sessionId]);
  
  const subscribeToScreenShare = async () => {
    try {
      const shareStream = await voiceChannel.subscribeToScreenShare(sessionId);
      setStream(shareStream);
      
      if (videoRef.current) {
        videoRef.current.srcObject = shareStream;
      }
    } catch (error) {
      console.error('Failed to subscribe to screen share:', error);
      toast.error('Failed to view screen share');
    }
  };
  
  const unsubscribeFromScreenShare = async () => {
    if (stream) {
      stream.getTracks().forEach(track => track.stop());
    }
    
    await voiceChannel.unsubscribeFromScreenShare(sessionId);
  };
  
  const toggleFullscreen = async () => {
    const container = videoRef.current?.parentElement;
    if (!container) return;
    
    if (!isFullscreen) {
      await container.requestFullscreen();
      setIsFullscreen(true);
    } else {
      await document.exitFullscreen();
      setIsFullscreen(false);
    }
  };
  
  const handleAnnotation = (annotation: ScreenAnnotation) => {
    setAnnotations(prev => [...prev, annotation]);
    
    // Remove annotation after duration
    if (annotation.duration) {
      setTimeout(() => {
        setAnnotations(prev => prev.filter(a => a.id !== annotation.id));
      }, annotation.duration);
    }
  };
  
  // Listen for annotations
  useEffect(() => {
    const transport = getScreenShareTransport(sessionId);
    transport.on('annotation', handleAnnotation);
    
    return () => {
      transport.off('annotation', handleAnnotation);
    };
  }, [sessionId]);
  
  return (
    <div 
      className={`screen-share-viewer ${isFullscreen ? 'fullscreen' : ''}`}
      onMouseMove={() => setShowControls(true)}
      onMouseLeave={() => setShowControls(false)}
    >
      <div className="viewer-header">
        <div className="sharing-info">
          <ScreenShareIcon />
          <span>{participantName} is sharing their screen</span>
        </div>
      </div>
      
      <div className="video-container">
        <video
          ref={videoRef}
          autoPlay
          playsInline
          className={`screen-video fit-${fitMode}`}
        />
        
        <canvas
          ref={canvasRef}
          className="annotation-layer"
        />
        
        {annotations.map(annotation => (
          <ScreenAnnotation
            key={annotation.id}
            annotation={annotation}
          />
        ))}
      </div>
      
      {showControls && (
        <div className="viewer-controls">
          <div className="control-group">
            <Button
              variant="ghost"
              size="small"
              onClick={() => setFitMode(fitMode === 'contain' ? 'cover' : 'contain')}
              leftIcon={fitMode === 'contain' ? <FitScreenIcon /> : <ZoomIcon />}
            >
              {fitMode === 'contain' ? 'Fit' : 'Fill'}
            </Button>
            
            <Button
              variant="ghost"
              size="small"
              onClick={toggleFullscreen}
              leftIcon={isFullscreen ? <MinimizeIcon /> : <MaximizeIcon />}
            >
              {isFullscreen ? 'Exit Fullscreen' : 'Fullscreen'}
            </Button>
          </div>
          
          <div className="control-group">
            <VolumeControl stream={stream} />
            
            <Button
              variant="ghost"
              size="small"
              onClick={() => downloadScreenshot()}
              leftIcon={<CameraIcon />}
            >
              Screenshot
            </Button>
          </div>
        </div>
      )}
    </div>
  );
}
```

### 5. Annotation System
```typescript
// Annotation tools for screen sharing
export interface ScreenAnnotation {
  id: string;
  type: 'pointer' | 'draw' | 'text' | 'shape' | 'highlight';
  data: any;
  style: {
    color: string;
    width?: number;
    opacity?: number;
  };
  position: { x: number; y: number };
  timestamp: number;
  duration?: number;
  authorId: string;
}

export class AnnotationManager {
  private canvas: HTMLCanvasElement;
  private ctx: CanvasRenderingContext2D;
  private annotations = new Map<string, ScreenAnnotation>();
  private currentTool: AnnotationTool = 'pointer';
  private isDrawing = false;
  private lastPoint: { x: number; y: number } | null = null;
  
  constructor(
    canvas: HTMLCanvasElement,
    private transport: ScreenShareTransport
  ) {
    this.canvas = canvas;
    this.ctx = canvas.getContext('2d')!;
    this.setupEventListeners();
  }
  
  private setupEventListeners() {
    this.canvas.addEventListener('mousedown', this.handleMouseDown);
    this.canvas.addEventListener('mousemove', this.handleMouseMove);
    this.canvas.addEventListener('mouseup', this.handleMouseUp);
    this.canvas.addEventListener('mouseleave', this.handleMouseLeave);
    
    // Touch support
    this.canvas.addEventListener('touchstart', this.handleTouchStart);
    this.canvas.addEventListener('touchmove', this.handleTouchMove);
    this.canvas.addEventListener('touchend', this.handleTouchEnd);
  }
  
  private handleMouseDown = (e: MouseEvent) => {
    const point = this.getRelativePoint(e);
    
    switch (this.currentTool) {
      case 'draw':
        this.startDrawing(point);
        break;
      case 'pointer':
        this.createPointer(point);
        break;
      case 'text':
        this.createTextAnnotation(point);
        break;
      case 'shape':
        this.startShape(point);
        break;
      case 'highlight':
        this.startHighlight(point);
        break;
    }
  };
  
  private handleMouseMove = (e: MouseEvent) => {
    const point = this.getRelativePoint(e);
    
    if (this.isDrawing && this.currentTool === 'draw') {
      this.continueDraw(point);
    } else if (this.currentTool === 'pointer') {
      this.updatePointer(point);
    }
  };
  
  private startDrawing(point: { x: number; y: number }) {
    this.isDrawing = true;
    this.lastPoint = point;
    
    const annotation: ScreenAnnotation = {
      id: crypto.randomUUID(),
      type: 'draw',
      data: {
        points: [point],
        path: new Path2D()
      },
      style: {
        color: this.currentColor,
        width: this.currentWidth,
        opacity: 0.8
      },
      position: point,
      timestamp: Date.now(),
      authorId: this.currentUserId
    };
    
    annotation.data.path.moveTo(point.x, point.y);
    this.annotations.set(annotation.id, annotation);
  }
  
  private continueDraw(point: { x: number; y: number }) {
    if (!this.isDrawing || !this.lastPoint) return;
    
    const currentAnnotation = Array.from(this.annotations.values())
      .find(a => a.type === 'draw' && a.timestamp > Date.now() - 100);
      
    if (currentAnnotation) {
      currentAnnotation.data.points.push(point);
      currentAnnotation.data.path.lineTo(point.x, point.y);
      
      // Draw on canvas
      this.ctx.strokeStyle = currentAnnotation.style.color;
      this.ctx.lineWidth = currentAnnotation.style.width || 2;
      this.ctx.globalAlpha = currentAnnotation.style.opacity || 0.8;
      this.ctx.lineCap = 'round';
      this.ctx.lineJoin = 'round';
      
      this.ctx.beginPath();
      this.ctx.moveTo(this.lastPoint.x, this.lastPoint.y);
      this.ctx.lineTo(point.x, point.y);
      this.ctx.stroke();
      
      // Send incremental update
      this.transport.sendAnnotation({
        ...currentAnnotation,
        data: {
          type: 'draw-update',
          from: this.lastPoint,
          to: point
        }
      });
    }
    
    this.lastPoint = point;
  }
  
  private createPointer(point: { x: number; y: number }) {
    const annotation: ScreenAnnotation = {
      id: crypto.randomUUID(),
      type: 'pointer',
      data: {
        size: 20,
        animated: true
      },
      style: {
        color: this.currentColor,
        opacity: 1
      },
      position: point,
      timestamp: Date.now(),
      duration: 3000, // Pointer disappears after 3 seconds
      authorId: this.currentUserId
    };
    
    this.annotations.set(annotation.id, annotation);
    this.transport.sendAnnotation(annotation);
    this.renderPointer(annotation);
  }
  
  private renderPointer(annotation: ScreenAnnotation) {
    const { x, y } = annotation.position;
    const size = annotation.data.size;
    
    // Animated ripple effect
    let scale = 1;
    const animate = () => {
      this.ctx.save();
      this.ctx.globalAlpha = Math.max(0, 1 - scale / 3);
      this.ctx.strokeStyle = annotation.style.color;
      this.ctx.lineWidth = 3;
      
      this.ctx.beginPath();
      this.ctx.arc(x, y, size * scale, 0, Math.PI * 2);
      this.ctx.stroke();
      
      this.ctx.restore();
      
      scale += 0.05;
      if (scale < 3) {
        requestAnimationFrame(animate);
      }
    };
    
    animate();
  }
  
  setTool(tool: AnnotationTool) {
    this.currentTool = tool;
    this.updateCursor();
  }
  
  private updateCursor() {
    switch (this.currentTool) {
      case 'draw':
        this.canvas.style.cursor = 'crosshair';
        break;
      case 'pointer':
        this.canvas.style.cursor = 'pointer';
        break;
      case 'text':
        this.canvas.style.cursor = 'text';
        break;
      case 'shape':
        this.canvas.style.cursor = 'crosshair';
        break;
      case 'highlight':
        this.canvas.style.cursor = 'crosshair';
        break;
      default:
        this.canvas.style.cursor = 'default';
    }
  }
  
  clearAnnotations() {
    this.annotations.clear();
    this.ctx.clearRect(0, 0, this.canvas.width, this.canvas.height);
    
    this.transport.sendAnnotation({
      id: crypto.randomUUID(),
      type: 'clear',
      data: {},
      style: {},
      position: { x: 0, y: 0 },
      timestamp: Date.now(),
      authorId: this.currentUserId
    });
  }
  
  private getRelativePoint(e: MouseEvent): { x: number; y: number } {
    const rect = this.canvas.getBoundingClientRect();
    const scaleX = this.canvas.width / rect.width;
    const scaleY = this.canvas.height / rect.height;
    
    return {
      x: (e.clientX - rect.left) * scaleX,
      y: (e.clientY - rect.top) * scaleY
    };
  }
}
```

### 6. Quality Adaptation
```typescript
// Dynamic quality adaptation for screen sharing
export class ScreenShareQualityAdapter {
  private qualityLevels: QualityLevel[] = [
    { name: 'ultra', bitrate: 8000000, fps: 60, scale: 1.0 },
    { name: 'high', bitrate: 3000000, fps: 30, scale: 1.0 },
    { name: 'medium', bitrate: 1500000, fps: 15, scale: 2.0 },
    { name: 'low', bitrate: 500000, fps: 5, scale: 4.0 }
  ];
  
  private currentLevel = 1; // Start with high
  private adaptationHistory: AdaptationEvent[] = [];
  
  constructor(
    private transport: ScreenShareTransport,
    private statsMonitor: StatsMonitor
  ) {
    this.startAdaptation();
  }
  
  private async startAdaptation() {
    setInterval(async () => {
      await this.checkAndAdapt();
    }, 2000); // Check every 2 seconds
  }
  
  private async checkAndAdapt() {
    const stats = await this.transport.getStats();
    const networkQuality = this.calculateNetworkQuality(stats);
    
    // Determine if we need to adapt
    if (networkQuality.score < 0.7 && this.currentLevel < this.qualityLevels.length - 1) {
      // Downgrade quality
      await this.changeQuality(this.currentLevel + 1);
    } else if (networkQuality.score > 0.9 && this.currentLevel > 0) {
      // Upgrade quality if stable for 10 seconds
      const recentAdaptations = this.adaptationHistory.filter(
        e => e.timestamp > Date.now() - 10000
      );
      
      if (recentAdaptations.length === 0) {
        await this.changeQuality(this.currentLevel - 1);
      }
    }
  }
  
  private calculateNetworkQuality(stats: ScreenShareStats): NetworkQuality {
    let score = 1.0;
    
    // Factor 1: Packet loss (40% weight)
    if (stats.packetLoss > 5) {
      score -= 0.4;
    } else if (stats.packetLoss > 2) {
      score -= 0.2;
    } else if (stats.packetLoss > 0.5) {
      score -= 0.1;
    }
    
    // Factor 2: RTT (30% weight)
    if (stats.roundTripTime > 300) {
      score -= 0.3;
    } else if (stats.roundTripTime > 150) {
      score -= 0.15;
    } else if (stats.roundTripTime > 50) {
      score -= 0.05;
    }
    
    // Factor 3: Bandwidth utilization (30% weight)
    const targetBitrate = this.qualityLevels[this.currentLevel].bitrate;
    const utilization = stats.bitrate / targetBitrate;
    
    if (utilization < 0.5) {
      score -= 0.3;
    } else if (utilization < 0.8) {
      score -= 0.15;
    }
    
    return {
      score: Math.max(0, score),
      packetLoss: stats.packetLoss,
      rtt: stats.roundTripTime,
      bandwidth: stats.bandwidth
    };
  }
  
  private async changeQuality(newLevel: number) {
    if (newLevel < 0 || newLevel >= this.qualityLevels.length) return;
    if (newLevel === this.currentLevel) return;
    
    const quality = this.qualityLevels[newLevel];
    
    console.log(`Adapting screen share quality: ${this.qualityLevels[this.currentLevel].name} -> ${quality.name}`);
    
    // Update transport quality
    await this.transport.updateQuality(quality.name as ScreenShareQuality);
    
    // Record adaptation
    this.adaptationHistory.push({
      timestamp: Date.now(),
      fromLevel: this.currentLevel,
      toLevel: newLevel,
      reason: newLevel > this.currentLevel ? 'network_degradation' : 'network_improvement'
    });
    
    this.currentLevel = newLevel;
    
    // Emit quality change event
    this.emit('qualityChanged', {
      quality: quality.name,
      bitrate: quality.bitrate,
      fps: quality.fps,
      scale: quality.scale
    });
  }
  
  getCurrentQuality(): QualityLevel {
    return this.qualityLevels[this.currentLevel];
  }
  
  getAdaptationHistory(): AdaptationEvent[] {
    return this.adaptationHistory.slice(-10); // Last 10 events
  }
}
```

## Dependencies
- WebRTC getDisplayMedia API
- RTCPeerConnection for transport
- Canvas API for annotations
- MediaStream API
- Screen Capture API permissions

## Estimated Effort
**5 days**
- 1 day: Screen capture manager and source selection
- 1 day: WebRTC transport and quality control
- 1 day: UI components and controls
- 1 day: Annotation system
- 1 day: Quality adaptation and optimization

## Notes
- Test across different operating systems
- Handle permission prompts gracefully
- Consider CPU usage for high-resolution shares
- Implement viewer-side quality preferences
- Add recording capability for screen shares
- Support multiple simultaneous screen shares
- Consider mobile screen sharing limitations