# Issue #53: Translation

## User Story
As a **waddle participant**, I want to **communicate with others in different languages through real-time translation** so that **language barriers don't prevent effective collaboration**.

## Description
Implement comprehensive real-time translation capabilities for voice and text communications. This includes automatic language detection, real-time voice translation with original speaker preservation, text message translation, and subtitle generation for video calls, enabling seamless multilingual collaboration.

## Acceptance Criteria
- [ ] Automatic language detection
- [ ] Real-time voice translation
- [ ] Text message translation
- [ ] Video call subtitles
- [ ] Language preference settings
- [ ] Translation quality indicators
- [ ] Offline translation support
- [ ] Translation history

## Technical Implementation

### 1. Translation Engine
```typescript
// Translation Service Core
export interface TranslationConfig {
  sourceLanguage: string | 'auto';
  targetLanguages: string[];
  translationMode: 'realtime' | 'batch';
  quality: 'fast' | 'balanced' | 'high';
  preserveFormatting: boolean;
  customGlossary?: GlossaryEntry[];
}

export class TranslationEngine {
  private activeTranslations = new Map<string, TranslationSession>();
  private languageDetector: LanguageDetector;
  private translators = new Map<string, Translator>();
  
  constructor(
    private config: TranslationConfig,
    private translationAPI: TranslationAPI
  ) {
    this.languageDetector = new LanguageDetector();
    this.initializeTranslators();
  }
  
  async translateText(
    text: string,
    options: TranslateOptions = {}
  ): Promise<TranslationResult> {
    // Detect source language if auto
    const sourceLanguage = options.sourceLanguage || 
      await this.detectLanguage(text);
    
    // Get target languages
    const targetLanguages = options.targetLanguages || 
      this.config.targetLanguages;
    
    // Check cache first
    const cacheKey = this.getCacheKey(text, sourceLanguage, targetLanguages);
    const cached = await this.getFromCache(cacheKey);
    if (cached) return cached;
    
    // Perform translations in parallel
    const translations = await Promise.all(
      targetLanguages.map(async (targetLang) => {
        const translator = this.getTranslator(sourceLanguage, targetLang);
        return translator.translate(text, {
          quality: options.quality || this.config.quality,
          preserveFormatting: options.preserveFormatting,
          glossary: this.config.customGlossary
        });
      })
    );
    
    const result: TranslationResult = {
      id: generateId(),
      originalText: text,
      sourceLanguage,
      translations: translations.reduce((acc, trans, idx) => {
        acc[targetLanguages[idx]] = trans;
        return acc;
      }, {} as Record<string, Translation>),
      timestamp: Date.now(),
      confidence: this.calculateConfidence(translations)
    };
    
    // Cache result
    await this.cacheResult(cacheKey, result);
    
    return result;
  }
  
  async startVoiceTranslation(
    channelId: string,
    userId: string,
    config: VoiceTranslationConfig
  ): Promise<VoiceTranslationSession> {
    const session = new VoiceTranslationSession({
      channelId,
      userId,
      sourceLanguage: config.sourceLanguage,
      targetLanguages: config.targetLanguages,
      onTranslation: this.handleVoiceTranslation.bind(this),
      preserveVoice: config.preserveVoice
    });
    
    this.activeTranslations.set(`${channelId}-${userId}`, session);
    
    await session.start();
    
    return session;
  }
  
  private async detectLanguage(
    text: string
  ): Promise<string> {
    const detection = await this.languageDetector.detect(text);
    
    if (detection.confidence < 0.7) {
      // Try with more context if available
      const extendedDetection = await this.detectWithContext(text);
      if (extendedDetection.confidence > detection.confidence) {
        return extendedDetection.language;
      }
    }
    
    return detection.language;
  }
  
  private getTranslator(
    sourceLanguage: string,
    targetLanguage: string
  ): Translator {
    const key = `${sourceLanguage}-${targetLanguage}`;
    
    if (!this.translators.has(key)) {
      this.translators.set(key, new Translator({
        source: sourceLanguage,
        target: targetLanguage,
        api: this.translationAPI,
        model: this.getModelForPair(sourceLanguage, targetLanguage)
      }));
    }
    
    return this.translators.get(key)!;
  }
}

// Voice Translation Session
export class VoiceTranslationSession {
  private audioProcessor: AudioProcessor;
  private speechRecognizer: SpeechRecognizer;
  private voiceSynthesizer: VoiceSynthesizer;
  private translationBuffer: TranslationBuffer;
  
  constructor(
    private config: VoiceTranslationSessionConfig
  ) {
    this.audioProcessor = new AudioProcessor();
    this.speechRecognizer = new SpeechRecognizer(config.sourceLanguage);
    this.voiceSynthesizer = new VoiceSynthesizer();
    this.translationBuffer = new TranslationBuffer();
  }
  
  async processAudioChunk(audioData: ArrayBuffer): Promise<void> {
    // Process audio for speech recognition
    const processed = await this.audioProcessor.process(audioData, {
      denoise: true,
      normalize: true,
      vad: true // Voice Activity Detection
    });
    
    if (!processed.hasVoice) return;
    
    // Add to recognition buffer
    await this.speechRecognizer.addAudio(processed.data);
    
    // Get intermediate results
    const result = await this.speechRecognizer.getResult();
    
    if (result.isFinal) {
      await this.translateAndSynthesize(result);
    } else {
      // Update live captions
      await this.updateLiveCaptions(result);
    }
  }
  
  private async translateAndSynthesize(
    recognitionResult: RecognitionResult
  ): Promise<void> {
    // Translate to all target languages
    const translations = await Promise.all(
      this.config.targetLanguages.map(async (lang) => {
        const translation = await this.translate(
          recognitionResult.text,
          recognitionResult.language,
          lang
        );
        
        // Synthesize voice if enabled
        if (this.config.preserveVoice) {
          const synthesized = await this.synthesizeWithVoiceCloning(
            translation.text,
            lang,
            recognitionResult.voiceCharacteristics
          );
          
          return {
            ...translation,
            audio: synthesized
          };
        }
        
        return translation;
      })
    );
    
    // Emit translation event
    this.config.onTranslation({
      original: recognitionResult,
      translations,
      timestamp: Date.now()
    });
  }
  
  private async synthesizeWithVoiceCloning(
    text: string,
    language: string,
    voiceCharacteristics: VoiceCharacteristics
  ): Promise<ArrayBuffer> {
    return this.voiceSynthesizer.synthesize(text, {
      language,
      voice: voiceCharacteristics,
      speed: 1.0,
      pitch: voiceCharacteristics.pitch,
      emotion: voiceCharacteristics.emotion
    });
  }
}
```

### 2. Real-time Translation UI
```tsx
export function TranslationInterface({ channelId }: { channelId: string }) {
  const [isTranslating, setIsTranslating] = useState(false);
  const [languages, setLanguages] = useState<LanguageSettings>({
    source: 'auto',
    targets: ['en', 'es', 'fr']
  });
  const [mode, setMode] = useState<'voice' | 'text' | 'both'>('both');
  const [showSubtitles, setShowSubtitles] = useState(true);
  
  const translationService = useTranslationService();
  
  useEffect(() => {
    if (isTranslating) {
      startTranslation();
    } else {
      stopTranslation();
    }
  }, [isTranslating, languages, mode]);
  
  const startTranslation = async () => {
    await translationService.start({
      channelId,
      languages,
      mode,
      onTranslation: handleTranslation
    });
  };
  
  const handleTranslation = (event: TranslationEvent) => {
    // Update UI with translations
    if (event.type === 'voice' && showSubtitles) {
      updateSubtitles(event);
    }
  };
  
  return (
    <div className="translation-interface">
      <div className="translation-header">
        <TranslationToggle
          isActive={isTranslating}
          onChange={setIsTranslating}
        />
        <LanguageSelector
          languages={languages}
          onChange={setLanguages}
        />
        <TranslationModeSelector
          mode={mode}
          onChange={setMode}
        />
      </div>
      
      {isTranslating && (
        <>
          <TranslationIndicator
            sourceLanguage={languages.source}
            targetLanguages={languages.targets}
          />
          
          <SubtitleDisplay
            show={showSubtitles}
            channelId={channelId}
          />
          
          <TranslationStats />
        </>
      )}
      
      <TranslationSettings
        showSubtitles={showSubtitles}
        onShowSubtitlesChange={setShowSubtitles}
      />
    </div>
  );
}

function SubtitleDisplay({ 
  show, 
  channelId 
}: { 
  show: boolean;
  channelId: string;
}) {
  const [subtitles, setSubtitles] = useState<Subtitle[]>([]);
  const [settings, setSettings] = useState<SubtitleSettings>({
    position: 'bottom',
    size: 'medium',
    background: 'translucent',
    fontFamily: 'sans-serif'
  });
  
  useSubscription(`translation.${channelId}`, (event: TranslationEvent) => {
    if (event.type === 'voice' && event.subtitle) {
      setSubtitles(prev => [...prev, event.subtitle].slice(-3));
    }
  });
  
  if (!show || subtitles.length === 0) return null;
  
  return (
    <div className={`subtitle-display ${settings.position}`}>
      {subtitles.map((subtitle, index) => (
        <SubtitleLine
          key={subtitle.id}
          subtitle={subtitle}
          settings={settings}
          isLatest={index === subtitles.length - 1}
        />
      ))}
    </div>
  );
}

function SubtitleLine({ 
  subtitle, 
  settings, 
  isLatest 
}: {
  subtitle: Subtitle;
  settings: SubtitleSettings;
  isLatest: boolean;
}) {
  const [selectedLanguage, setSelectedLanguage] = useState(
    subtitle.translations[0]?.language || 'en'
  );
  
  const translation = subtitle.translations.find(
    t => t.language === selectedLanguage
  );
  
  return (
    <div className={`subtitle-line ${isLatest ? 'latest' : ''}`}>
      <div className="subtitle-header">
        <span className="speaker">{subtitle.speaker}</span>
        <LanguageToggle
          languages={subtitle.translations.map(t => t.language)}
          selected={selectedLanguage}
          onChange={setSelectedLanguage}
        />
      </div>
      
      <div 
        className={`subtitle-text ${settings.size} ${settings.background}`}
        style={{ fontFamily: settings.fontFamily }}
      >
        {translation?.text || subtitle.originalText}
      </div>
      
      {translation?.confidence && translation.confidence < 0.8 && (
        <ConfidenceIndicator confidence={translation.confidence} />
      )}
    </div>
  );
}
```

### 3. Message Translation
```typescript
// Message Translation System
export class MessageTranslationService {
  private translationEngine: TranslationEngine;
  private messageCache = new Map<string, TranslatedMessage>();
  
  constructor(
    private env: Env,
    private userPreferences: UserPreferencesService
  ) {
    this.translationEngine = new TranslationEngine(env.TRANSLATION_CONFIG);
  }
  
  async translateMessage(
    message: Message,
    targetLanguages?: string[]
  ): Promise<TranslatedMessage> {
    // Check cache
    const cacheKey = `${message.id}-${targetLanguages?.join(',')}`;
    if (this.messageCache.has(cacheKey)) {
      return this.messageCache.get(cacheKey)!;
    }
    
    // Get user's preferred languages if not specified
    const languages = targetLanguages || 
      await this.getUserLanguages(message.recipientId);
    
    // Detect message language
    const sourceLanguage = await this.detectMessageLanguage(message);
    
    // Skip if already in target language
    if (languages.length === 1 && languages[0] === sourceLanguage) {
      return {
        ...message,
        translations: {},
        sourceLanguage
      };
    }
    
    // Translate message parts
    const translations = await this.translateMessageParts(
      message,
      sourceLanguage,
      languages
    );
    
    const translatedMessage: TranslatedMessage = {
      ...message,
      sourceLanguage,
      translations,
      translatedAt: Date.now()
    };
    
    // Cache result
    this.messageCache.set(cacheKey, translatedMessage);
    
    return translatedMessage;
  }
  
  private async translateMessageParts(
    message: Message,
    sourceLanguage: string,
    targetLanguages: string[]
  ): Promise<MessageTranslations> {
    const translations: MessageTranslations = {};
    
    for (const lang of targetLanguages) {
      if (lang === sourceLanguage) continue;
      
      translations[lang] = {
        content: await this.translateContent(
          message.content,
          sourceLanguage,
          lang
        ),
        embeds: await this.translateEmbeds(
          message.embeds,
          sourceLanguage,
          lang
        ),
        reactions: await this.translateReactions(
          message.reactions,
          sourceLanguage,
          lang
        )
      };
    }
    
    return translations;
  }
  
  private async translateContent(
    content: MessageContent,
    source: string,
    target: string
  ): Promise<MessageContent> {
    if (content.type === 'text') {
      const result = await this.translationEngine.translateText(
        content.text,
        { sourceLanguage: source, targetLanguages: [target] }
      );
      
      return {
        type: 'text',
        text: result.translations[target].text,
        formatting: await this.translateFormatting(
          content.formatting,
          source,
          target
        )
      };
    }
    
    // Handle other content types (images with captions, etc.)
    return content;
  }
  
  async createTranslationView(
    messages: Message[],
    viewerLanguage: string
  ): Promise<TranslationView> {
    const translatedMessages = await Promise.all(
      messages.map(msg => this.translateMessage(msg, [viewerLanguage]))
    );
    
    return {
      messages: translatedMessages,
      viewerLanguage,
      statistics: this.calculateTranslationStats(translatedMessages),
      glossary: await this.extractGlossary(translatedMessages)
    };
  }
}

// Translation UI Components
export function MessageWithTranslation({ 
  message 
}: { 
  message: TranslatedMessage 
}) {
  const [showOriginal, setShowOriginal] = useState(false);
  const [selectedLanguage, setSelectedLanguage] = useState<string>();
  const userLanguage = useUserLanguage();
  
  const displayLanguage = selectedLanguage || userLanguage;
  const translation = message.translations[displayLanguage];
  
  return (
    <div className="translated-message">
      <div className="message-header">
        <UserAvatar user={message.author} />
        <span className="author-name">{message.author.name}</span>
        <MessageTimestamp timestamp={message.timestamp} />
        
        {message.sourceLanguage !== displayLanguage && (
          <TranslationBadge
            from={message.sourceLanguage}
            to={displayLanguage}
            onClick={() => setShowOriginal(!showOriginal)}
          />
        )}
      </div>
      
      <div className="message-content">
        {showOriginal ? (
          <div className="original-content">
            <MessageContent content={message.content} />
            <span className="original-label">Original ({message.sourceLanguage})</span>
          </div>
        ) : translation ? (
          <MessageContent content={translation.content} />
        ) : (
          <MessageContent content={message.content} />
        )}
      </div>
      
      {translation && (
        <TranslationQualityIndicator
          confidence={translation.confidence}
          onReport={() => reportTranslationIssue(message.id, displayLanguage)}
        />
      )}
      
      <LanguageSelector
        available={Object.keys(message.translations)}
        selected={displayLanguage}
        onChange={setSelectedLanguage}
      />
    </div>
  );
}
```

### 4. Live Translation Features
```typescript
// Live Translation Manager
export class LiveTranslationManager {
  private sessions = new Map<string, LiveSession>();
  private subtitleGenerator: SubtitleGenerator;
  
  constructor(
    private translationEngine: TranslationEngine,
    private audioProcessor: AudioProcessingService
  ) {
    this.subtitleGenerator = new SubtitleGenerator();
  }
  
  async startLiveTranslation(
    sessionId: string,
    config: LiveTranslationConfig
  ): Promise<void> {
    const session = new LiveSession({
      id: sessionId,
      participants: config.participants,
      languages: config.languages,
      mode: config.mode
    });
    
    this.sessions.set(sessionId, session);
    
    // Initialize audio streams for each participant
    for (const participant of config.participants) {
      await this.initializeParticipantStream(session, participant);
    }
  }
  
  private async initializeParticipantStream(
    session: LiveSession,
    participant: Participant
  ): Promise<void> {
    const stream = new TranslationStream({
      participantId: participant.id,
      sourceLanguage: participant.language || 'auto',
      targetLanguages: session.getTargetLanguagesFor(participant.id),
      onSegment: async (segment) => {
        await this.processSegment(session, participant, segment);
      }
    });
    
    session.addStream(participant.id, stream);
  }
  
  private async processSegment(
    session: LiveSession,
    speaker: Participant,
    segment: AudioSegment
  ): Promise<void> {
    // Transcribe audio segment
    const transcript = await this.transcribeSegment(segment, speaker.language);
    
    // Generate translations for other participants
    const translations = await this.generateTranslations(
      transcript,
      session.getParticipantLanguages()
    );
    
    // Create subtitles
    const subtitles = await this.subtitleGenerator.generate({
      speaker: speaker.name,
      transcript,
      translations,
      timing: segment.timing
    });
    
    // Distribute to participants
    await this.distributeTranslations(session, {
      speakerId: speaker.id,
      original: transcript,
      translations,
      subtitles
    });
  }
  
  private async distributeTranslations(
    session: LiveSession,
    packet: TranslationPacket
  ): Promise<void> {
    for (const participant of session.participants) {
      if (participant.id === packet.speakerId) continue;
      
      const targetLanguage = participant.language || 'en';
      const translation = packet.translations[targetLanguage];
      
      if (translation) {
        await this.sendToParticipant(participant.id, {
          type: 'translation',
          speaker: packet.speakerId,
          content: translation,
          subtitle: packet.subtitles[targetLanguage],
          confidence: translation.confidence
        });
      }
    }
  }
}

// Subtitle Generator
export class SubtitleGenerator {
  private timingCalculator: TimingCalculator;
  
  constructor() {
    this.timingCalculator = new TimingCalculator();
  }
  
  async generate(
    config: SubtitleConfig
  ): Promise<Record<string, Subtitle>> {
    const subtitles: Record<string, Subtitle> = {};
    
    // Generate subtitle for original language
    subtitles[config.transcript.language] = {
      id: generateId(),
      speaker: config.speaker,
      text: config.transcript.text,
      language: config.transcript.language,
      startTime: config.timing.start,
      endTime: config.timing.end,
      duration: config.timing.duration,
      words: await this.splitIntoWords(config.transcript)
    };
    
    // Generate subtitles for translations
    for (const [lang, translation] of Object.entries(config.translations)) {
      const timing = await this.adjustTimingForTranslation(
        config.timing,
        config.transcript.text,
        translation.text
      );
      
      subtitles[lang] = {
        id: generateId(),
        speaker: config.speaker,
        text: translation.text,
        language: lang,
        startTime: timing.start,
        endTime: timing.end,
        duration: timing.duration,
        words: await this.splitIntoWords(translation),
        isTranslated: true,
        confidence: translation.confidence
      };
    }
    
    return subtitles;
  }
  
  private async adjustTimingForTranslation(
    originalTiming: Timing,
    originalText: string,
    translatedText: string
  ): Promise<Timing> {
    // Calculate speaking rate adjustment
    const originalWords = originalText.split(' ').length;
    const translatedWords = translatedText.split(' ').length;
    const ratio = translatedWords / originalWords;
    
    // Adjust duration proportionally
    const adjustedDuration = originalTiming.duration * ratio;
    
    return {
      start: originalTiming.start,
      end: originalTiming.start + adjustedDuration,
      duration: adjustedDuration
    };
  }
}
```

### 5. Translation Quality & Feedback
```typescript
// Translation Quality Service
export class TranslationQualityService {
  private qualityMetrics = new Map<string, QualityMetrics>();
  private feedbackStore: FeedbackStore;
  
  constructor(
    private env: Env,
    private mlService: MLService
  ) {
    this.feedbackStore = new FeedbackStore(env.D1);
  }
  
  async evaluateTranslation(
    original: string,
    translated: string,
    sourceLang: string,
    targetLang: string
  ): Promise<QualityScore> {
    // Multiple quality checks
    const [
      fluency,
      adequacy,
      terminology,
      grammar
    ] = await Promise.all([
      this.checkFluency(translated, targetLang),
      this.checkAdequacy(original, translated, sourceLang, targetLang),
      this.checkTerminology(original, translated),
      this.checkGrammar(translated, targetLang)
    ]);
    
    const overall = this.calculateOverallScore({
      fluency,
      adequacy,
      terminology,
      grammar
    });
    
    return {
      overall,
      fluency,
      adequacy,
      terminology,
      grammar,
      confidence: this.calculateConfidence(overall),
      suggestions: await this.generateSuggestions(
        translated,
        { fluency, adequacy, terminology, grammar }
      )
    };
  }
  
  async collectFeedback(
    translationId: string,
    feedback: TranslationFeedback
  ): Promise<void> {
    await this.feedbackStore.save({
      id: generateId(),
      translationId,
      userId: feedback.userId,
      rating: feedback.rating,
      issues: feedback.issues,
      suggestion: feedback.suggestion,
      timestamp: Date.now()
    });
    
    // Update quality metrics
    await this.updateQualityMetrics(translationId, feedback);
    
    // Trigger model improvement if needed
    if (feedback.rating < 3) {
      await this.triggerModelImprovement(translationId, feedback);
    }
  }
  
  private async checkFluency(
    text: string,
    language: string
  ): Promise<number> {
    const model = await this.mlService.loadModel(
      `fluency-${language}`
    );
    
    const score = await model.evaluate(text);
    
    // Additional checks
    const readabilityScore = this.calculateReadability(text, language);
    const naturalness = await this.checkNaturalness(text, language);
    
    return (score + readabilityScore + naturalness) / 3;
  }
  
  private async checkAdequacy(
    original: string,
    translated: string,
    sourceLang: string,
    targetLang: string
  ): Promise<number> {
    // Semantic similarity check
    const sourceEmbedding = await this.getEmbedding(original, sourceLang);
    const targetEmbedding = await this.getEmbedding(translated, targetLang);
    
    const similarity = this.cosineSimilarity(sourceEmbedding, targetEmbedding);
    
    // Information preservation check
    const infoPreserved = await this.checkInformationPreservation(
      original,
      translated,
      sourceLang,
      targetLang
    );
    
    return (similarity + infoPreserved) / 2;
  }
}

// Translation Feedback UI
export function TranslationFeedback({ 
  translationId,
  onSubmit 
}: {
  translationId: string;
  onSubmit: () => void;
}) {
  const [rating, setRating] = useState<number>(0);
  const [issues, setIssues] = useState<string[]>([]);
  const [suggestion, setSuggestion] = useState('');
  const [isSubmitting, setIsSubmitting] = useState(false);
  
  const submitFeedback = async () => {
    setIsSubmitting(true);
    try {
      await api.submitTranslationFeedback({
        translationId,
        rating,
        issues,
        suggestion
      });
      
      toast.success('Thank you for your feedback!');
      onSubmit();
    } finally {
      setIsSubmitting(false);
    }
  };
  
  return (
    <div className="translation-feedback">
      <h4>How was this translation?</h4>
      
      <StarRating
        value={rating}
        onChange={setRating}
        max={5}
      />
      
      {rating > 0 && rating < 4 && (
        <>
          <div className="issue-selection">
            <p>What issues did you notice?</p>
            <IssueCheckboxes
              selected={issues}
              onChange={setIssues}
              options={[
                'Incorrect meaning',
                'Unnatural phrasing',
                'Grammar errors',
                'Missing context',
                'Technical terms',
                'Cultural inappropriateness'
              ]}
            />
          </div>
          
          <div className="suggestion-input">
            <label>Suggest a better translation (optional)</label>
            <textarea
              value={suggestion}
              onChange={(e) => setSuggestion(e.target.value)}
              placeholder="Enter your suggested translation..."
            />
          </div>
        </>
      )}
      
      <button
        onClick={submitFeedback}
        disabled={rating === 0 || isSubmitting}
      >
        Submit Feedback
      </button>
    </div>
  );
}
```

### 6. Offline Translation Support
```typescript
// Offline Translation Manager
export class OfflineTranslationManager {
  private offlineModels = new Map<string, OfflineModel>();
  private modelCache: ModelCache;
  
  constructor(private config: OfflineConfig) {
    this.modelCache = new ModelCache(config.maxCacheSize);
  }
  
  async downloadLanguagePack(
    languages: LanguagePair[]
  ): Promise<void> {
    for (const pair of languages) {
      const modelUrl = this.getModelUrl(pair);
      const model = await this.downloadModel(modelUrl);
      
      await this.modelCache.store(pair, model);
      
      // Initialize offline model
      const offlineModel = new OfflineModel({
        source: pair.source,
        target: pair.target,
        modelData: model
      });
      
      await offlineModel.initialize();
      
      this.offlineModels.set(
        `${pair.source}-${pair.target}`,
        offlineModel
      );
    }
  }
  
  async translateOffline(
    text: string,
    source: string,
    target: string
  ): Promise<Translation> {
    const model = this.offlineModels.get(`${source}-${target}`);
    
    if (!model) {
      throw new Error(
        `Offline model not available for ${source} to ${target}`
      );
    }
    
    const startTime = performance.now();
    
    const result = await model.translate(text);
    
    const duration = performance.now() - startTime;
    
    return {
      text: result.text,
      language: target,
      confidence: result.confidence,
      isOffline: true,
      duration,
      model: model.version
    };
  }
  
  async syncTranslations(): Promise<void> {
    // Get pending offline translations
    const pending = await this.getPendingTranslations();
    
    if (pending.length === 0) return;
    
    // Send to server for quality check
    const validated = await api.validateOfflineTranslations(pending);
    
    // Update local cache with server feedback
    for (const validation of validated) {
      if (validation.improved) {
        await this.updateTranslation(
          validation.id,
          validation.improvedTranslation
        );
      }
    }
  }
}

// Offline Translation UI
export function OfflineTranslationSettings() {
  const [downloadedPacks, setDownloadedPacks] = useState<LanguagePack[]>([]);
  const [availablePacks, setAvailablePacks] = useState<LanguagePack[]>([]);
  const [downloading, setDownloading] = useState<string | null>(null);
  
  useEffect(() => {
    loadLanguagePacks();
  }, []);
  
  const loadLanguagePacks = async () => {
    const [downloaded, available] = await Promise.all([
      api.getDownloadedLanguagePacks(),
      api.getAvailableLanguagePacks()
    ]);
    
    setDownloadedPacks(downloaded);
    setAvailablePacks(available);
  };
  
  const downloadPack = async (pack: LanguagePack) => {
    setDownloading(pack.id);
    
    try {
      await api.downloadLanguagePack(pack);
      await loadLanguagePacks();
      toast.success(`${pack.name} downloaded successfully`);
    } catch (error) {
      toast.error(`Failed to download ${pack.name}`);
    } finally {
      setDownloading(null);
    }
  };
  
  return (
    <div className="offline-translation-settings">
      <h3>Offline Translation</h3>
      <p>Download language packs for offline translation support</p>
      
      <div className="language-packs">
        <h4>Downloaded Packs</h4>
        {downloadedPacks.map(pack => (
          <LanguagePackCard
            key={pack.id}
            pack={pack}
            isDownloaded
            onDelete={() => deletePack(pack)}
          />
        ))}
        
        <h4>Available Packs</h4>
        {availablePacks.map(pack => (
          <LanguagePackCard
            key={pack.id}
            pack={pack}
            isDownloading={downloading === pack.id}
            onDownload={() => downloadPack(pack)}
          />
        ))}
      </div>
      
      <StorageIndicator
        used={calculateUsedStorage(downloadedPacks)}
        total={config.maxOfflineStorage}
      />
    </div>
  );
}
```

## Dependencies
- Translation API (Google Translate, DeepL, or custom)
- Speech recognition for voice translation
- Voice synthesis for translated audio
- WebRTC for real-time audio processing
- Offline translation models

## Estimated Effort
**6 days**
- 1 day: Translation engine core
- 1 day: Voice translation system
- 1 day: UI components and subtitles
- 1 day: Message translation
- 1 day: Quality evaluation system
- 1 day: Offline support

## Notes
- Implement caching for frequently translated phrases
- Add support for custom glossaries and terminology
- Consider context-aware translation
- Implement translation memory
- Add support for document translation
- Handle code-switching scenarios
- Optimize for low-latency translation